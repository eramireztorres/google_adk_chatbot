{"id": "23ab0130-db6e-403b-b44c-0cb21d132c26", "code": "from __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import LoopAgent, LlmAgent\n\n# Wrap the rag_agent in a LoopAgent for retry logic on code check failure\nbase_rag_agent = LlmAgent(\n    name=\"RagAgent\",\n    model=model,\n    instruction=(\n        \"Answer user questions about Google ADK using the MCP RAG tool. \"\n        \"If the question has multiple concepts, split into 2-3 focused subqueries, \"\n        \"call the MCP tool for each, and synthesize a single answer. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n        \"Do not include commented-out calls to non-existent methods; omit the call entirely.\"\n    ),\n    tools=[rag_toolset],\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[base_rag_agent],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit loops if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Limit snippet size to avoid abuse and long runs\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        # Escalate to exit LoopAgent early if used in loop\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, delegate to the RAG loop agent. \"\n        \"When the RAG agent returns Python code blocks, use the code-check tool to validate imports and instantiations. \"\n        \"If validation fails, instruct the RAG agent to reformulate the answer and retry once. \"\n        \"Only return finalized answers after successful code validation. \"\n        \"Avoid commented-out or non-existent method calls in your responses.\"\n    ),\n    tools=[rag_tool, check_tool],\n)\n\n", "language": "python", "parent_id": "e3b12877-6d29-4636-9724-6523b1243bd0", "generation": 1, "timestamp": 1769337793.3179922, "iteration_found": 9, "metrics": {"combined_score": 0.5280612759590149, "latency": 43.60539070765177, "artifacts": {"details": [{"query": "Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.", "score": 0.45, "latency": 51.867241621017456, "code_extracted": true, "exec_success": false, "keyword_match": 0.16666666666666666}, {"query": "Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.", "score": 0.0, "latency": 28.209362506866455, "code_extracted": false, "exec_success": false, "keyword_match": 0.0}, {"query": "Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.", "score": 0.46, "latency": 74.71838021278381, "code_extracted": true, "exec_success": false, "keyword_match": 0.2}, {"query": "Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.", "score": 0.85, "latency": 29.210249662399292, "code_extracted": true, "exec_success": true, "keyword_match": 0.5}, {"query": "Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.", "score": 0.82, "latency": 23.710159063339233, "code_extracted": true, "exec_success": true, "keyword_match": 0.4}, {"query": "Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.", "score": 0.85, "latency": 53.916951179504395, "code_extracted": true, "exec_success": true, "keyword_match": 0.5}], "avg_latency": 43.60539070765177}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 15 lines with 24 lines\nChange 2: Replace 13 lines with 12 lines\nChange 3: Replace 34 lines with 42 lines", "parent_metrics": {"combined_score": 0.5237877621253332, "latency": 39.54557120800018, "artifacts": {"details": [{"query": "Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.", "score": 0.5, "latency": 22.27932381629944, "code_extracted": true, "exec_success": false, "keyword_match": 0.3333333333333333}, {"query": "Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.", "score": 0.7, "latency": 33.00701379776001, "code_extracted": true, "exec_success": true, "keyword_match": 0.0}, {"query": "Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.", "score": 0.46, "latency": 39.699023723602295, "code_extracted": true, "exec_success": false, "keyword_match": 0.2}, {"query": "Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.", "score": 0.55, "latency": 15.255670309066772, "code_extracted": true, "exec_success": false, "keyword_match": 0.5}, {"query": "Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.", "score": 0.52, "latency": 57.45232081413269, "code_extracted": true, "exec_success": false, "keyword_match": 0.4}, {"query": "Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.", "score": 0.65, "latency": 69.58007478713989, "code_extracted": true, "exec_success": false, "keyword_match": 0.8333333333333334}], "avg_latency": 39.54557120800018}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert ADK Architect optimizing an agent for Python code generation.\nThe agent instructions and tool usage are key areas to optimize.\nEncourage the exploration of:\n- Different and more robust agent instructions.\n- Creating separate specialized agents if necessary (e.g. valid for creating/running agents vs using tools).\nAlso, you are free to improve 'initial_program.py' using these advanced ADK patterns:\n\n1. **Workflow Agents** (deterministic coordination):\n   - `SequentialAgent(name=str, sub_agents=[agent1, agent2], description=str)`: Linear pipelines (e.g., Plan -> Code -> Review).\n   - `LoopAgent(name=str, sub_agents=[...], max_iterations=int)`: Iterative tasks (e.g., Generate -> Test -> Fix).\n   - `ParallelAgent(name=str, sub_agents=[...])`: Concurrent execution (e.g., Research multiple topics).\n\n2. **State & Control**:\n   - **Shared State**: `InvocationContext` is shared. Access via `tool_context.state` (in tools) or `callback_context.state` (in callbacks).\n   - **Loop Escalation**: To exit a `LoopAgent` early from a tool, use:\n     ```python\n     def exit_tool(tool_context: ToolContext):\n         tool_context.actions.escalate = True\n         return {\"status\": \"exiting\"}\n     ```\n   - **Data Flow**: Use `output_key=\"my_key\"` in `LlmAgent` to automatically write its output to state.\n\n3. **Callbacks & Imports** (Cheat Sheet):\n   - **Imports**:\n     ```python\n     from google.adk.agents import LlmAgent, Action\n     from google.adk.agents.callback_context import CallbackContext\n     from google.adk.tool import ToolContext\n     from google.adk.runners import InMemoryRunner\n     from google.genai import types\n     from typing import Optional\n     ```\n   - **Signatures**:\n     - `def my_cb(ctx: CallbackContext, req: LlmRequest) -> Optional[LlmResponse]: ...`\n   - **Usage**: `LlmAgent(..., before_model_callback=my_cb)`\n\n4. **Custom Agents** (Deterministic Logic):\n   - Subclass `BaseAgent` for complex orchestration logic not covered by standard workflows.\n   - Implement `async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:`.\n   - Yield events from sub-agents: `async for event in self.sub_agent.run_async(ctx): yield event`.\n\n5. **Constraints**:\n   - `root_agent` MUST be an `LlmAgent` (not deterministic). It acts as the intelligent entry point.\n   - Ensure generated Python code is robust, self-contained, and uses these ADK patterns correctly.\n", "user": "# Current Program Information\n- Fitness: 0.5238\n- Feature coordinates: \n- Focus areas: - Fitness improved: 0.0000 \u2192 0.5238\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 15 lines with 24 lines\nChange 2: Replace 54 lines with 54 lines\nChange 3: Replace 18 lines with 9 lines\nChange 4: Replace _configure_logging() with 4 lines\n- Metrics: combined_score: 0.0000, error: No module named 'google.adk.tool', artifacts: {'traceback': 'Traceback (most recent call last):\\n  File \"/home/erick/repo/google_adk_chatbot/chatbot/ADK_assistant/openevolve_experiments/evaluator.py\", line 117, in evaluate\\n    spec.loader.exec_module(candidate_module)\\n    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\\n  File \"<frozen importlib._bootstrap_external>\", line 1026, in exec_module\\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\\n  File \"/tmp/tmpsgybn9hm.py\", line 24, in <module>\\n    from google.adk.tool import ToolContext\\nModuleNotFoundError: No module named \\'google.adk.tool\\'\\n'}\n- Outcome: Regression in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 15 lines with 31 lines\nChange 2: Replace 34 lines with 44 lines\nChange 3: Replace 13 lines with 22 lines\nChange 4: Replace 11 lines with 11 lines\n- Metrics: combined_score: 0.0000, error: 1 validation error for LlmAgent\nname\n  Value error, Found invalid agent name: `RagAgent-SubquerySplitter`. Agent name must be a valid identifier. It should start with a letter (a-z, A-Z) or an underscore (_), and can only contain letters, digits (0-9), and underscores. [type=value_error, input_value='RagAgent-SubquerySplitter', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error, artifacts: {'traceback': 'Traceback (most recent call last):\\n  File \"/home/erick/repo/google_adk_chatbot/chatbot/ADK_assistant/openevolve_experiments/evaluator.py\", line 117, in evaluate\\n    spec.loader.exec_module(candidate_module)\\n    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\\n  File \"<frozen importlib._bootstrap_external>\", line 1026, in exec_module\\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\\n  File \"/tmp/tmpyqb0d2ex.py\", line 69, in <module>\\n    LlmAgent(\\n    ~~~~~~~~^\\n        name=\"RagAgent-SubquerySplitter\",\\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n    ...<5 lines>...\\n        output_key=\"subqueries\",\\n        ^^^^^^^^^^^^^^^^^^^^^^^^\\n    ),\\n    ^\\n  File \"/home/erick/repo/google_adk_chatbot/venv/lib/python3.13/site-packages/pydantic/main.py\", line 250, in __init__\\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\\npydantic_core._pydantic_core.ValidationError: 1 validation error for LlmAgent\\nname\\n  Value error, Found invalid agent name: `RagAgent-SubquerySplitter`. Agent name must be a valid identifier. It should start with a letter (a-z, A-Z) or an underscore (_), and can only contain letters, digits (0-9), and underscores. [type=value_error, input_value=\\'RagAgent-SubquerySplitter\\', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error\\n'}\n- Outcome: Regression in all metrics\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: combined_score: 0.5238, latency: 39.5456, artifacts: {'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.5, 'latency': 22.27932381629944, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.7, 'latency': 33.00701379776001, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.0}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.46, 'latency': 39.699023723602295, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.2}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.55, 'latency': 15.255670309066772, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.5}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.52, 'latency': 57.45232081413269, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.4}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.65, 'latency': 69.58007478713989, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8333333333333334}], 'avg_latency': 39.54557120800018}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.5238)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nrag_agent = LlmAgent(\n    name=\"RagAgent\",\n    model=model,\n    instruction=(\n        \"Answer user questions about Google ADK using the MCP RAG tool. \"\n        \"If the question has multiple concepts, split into 2-3 focused subqueries, \"\n        \"call the MCP tool for each, and synthesize a single answer. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n        \"Do not include commented-out calls to non-existent methods; omit the call entirely.\"\n    ),\n    tools=[rag_toolset],\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. For every user query, call the RAG tool. \"\n        \"If the RagAgent response includes a Python code block, run a minimal \"\n        \"import/instantiation check using the code-check tool before responding. \"\n        \"If the check fails, reformulate the query and call the RAG tool again, \"\n        \"then re-check once before responding. \"\n        \"Do not return commented-out calls to non-existent methods.\"\n    ),\n    tools=[rag_tool, check_tool],\n)\n\n\n```\nKey features: Performs well on combined_score (0.5238), Performs well on latency (39.5456), Performs well on artifacts ({'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.5, 'latency': 22.27932381629944, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.7, 'latency': 33.00701379776001, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.0}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.46, 'latency': 39.699023723602295, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.2}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.55, 'latency': 15.255670309066772, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.5}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.52, 'latency': 57.45232081413269, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.4}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.65, 'latency': 69.58007478713989, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8333333333333334}], 'avg_latency': 39.54557120800018})\n\n### Program 2 (Score: 0.0000)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent, SequentialAgent, LoopAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent\n\nrag_agent = SequentialAgent(\n    name=\"RagAgent\",\n    sub_agents=[\n        LlmAgent(\n            name=\"RagAgent-SubquerySplitter\",\n            model=model,\n            instruction=(\n                \"You are an assistant that splits complex user questions about Google ADK into 2-3 focused subqueries. \"\n                \"Output a JSON list of subquery strings.\"\n            ),\n            output_key=\"subqueries\",\n        ),\n        LlmAgent(\n            name=\"RagAgent-MCPCaller\",\n            model=model,\n            instruction=(\n                \"You receive a list of focused subqueries about Google ADK. \"\n                \"For each, call the MCP tool to get answers, then synthesize a single comprehensive answer. \"\n                \"If the user asks for code, include a Python code block. \"\n                \"Only use documented ADK APIs and Runner/Invocation patterns. \"\n                \"Do not invent convenience methods or include commented-out calls.\"\n            ),\n            tools=[rag_toolset],\n            output_key=\"final_answer\",\n        ),\n    ],\n    instruction=\"Coordinate splitting and answering user questions about Google ADK with MCP tool.\",\n    output_key=\"final_answer\",\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in a subprocess to validate imports or simple instantiations.\n    Abort early if code is empty or whitespace.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        # Use subprocess with check=True to raise on failures, capturing output.\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n            check=True,\n        )\n        ok = True\n    except subprocess.CalledProcessError as e:\n        # Return failure details on error\n        return {\n            \"ok\": False,\n            \"returncode\": e.returncode,\n            \"stdout\": e.stdout.strip() if e.stdout else \"\",\n            \"stderr\": e.stderr.strip() if e.stderr else \"\",\n        }\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    return {\n        \"ok\": ok,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nfrom google.adk.agents import LoopAgent, LlmAgent\n\nroot_agent = LoopAgent(\n    name=\"RootAgent\",\n    sub_agents=[\n        rag_agent,\n        LlmAgent(\n            name=\"CodeCheckAgent\",\n            model=model,\n            instruction=(\n                \"Given a response from the RagAgent, detect if there is a Python code block. \"\n                \"If present, extract the code and run a minimal import/instantiation check using the code-check tool. \"\n                \"If the check fails, escalate to rerun the RagAgent with a reformulated query. \"\n                \"Otherwise, approve the response.\"\n            ),\n            tools=[check_tool],\n            output_key=\"check_result\",\n        ),\n    ],\n    max_iterations=2,\n    instruction=\"Run RagAgent and validate Python code blocks iteratively, retrying once on failure.\",\n)\n\n\n```\nKey features: Performs well on combined_score (0.0000), Performs well on error (1 validation error for LlmAgent\nname\n  Value error, Found invalid agent name: `RagAgent-SubquerySplitter`. Agent name must be a valid identifier. It should start with a letter (a-z, A-Z) or an underscore (_), and can only contain letters, digits (0-9), and underscores. [type=value_error, input_value='RagAgent-SubquerySplitter', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error), Performs well on artifacts ({'traceback': 'Traceback (most recent call last):\\n  File \"/home/erick/repo/google_adk_chatbot/chatbot/ADK_assistant/openevolve_experiments/evaluator.py\", line 117, in evaluate\\n    spec.loader.exec_module(candidate_module)\\n    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\\n  File \"<frozen importlib._bootstrap_external>\", line 1026, in exec_module\\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\\n  File \"/tmp/tmpyqb0d2ex.py\", line 69, in <module>\\n    LlmAgent(\\n    ~~~~~~~~^\\n        name=\"RagAgent-SubquerySplitter\",\\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n    ...<5 lines>...\\n        output_key=\"subqueries\",\\n        ^^^^^^^^^^^^^^^^^^^^^^^^\\n    ),\\n    ^\\n  File \"/home/erick/repo/google_adk_chatbot/venv/lib/python3.13/site-packages/pydantic/main.py\", line 250, in __init__\\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\\npydantic_core._pydantic_core.ValidationError: 1 validation error for LlmAgent\\nname\\n  Value error, Found invalid agent name: `RagAgent-SubquerySplitter`. Agent name must be a valid identifier. It should start with a letter (a-z, A-Z) or an underscore (_), and can only contain letters, digits (0-9), and underscores. [type=value_error, input_value=\\'RagAgent-SubquerySplitter\\', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error\\n'})\n\n### Program 3 (Score: 0.0000)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.tool import ToolContext\n\ndef before_root_agent_callback(ctx: CallbackContext, req) -> None:\n    logging.info(f\"RootAgent received prompt: {req.prompt}\")\n\n_configure_logging()\n\n# Optional: Add a callback to log before root agent runs\nroot_agent.before_model_callback = before_root_agent_callback\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent\n\nrag_agent = LlmAgent(\n    name=\"RagAgentLLM\",\n    model=model,\n    instruction=(\n        \"You are a helpful assistant answering questions about Google ADK using the MCP RAG tool. \"\n        \"For multi-concept questions, split into focused subqueries, call the MCP tool for each, \"\n        \"and synthesize a single comprehensive answer. \"\n        \"If user requests code, include a valid Python code block using only ADK APIs documented. \"\n        \"Avoid invented convenience methods; use official Runner/Invocation patterns.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_answer\",\n)\n\n# Wrap rag_agent in a LoopAgent to allow re-query on code check failures\nrag_loop_agent = LoopAgent(\n    name=\"RagLoopAgent\",\n    sub_agents=[rag_agent],\n    max_iterations=2,  # Try up to 2 times if code check fails\n)\n\n# Now rag_loop_agent will be used instead of rag_agent\n\n\n# 2. Define the Code Check Tool (unchanged, but renamed for clarity)\ndef validate_python_code(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n\n\n# 3. Define the Root Agent with improved instructions and tool usage\nrag_tool = AgentTool(agent=rag_loop_agent)\ncheck_tool = FunctionTool(func=validate_python_code)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, delegate to the RAG loop agent. \"\n        \"When the RAG agent returns code blocks, use the code-check tool to validate imports and instantiations. \"\n        \"If validation fails, instruct the RAG agent to reformulate the answer and retry once. \"\n        \"Only return finalized answers after successful code validation. \"\n        \"Avoid commented-out or non-existent method calls in your responses.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nKey features: Performs well on combined_score (0.0000), Performs well on error (No module named 'google.adk.tool'), Performs well on artifacts ({'traceback': 'Traceback (most recent call last):\\n  File \"/home/erick/repo/google_adk_chatbot/chatbot/ADK_assistant/openevolve_experiments/evaluator.py\", line 117, in evaluate\\n    spec.loader.exec_module(candidate_module)\\n    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\\n  File \"<frozen importlib._bootstrap_external>\", line 1026, in exec_module\\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\\n  File \"/tmp/tmpsgybn9hm.py\", line 24, in <module>\\n    from google.adk.tool import ToolContext\\nModuleNotFoundError: No module named \\'google.adk.tool\\'\\n'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent\n\n# Compose a workflow agent that separates planning, RAG query, code check and response synthesis.\n\n# Sub-agent 1: Plan and split question if needed\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"if it contains multiple concepts, split it into 2-3 focused subqueries. \"\n        \"Return the list of subqueries in JSON array format. If only one, return single-element array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\n# Sub-agent 2: RAG queries for each subquery (runs MCP tool)\nrag_agent = LlmAgent(\n    name=\"RagAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\n# Sub-agent 3: Code snippet checker\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the RAG response for Python code blocks. For each code block, \"\n        \"run the code snippet checker tool to validate imports and instantiation. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'.\"\n    ),\n    tools=[check_tool],\n    output_key=\"check_result\",\n)\n\n# Sub-agent 4: Response synthesizer\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize the final answer by combining the RAG responses to the subqueries. \"\n        \"If code was checked and passed, include the code blocks in the answer. \"\n        \"If code check failed, say you are retrying. \"\n        \"Keep the answer concise and relevant.\"\n    ),\n)\n\n# Compose a sequential agent that performs planning, queries, checking and synthesis\nrag_agent = SequentialAgent(\n    name=\"RagAgent\",\n    sub_agents=[\n        planning_agent,\n        rag_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. Given a user query, use the RagAgent workflow \"\n        \"to plan, query, check code, and synthesize a final answer. \"\n        \"If code check fails, instruct the RagAgent to retry once. \"\n        \"Return the final synthesized answer only. \"\n        \"Do not include commented-out or non-existent method calls.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to error\n\n### Program D2 (Score: 0.0000)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent\n\nrag_agent = LlmAgent(\n    name=\"RagAgent\",\n    model=model,\n    instruction=(\n        \"Answer user questions about Google ADK using the MCP RAG tool. \"\n        \"If the question has multiple concepts, split into 2-3 focused subqueries, \"\n        \"call the MCP tool for each, and synthesize a single answer. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n        \"Do not include commented-out calls to non-existent methods; omit the call entirely.\"\n    ),\n    tools=[rag_toolset],\n)\n\n# Wrap rag_agent in a SequentialAgent with a code review step for robustness\nfrom google.adk.agents import LlmAgent\n\ncode_review_agent = LlmAgent(\n    name=\"CodeReviewAgent\",\n    model=model,\n    instruction=(\n        \"Review the provided Python code snippet for correctness, style, and adherence \"\n        \"to best practices in ADK usage. Respond with 'APPROVED' if the code is good, \"\n        \"or provide specific suggestions for fixes.\"\n    ),\n    tools=[],\n    output_key=\"code_review\"\n)\n\nrag_agent = SequentialAgent(\n    name=\"RagAgentWithReview\",\n    sub_agents=[rag_agent, code_review_agent],\n    description=(\n        \"Sequentially runs the RAG agent and then reviews its code output for quality assurance.\"\n    ),\n)\n\n\n# 2. Define the Code Check Tool\nfrom google.adk.tools.tool_context import ToolContext, ToolAction\n\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    If execution fails, escalate to exit LoopAgent early if used in loop.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        # Escalate to exit loop if running inside LoopAgent\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nfrom google.adk.agents import LoopAgent\n\nroot_agent = LoopAgent(\n    name=\"RootAgent\",\n    sub_agents=[rag_tool, check_tool],\n    max_iterations=2,\n    description=(\n        \"Main coordinator agent loop. Calls RAG tool to answer user query. \"\n        \"If the RAG tool's response contains Python code, uses the code check tool to validate. \"\n        \"If validation fails, reformulates and retries once. Exits loop early on successful validation.\"\n    ),\n)\n\n# Assign the root agent as an LlmAgent wrapper for compliance with constraints\nroot_agent = LlmAgent(\n    name=\"RootAgentWrapper\",\n    model=model,\n    instruction=(\n        \"You are the main entry point agent. Delegate user queries to the RootAgent loop which \"\n        \"handles RAG querying and code validation.\"\n    ),\n    tools=[root_agent],\n)\n\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to error\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent\n\nrag_agent = LlmAgent(\n    name=\"RagAgent\",\n    model=model,\n    instruction=(\n        \"Answer user questions about Google ADK using the MCP RAG tool. \"\n        \"If the question has multiple concepts, split into 2-3 focused subqueries, \"\n        \"call the MCP tool for each, and synthesize a single answer. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n        \"Do not include commented-out calls to non-existent methods; omit the call entirely.\"\n    ),\n    tools=[rag_toolset],\n)\n\n# Wrap rag_agent in a SequentialAgent with a code review step for robustness\nfrom google.adk.agents import LlmAgent\n\ncode_review_agent = LlmAgent(\n    name=\"CodeReviewAgent\",\n    model=model,\n    instruction=(\n        \"Review the provided Python code snippet for correctness, style, and adherence \"\n        \"to best practices in ADK usage. Respond with 'APPROVED' if the code is good, \"\n        \"or provide specific suggestions for fixes.\"\n    ),\n    tools=[],\n    output_key=\"code_review\"\n)\n\nrag_agent = SequentialAgent(\n    name=\"RagAgentWithReview\",\n    sub_agents=[rag_agent, code_review_agent],\n    description=(\n        \"Sequentially runs the RAG agent and then reviews its code output for quality assurance.\"\n    ),\n)\n\n\n# 2. Define the Code Check Tool\nfrom google.adk.tools.tool_context import ToolContext, ToolAction\n\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    If execution fails, escalate to exit LoopAgent early if used in loop.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        # Escalate to exit loop if running inside LoopAgent\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nfrom google.adk.agents import LoopAgent\n\nroot_agent = LoopAgent(\n    name=\"RootAgent\",\n    sub_agents=[rag_tool, check_tool],\n    max_iterations=2,\n    description=(\n        \"Main coordinator agent loop. Calls RAG tool to answer user query. \"\n        \"If the RAG tool's response contains Python code, uses the code check tool to validate. \"\n        \"If validation fails, reformulates and retries once. Exits loop early on successful validation.\"\n    ),\n)\n\n# Assign the root agent as an LlmAgent wrapper for compliance with constraints\nroot_agent = LlmAgent(\n    name=\"RootAgentWrapper\",\n    model=model,\n    instruction=(\n        \"You are the main entry point agent. Delegate user queries to the RootAgent loop which \"\n        \"handles RAG querying and code validation.\"\n    ),\n    tools=[root_agent],\n)\n\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Comprehensive implementation\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.tool import ToolContext\n\ndef before_root_agent_callback(ctx: CallbackContext, req) -> None:\n    logging.info(f\"RootAgent received prompt: {req.prompt}\")\n\n_configure_logging()\n\n# Optional: Add a callback to log before root agent runs\nroot_agent.before_model_callback = before_root_agent_callback\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent\n\nrag_agent = LlmAgent(\n    name=\"RagAgentLLM\",\n    model=model,\n    instruction=(\n        \"You are a helpful assistant answering questions about Google ADK using the MCP RAG tool. \"\n        \"For multi-concept questions, split into focused subqueries, call the MCP tool for each, \"\n        \"and synthesize a single comprehensive answer. \"\n        \"If user requests code, include a valid Python code block using only ADK APIs documented. \"\n        \"Avoid invented convenience methods; use official Runner/Invocation patterns.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_answer\",\n)\n\n# Wrap rag_agent in a LoopAgent to allow re-query on code check failures\nrag_loop_agent = LoopAgent(\n    name=\"RagLoopAgent\",\n    sub_agents=[rag_agent],\n    max_iterations=2,  # Try up to 2 times if code check fails\n)\n\n# Now rag_loop_agent will be used instead of rag_agent\n\n\n# 2. Define the Code Check Tool (unchanged, but renamed for clarity)\ndef validate_python_code(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n\n\n# 3. Define the Root Agent with improved instructions and tool usage\nrag_tool = AgentTool(agent=rag_loop_agent)\ncheck_tool = FunctionTool(func=validate_python_code)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, delegate to the RAG loop agent. \"\n        \"When the RAG agent returns code blocks, use the code-check tool to validate imports and instantiations. \"\n        \"If validation fails, instruct the RAG agent to reformulate the answer and retry once. \"\n        \"Only return finalized answers after successful code validation. \"\n        \"Avoid commented-out or non-existent method calls in your responses.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Comprehensive implementation\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent\n\n# Compose a workflow agent that separates planning, RAG query, code check and response synthesis.\n\n# Sub-agent 1: Plan and split question if needed\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"if it contains multiple concepts, split it into 2-3 focused subqueries. \"\n        \"Return the list of subqueries in JSON array format. If only one, return single-element array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\n# Sub-agent 2: RAG queries for each subquery (runs MCP tool)\nrag_agent = LlmAgent(\n    name=\"RagAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\n# Sub-agent 3: Code snippet checker\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the RAG response for Python code blocks. For each code block, \"\n        \"run the code snippet checker tool to validate imports and instantiation. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'.\"\n    ),\n    tools=[check_tool],\n    output_key=\"check_result\",\n)\n\n# Sub-agent 4: Response synthesizer\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize the final answer by combining the RAG responses to the subqueries. \"\n        \"If code was checked and passed, include the code blocks in the answer. \"\n        \"If code check failed, say you are retrying. \"\n        \"Keep the answer concise and relevant.\"\n    ),\n)\n\n# Compose a sequential agent that performs planning, queries, checking and synthesis\nrag_agent = SequentialAgent(\n    name=\"RagAgent\",\n    sub_agents=[\n        planning_agent,\n        rag_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. Given a user query, use the RagAgent workflow \"\n        \"to plan, query, check code, and synthesize a final answer. \"\n        \"If code check fails, instruct the RagAgent to retry once. \"\n        \"Return the final synthesized answer only. \"\n        \"Do not include commented-out or non-existent method calls.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Comprehensive implementation\n\n# Current Program\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nrag_agent = LlmAgent(\n    name=\"RagAgent\",\n    model=model,\n    instruction=(\n        \"Answer user questions about Google ADK using the MCP RAG tool. \"\n        \"If the question has multiple concepts, split into 2-3 focused subqueries, \"\n        \"call the MCP tool for each, and synthesize a single answer. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n        \"Do not include commented-out calls to non-existent methods; omit the call entirely.\"\n    ),\n    tools=[rag_toolset],\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. For every user query, call the RAG tool. \"\n        \"If the RagAgent response includes a Python code block, run a minimal \"\n        \"import/instantiation check using the code-check tool before responding. \"\n        \"If the check fails, reformulate the query and call the RAG tool again, \"\n        \"then re-check once before responding. \"\n        \"Do not return commented-out calls to non-existent methods.\"\n    ),\n    tools=[rag_tool, check_tool],\n)\n\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["<<<<<<< SEARCH\nrag_agent = LlmAgent(\n    name=\"RagAgent\",\n    model=model,\n    instruction=(\n        \"Answer user questions about Google ADK using the MCP RAG tool. \"\n        \"If the question has multiple concepts, split into 2-3 focused subqueries, \"\n        \"call the MCP tool for each, and synthesize a single answer. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n        \"Do not include commented-out calls to non-existent methods; omit the call entirely.\"\n    ),\n    tools=[rag_toolset],\n)\n=======\nfrom google.adk.agents import LoopAgent, LlmAgent\n\n# Wrap the rag_agent in a LoopAgent for retry logic on code check failure\nbase_rag_agent = LlmAgent(\n    name=\"RagAgent\",\n    model=model,\n    instruction=(\n        \"Answer user questions about Google ADK using the MCP RAG tool. \"\n        \"If the question has multiple concepts, split into 2-3 focused subqueries, \"\n        \"call the MCP tool for each, and synthesize a single answer. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n        \"Do not include commented-out calls to non-existent methods; omit the call entirely.\"\n    ),\n    tools=[rag_toolset],\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[base_rag_agent],\n    max_iterations=2,\n)\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. For every user query, call the RAG tool. \"\n        \"If the RagAgent response includes a Python code block, run a minimal \"\n        \"import/instantiation check using the code-check tool before responding. \"\n        \"If the check fails, reformulate the query and call the RAG tool again, \"\n        \"then re-check once before responding. \"\n        \"Do not return commented-out calls to non-existent methods.\"\n    ),\n    tools=[rag_tool, check_tool],\n)\n=======\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, delegate to the RAG loop agent. \"\n        \"When the RAG agent returns Python code blocks, use the code-check tool to validate imports and instantiations. \"\n        \"If validation fails, instruct the RAG agent to reformulate the answer and retry once. \"\n        \"Only return finalized answers after successful code validation. \"\n        \"Avoid commented-out or non-existent method calls in your responses.\"\n    ),\n    tools=[rag_tool, check_tool],\n)\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n=======\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit loops if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Limit snippet size to avoid abuse and long runs\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        # Escalate to exit LoopAgent early if used in loop\n        tool_context.actions.escalate = True\n    return result_payload\n>>>>>>> REPLACE"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}