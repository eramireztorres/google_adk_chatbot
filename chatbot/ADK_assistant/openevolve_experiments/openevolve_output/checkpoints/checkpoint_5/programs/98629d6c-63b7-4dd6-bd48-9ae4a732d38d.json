{"id": "98629d6c-63b7-4dd6-bd48-9ae4a732d38d", "code": "from __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    # Use a more robust default model for better code generation\n    default_model = \"gpt-4.1-nano\"\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model or default_model}\")\n    return model or default_model\n\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\n\n\n\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Improved error handling and added retry logic for transient errors.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    max_retries = 2\n    for attempt in range(max_retries):\n        with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n            handle.write(code)\n            path = handle.name\n\n        try:\n            result = subprocess.run(\n                [sys.executable, path],\n                capture_output=True,\n                text=True,\n                timeout=10,\n            )\n            if result.returncode == 0:\n                # Success\n                break\n            else:\n                # Check for common transient errors in stderr\n                stderr_lower = result.stderr.lower()\n                if any(err in stderr_lower for err in [\"resource temporarily unavailable\", \"too many open files\"]):\n                    # Retry if transient error detected\n                    continue\n                else:\n                    # Non-recoverable error, break and report\n                    break\n        except subprocess.TimeoutExpired:\n            return {\"ok\": False, \"error\": \"Execution timed out.\"}\n        finally:\n            try:\n                os.unlink(path)\n            except OSError:\n                pass\n    else:\n        # If retries exhausted\n        return {\"ok\": False, \"error\": \"Execution failed after retries.\"}\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n\n\ndef _build_rag_agent(model: str | LiteLlm) -> LlmAgent:\n    rag_toolset = MCPToolset(\n        connection_params=SseConnectionParams(\n            url=_rag_mcp_url(),\n            timeout=300,\n        )\n    )\n    return LlmAgent(\n        name=\"RagAgent\",\n        model=model,\n        instruction=(\n            \"You are a knowledgeable assistant about Google ADK and related tools. \"\n            \"For each user question, identify distinct concepts and split them into 2-3 focused subqueries. \"\n            \"Call the MCP tool for each subquery and synthesize a clear, concise, and accurate single answer. \"\n            \"If code is requested, provide a properly formatted Python code block. \"\n            \"Only use documented ADK APIs; do not invent convenience methods like agent.chat, agent.run, or agent.invoke. \"\n            \"Follow the Runner/Invocation patterns as shown in official ADK docs for code execution. \"\n            \"Avoid including any commented-out calls to non-existent methods; omit such calls entirely.\"\n        ),\n        tools=[rag_toolset],\n    )\n\n\ndef _build_root_agent(model: str | LiteLlm) -> LlmAgent:\n    rag_agent = _build_rag_agent(model)\n    rag_tool = AgentTool(agent=rag_agent)\n    check_tool = FunctionTool(func=run_python_snippet)\n\n    return LlmAgent(\n        name=\"RootAgent\",\n        model=model,\n        instruction=(\n            \"You are the main coordinating agent. For each user query, first call the RAG tool. \"\n            \"If the response from RagAgent contains a Python code block, extract it and run a minimal \"\n            \"import and instantiation check using the code-check tool before replying to the user. \"\n            \"If the code check fails, reformulate the query with additional clarification or corrections and call the RAG tool again. \"\n            \"Perform one retry of code validation before responding. \"\n            \"Ensure the final response contains no commented-out calls to non-existent methods. \"\n            \"Provide clear, concise, and runnable Python code when requested.\"\n        ),\n        tools=[rag_tool, check_tool],\n    )\n\n\nroot_agent = _build_root_agent(_resolve_llm_model())\n", "language": "python", "parent_id": "18cbb167-4f44-4bac-971e-76a15ed75dd1", "generation": 1, "timestamp": 1769299196.7742925, "iteration_found": 1, "metrics": {"combined_score": 0.38421997841199235, "latency": 49.11335492134094, "artifacts": {"details": [{"query": "Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.", "score": 0.0, "latency": 63.574668407440186, "code_extracted": false, "exec_success": false, "keyword_match": 0.0}, {"query": "Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.", "score": 0.0, "latency": 35.88235139846802, "code_extracted": false, "exec_success": false, "keyword_match": 0.0}, {"query": "Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.", "score": 0.8799999999999999, "latency": 59.95132064819336, "code_extracted": true, "exec_success": true, "keyword_match": 0.6}, {"query": "Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.", "score": 0.0, "latency": 39.91960692405701, "code_extracted": false, "exec_success": false, "keyword_match": 0.0}, {"query": "Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.", "score": 0.82, "latency": 22.236692667007446, "code_extracted": true, "exec_success": true, "keyword_match": 0.4}, {"query": "Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.", "score": 0.8999999999999999, "latency": 73.11548948287964, "code_extracted": true, "exec_success": true, "keyword_match": 0.6666666666666666}], "avg_latency": 49.11335492134094}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 34 lines with 52 lines\nChange 2: Replace 22 lines with 21 lines\nChange 3: Replace 18 lines with 19 lines\nChange 4: Replace 6 lines with 8 lines", "parent_metrics": {"combined_score": 0.535304036140442, "latency": 38.02929719289144, "artifacts": {"details": [{"query": "Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.", "score": 0.55, "latency": 19.38530969619751, "code_extracted": true, "exec_success": false, "keyword_match": 0.5}, {"query": "Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.", "score": 0.5, "latency": 26.569865703582764, "code_extracted": true, "exec_success": false, "keyword_match": 0.3333333333333333}, {"query": "Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.", "score": 0.5800000000000001, "latency": 18.542023181915283, "code_extracted": true, "exec_success": false, "keyword_match": 0.6}, {"query": "Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.", "score": 0.45, "latency": 23.256146907806396, "code_extracted": true, "exec_success": false, "keyword_match": 0.16666666666666666}, {"query": "Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.", "score": 0.76, "latency": 47.44441866874695, "code_extracted": true, "exec_success": true, "keyword_match": 0.2}, {"query": "Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.", "score": 0.6, "latency": 92.97801899909973, "code_extracted": true, "exec_success": false, "keyword_match": 0.6666666666666666}], "avg_latency": 38.02929719289144}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert AI optimization assistant used to evolve a Google ADK agent.\nYour goal is to modify the 'agent.py' (initial_program.py) to better handle user queries and generate correct Python code.\n\nThe agent instructions and tool usage are key areas to optimize. \nEncourage the exploration of:\n- Different and more robust agent instructions.\n- Creating separate specialized agents if necessary (e.g. valid for creating/running agents vs using tools).\n- Improving the error handling and retry logic in the 'run_python_snippet' tool or the agent's usage of it.\n\nFocus on Correctness and Robustness of the generated code.\n", "user": "# Current Program Information\n- Fitness: 0.5353\n- Feature coordinates: combined_score=0.54, latency=38.03\n- Focus areas: - Fitness unchanged at 0.5353\n- Exploring combined_score=0.54, latency=38.03 region of solution space\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: combined_score: 0.5353, latency: 38.0293, artifacts: {'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.55, 'latency': 19.38530969619751, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.5}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.5, 'latency': 26.569865703582764, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.5800000000000001, 'latency': 18.542023181915283, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.45, 'latency': 23.256146907806396, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.16666666666666666}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.76, 'latency': 47.44441866874695, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.2}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.6, 'latency': 92.97801899909973, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6666666666666666}], 'avg_latency': 38.02929719289144}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.5353)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\n\n\n\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n\n\ndef _build_rag_agent(model: str | LiteLlm) -> LlmAgent:\n    rag_toolset = MCPToolset(\n        connection_params=SseConnectionParams(\n            url=_rag_mcp_url(),\n            timeout=300,\n        )\n    )\n    return LlmAgent(\n        name=\"RagAgent\",\n        model=model,\n        instruction=(\n            \"Answer user questions about Google ADK using the MCP RAG tool. \"\n            \"If the question has multiple concepts, split into 2-3 focused subqueries, \"\n            \"call the MCP tool for each, and synthesize a single answer. \"\n            \"If the user asks for code, include a Python code block. \"\n            \"Only use ADK APIs that appear in the provided documentation. \"\n            \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n            \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n            \"Do not include commented-out calls to non-existent methods; omit the call entirely.\"\n        ),\n        tools=[rag_toolset],\n    )\n\n\ndef _build_root_agent(model: str | LiteLlm) -> LlmAgent:\n    rag_agent = _build_rag_agent(model)\n    rag_tool = AgentTool(agent=rag_agent)\n    check_tool = FunctionTool(func=run_python_snippet)\n\n    return LlmAgent(\n        name=\"RootAgent\",\n        model=model,\n        instruction=(\n            \"You are the main coordinator. For every user query, call the RAG tool. \"\n            \"If the RagAgent response includes a Python code block, run a minimal \"\n            \"import/instantiation check using the code-check tool before responding. \"\n            \"If the check fails, reformulate the query and call the RAG tool again, \"\n            \"then re-check once before responding. \"\n            \"Do not return commented-out calls to non-existent methods.\"\n        ),\n        tools=[rag_tool, check_tool],\n    )\n\n\nroot_agent = _build_root_agent(_resolve_llm_model())\n\n```\nKey features: Performs well on combined_score (0.5353), Performs well on latency (38.0293), Performs well on artifacts ({'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.55, 'latency': 19.38530969619751, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.5}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.5, 'latency': 26.569865703582764, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.5800000000000001, 'latency': 18.542023181915283, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.45, 'latency': 23.256146907806396, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.16666666666666666}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.76, 'latency': 47.44441866874695, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.2}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.6, 'latency': 92.97801899909973, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6666666666666666}], 'avg_latency': 38.02929719289144})\n\n\n\n# Current Program\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\n\n\n\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n\n\ndef _build_rag_agent(model: str | LiteLlm) -> LlmAgent:\n    rag_toolset = MCPToolset(\n        connection_params=SseConnectionParams(\n            url=_rag_mcp_url(),\n            timeout=300,\n        )\n    )\n    return LlmAgent(\n        name=\"RagAgent\",\n        model=model,\n        instruction=(\n            \"Answer user questions about Google ADK using the MCP RAG tool. \"\n            \"If the question has multiple concepts, split into 2-3 focused subqueries, \"\n            \"call the MCP tool for each, and synthesize a single answer. \"\n            \"If the user asks for code, include a Python code block. \"\n            \"Only use ADK APIs that appear in the provided documentation. \"\n            \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n            \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n            \"Do not include commented-out calls to non-existent methods; omit the call entirely.\"\n        ),\n        tools=[rag_toolset],\n    )\n\n\ndef _build_root_agent(model: str | LiteLlm) -> LlmAgent:\n    rag_agent = _build_rag_agent(model)\n    rag_tool = AgentTool(agent=rag_agent)\n    check_tool = FunctionTool(func=run_python_snippet)\n\n    return LlmAgent(\n        name=\"RootAgent\",\n        model=model,\n        instruction=(\n            \"You are the main coordinator. For every user query, call the RAG tool. \"\n            \"If the RagAgent response includes a Python code block, run a minimal \"\n            \"import/instantiation check using the code-check tool before responding. \"\n            \"If the check fails, reformulate the query and call the RAG tool again, \"\n            \"then re-check once before responding. \"\n            \"Do not return commented-out calls to non-existent methods.\"\n        ),\n        tools=[rag_tool, check_tool],\n    )\n\n\nroot_agent = _build_root_agent(_resolve_llm_model())\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: combined_score, latency\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["<<<<<<< SEARCH\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n=======\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Improved error handling and added retry logic for transient errors.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    max_retries = 2\n    for attempt in range(max_retries):\n        with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n            handle.write(code)\n            path = handle.name\n\n        try:\n            result = subprocess.run(\n                [sys.executable, path],\n                capture_output=True,\n                text=True,\n                timeout=10,\n            )\n            if result.returncode == 0:\n                # Success\n                break\n            else:\n                # Check for common transient errors in stderr\n                stderr_lower = result.stderr.lower()\n                if any(err in stderr_lower for err in [\"resource temporarily unavailable\", \"too many open files\"]):\n                    # Retry if transient error detected\n                    continue\n                else:\n                    # Non-recoverable error, break and report\n                    break\n        except subprocess.TimeoutExpired:\n            return {\"ok\": False, \"error\": \"Execution timed out.\"}\n        finally:\n            try:\n                os.unlink(path)\n            except OSError:\n                pass\n    else:\n        # If retries exhausted\n        return {\"ok\": False, \"error\": \"Execution failed after retries.\"}\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\ndef _build_rag_agent(model: str | LiteLlm) -> LlmAgent:\n    rag_toolset = MCPToolset(\n        connection_params=SseConnectionParams(\n            url=_rag_mcp_url(),\n            timeout=300,\n        )\n    )\n    return LlmAgent(\n        name=\"RagAgent\",\n        model=model,\n        instruction=(\n            \"Answer user questions about Google ADK using the MCP RAG tool. \"\n            \"If the question has multiple concepts, split into 2-3 focused subqueries, \"\n            \"call the MCP tool for each, and synthesize a single answer. \"\n            \"If the user asks for code, include a Python code block. \"\n            \"Only use ADK APIs that appear in the provided documentation. \"\n            \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n            \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n            \"Do not include commented-out calls to non-existent methods; omit the call entirely.\"\n        ),\n        tools=[rag_toolset],\n    )\n=======\ndef _build_rag_agent(model: str | LiteLlm) -> LlmAgent:\n    rag_toolset = MCPToolset(\n        connection_params=SseConnectionParams(\n            url=_rag_mcp_url(),\n            timeout=300,\n        )\n    )\n    return LlmAgent(\n        name=\"RagAgent\",\n        model=model,\n        instruction=(\n            \"You are a knowledgeable assistant about Google ADK and related tools. \"\n            \"For each user question, identify distinct concepts and split them into 2-3 focused subqueries. \"\n            \"Call the MCP tool for each subquery and synthesize a clear, concise, and accurate single answer. \"\n            \"If code is requested, provide a properly formatted Python code block. \"\n            \"Only use documented ADK APIs; do not invent convenience methods like agent.chat, agent.run, or agent.invoke. \"\n            \"Follow the Runner/Invocation patterns as shown in official ADK docs for code execution. \"\n            \"Avoid including any commented-out calls to non-existent methods; omit such calls entirely.\"\n        ),\n        tools=[rag_toolset],\n    )\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\ndef _build_root_agent(model: str | LiteLlm) -> LlmAgent:\n    rag_agent = _build_rag_agent(model)\n    rag_tool = AgentTool(agent=rag_agent)\n    check_tool = FunctionTool(func=run_python_snippet)\n\n    return LlmAgent(\n        name=\"RootAgent\",\n        model=model,\n        instruction=(\n            \"You are the main coordinator. For every user query, call the RAG tool. \"\n            \"If the RagAgent response includes a Python code block, run a minimal \"\n            \"import/instantiation check using the code-check tool before responding. \"\n            \"If the check fails, reformulate the query and call the RAG tool again, \"\n            \"then re-check once before responding. \"\n            \"Do not return commented-out calls to non-existent methods.\"\n        ),\n        tools=[rag_tool, check_tool],\n    )\n=======\ndef _build_root_agent(model: str | LiteLlm) -> LlmAgent:\n    rag_agent = _build_rag_agent(model)\n    rag_tool = AgentTool(agent=rag_agent)\n    check_tool = FunctionTool(func=run_python_snippet)\n\n    return LlmAgent(\n        name=\"RootAgent\",\n        model=model,\n        instruction=(\n            \"You are the main coordinating agent. For each user query, first call the RAG tool. \"\n            \"If the response from RagAgent contains a Python code block, extract it and run a minimal \"\n            \"import and instantiation check using the code-check tool before replying to the user. \"\n            \"If the code check fails, reformulate the query with additional clarification or corrections and call the RAG tool again. \"\n            \"Perform one retry of code validation before responding. \"\n            \"Ensure the final response contains no commented-out calls to non-existent methods. \"\n            \"Provide clear, concise, and runnable Python code when requested.\"\n        ),\n        tools=[rag_tool, check_tool],\n    )\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n=======\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    # Use a more robust default model for better code generation\n    default_model = \"gpt-4.1-nano\"\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model or default_model}\")\n    return model or default_model\n>>>>>>> REPLACE"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}