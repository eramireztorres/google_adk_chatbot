{"id": "711c5cc6-8645-4190-867c-f0927195b642", "code": "from __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.tool_context import ToolContext\n\n# Compose a SequentialAgent that explicitly splits planning, querying, code-checking, and synthesis steps\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"if it contains multiple concepts, split it into 2-3 focused subqueries. \"\n        \"Return a JSON array of subqueries. If only one concept, return a single-element array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user requests code, include a Python code block. \"\n        \"Only use ADK APIs documented. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the rag_response for Python code blocks. For each code block, \"\n        \"run the code-check tool to validate imports and instantiations. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'. \"\n        \"If no code blocks are present, respond with 'NO_CODE'. \"\n        \"Output only one of these three strings exactly, no other text.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize the final answer by combining rag_response. \"\n        \"If code_check_result is 'CHECK_PASSED' or 'NO_CODE', include code blocks in the answer if any. \"\n        \"If 'CHECK_FAILED', say you are retrying and do not include code blocks. \"\n        \"Keep the answer concise and user-friendly.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nrag_agent = SequentialAgent(\n    name=\"RagAgentWorkflow\",\n    sub_agents=[\n        planning_agent,\n        query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n)\n\n# Add output_key to propagate final_answer to state for easy access by root agent if needed\nrag_agent = LoopAgent(\n    name=\"RagAgentWithRetry\",\n    sub_agents=[rag_agent],\n    max_iterations=2,\n    output_key=\"final_answer\",\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Sanitize code to prevent dangerous operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (basic heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\", \"__import__\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip() if result.stdout else \"\",\n        \"stderr\": result.stderr.strip() if result.stderr else \"\",\n    }\n    # Escalate to exit LoopAgent early if code check fails\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\n# Add a before_model_callback to log agent start for observability\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.genai import types\nfrom typing import Optional\n\ndef before_agent_callback(ctx: CallbackContext, req: types.LlmRequest) -> Optional[types.LlmResponse]:\n    logging.info(f\"Agent '{ctx.agent.name}' is starting with prompt: {req.prompt[:100]}...\")\n    return None\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. For every user query, call the RAG agent workflow. \"\n        \"If the response contains Python code blocks, run the code-check tool to validate imports and instantiations. \"\n        \"If the code check fails, instruct the RAG agent workflow to retry once with a reformulated answer. \"\n        \"Only respond with the final validated answer. \"\n        \"Avoid including commented-out code or calls to non-existent methods. \"\n        \"Respond concisely and clearly.\"\n    ),\n    tools=[AgentTool(agent=rag_agent), FunctionTool(func=run_python_snippet)],\n    output_key=\"final_answer\",\n    before_model_callback=before_agent_callback,\n)\n\n", "language": "python", "parent_id": "685dab5b-0aac-4446-bbbf-ba493b17bef8", "generation": 4, "timestamp": 1769341067.6160004, "iteration_found": 56, "metrics": {"combined_score": 0.0, "error": "1 validation error for LoopAgent\noutput_key\n  Extra inputs are not permitted [type=extra_forbidden, input_value='final_answer', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden", "artifacts": {"traceback": "Traceback (most recent call last):\n  File \"/home/erick/repo/google_adk_chatbot/chatbot/ADK_assistant/openevolve_experiments/evaluator.py\", line 117, in evaluate\n    spec.loader.exec_module(candidate_module)\n    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap_external>\", line 1026, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/tmp/tmp2g0s_cr6.py\", line 132, in <module>\n    rag_agent = LoopAgent(\n        name=\"RagAgentWithRetry\",\n    ...<2 lines>...\n        output_key=\"final_answer\",\n    )\n  File \"/home/erick/repo/google_adk_chatbot/venv/lib/python3.13/site-packages/pydantic/main.py\", line 250, in __init__\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\npydantic_core._pydantic_core.ValidationError: 1 validation error for LoopAgent\noutput_key\n  Extra inputs are not permitted [type=extra_forbidden, input_value='final_answer', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden\n"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 12 lines with 13 lines\nChange 2: Replace 12 lines with 13 lines\nChange 3: Replace 24 lines with 26 lines\nChange 4: Replace 47 lines with 51 lines\nChange 5: Replace 14 lines with 24 lines\nChange 6: Replace 14 lines with 16 lines", "parent_metrics": {"combined_score": 0.0, "error": "1 validation error for LoopAgent\noutput_key\n  Extra inputs are not permitted [type=extra_forbidden, input_value='final_answer', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden", "artifacts": {"traceback": "Traceback (most recent call last):\n  File \"/home/erick/repo/google_adk_chatbot/chatbot/ADK_assistant/openevolve_experiments/evaluator.py\", line 117, in evaluate\n    spec.loader.exec_module(candidate_module)\n    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap_external>\", line 1026, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/tmp/tmp65ocey9s.py\", line 131, in <module>\n    rag_agent = LoopAgent(\n        name=\"RagAgentWithRetry\",\n    ...<2 lines>...\n        output_key=\"final_answer\",\n    )\n  File \"/home/erick/repo/google_adk_chatbot/venv/lib/python3.13/site-packages/pydantic/main.py\", line 250, in __init__\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\npydantic_core._pydantic_core.ValidationError: 1 validation error for LoopAgent\noutput_key\n  Extra inputs are not permitted [type=extra_forbidden, input_value='final_answer', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden\n"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert ADK Architect optimizing an agent for Python code generation.\nThe agent instructions and tool usage are key areas to optimize.\nEncourage the exploration of:\n- Different and more robust agent instructions.\n- Creating separate specialized agents if necessary (e.g. valid for creating/running agents vs using tools).\nAlso, you are free to improve 'initial_program.py' using these advanced ADK patterns:\n\n1. **Workflow Agents** (deterministic coordination):\n   - `SequentialAgent(name=str, sub_agents=[agent1, agent2], description=str)`: Linear pipelines (e.g., Plan -> Code -> Review).\n   - `LoopAgent(name=str, sub_agents=[...], max_iterations=int)`: Iterative tasks (e.g., Generate -> Test -> Fix).\n   - `ParallelAgent(name=str, sub_agents=[...])`: Concurrent execution (e.g., Research multiple topics).\n\n2. **State & Control**:\n   - **Shared State**: `InvocationContext` is shared. Access via `tool_context.state` (in tools) or `callback_context.state` (in callbacks).\n   - **Loop Escalation**: To exit a `LoopAgent` early from a tool, use:\n     ```python\n     def exit_tool(tool_context: ToolContext):\n         tool_context.actions.escalate = True\n         return {\"status\": \"exiting\"}\n     ```\n   - **Data Flow**: Use `output_key=\"my_key\"` in `LlmAgent` to automatically write its output to state.\n\n3. **Callbacks & Imports** (Cheat Sheet):\n   - **Imports**:\n     ```python\n     from google.adk.agents import LlmAgent, Action\n     from google.adk.agents.callback_context import CallbackContext\n     from google.adk.tool import ToolContext\n     from google.adk.runners import InMemoryRunner\n     from google.genai import types\n     from typing import Optional\n     ```\n   - **Signatures**:\n     - `def my_cb(ctx: CallbackContext, req: LlmRequest) -> Optional[LlmResponse]: ...`\n   - **Usage**: `LlmAgent(..., before_model_callback=my_cb)`\n\n4. **Custom Agents** (Deterministic Logic):\n   - Subclass `BaseAgent` for complex orchestration logic not covered by standard workflows.\n   - Implement `async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:`.\n   - Yield events from sub-agents: `async for event in self.sub_agent.run_async(ctx): yield event`.\n\n5. **Constraints**:\n   - `root_agent` MUST be an `LlmAgent` (not deterministic). It acts as the intelligent entry point.\n   - Ensure generated Python code is robust, self-contained, and uses these ADK patterns correctly.\n", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.5314 \u2192 0.0000. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 15 lines with 64 lines\nChange 2: Replace 34 lines with 38 lines\nChange 3: Replace 16 lines with 19 lines\n- Metrics: combined_score: 0.5314, latency: 35.2564, artifacts: {'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.5, 'latency': 53.40760922431946, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.5, 'latency': 32.95418953895569, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.5800000000000001, 'latency': 31.257057666778564, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.65, 'latency': 36.97488808631897, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8333333333333334}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.52, 'latency': 32.2972366809845, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.4}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.65, 'latency': 24.64751362800598, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8333333333333334}], 'avg_latency': 35.256415804227196}\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Change 1: Replace 15 lines with 61 lines\nChange 2: Replace 34 lines with 41 lines\nChange 3: Replace 13 lines with 13 lines\n- Metrics: combined_score: 0.6283, latency: 31.7398, artifacts: {'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.45, 'latency': 24.607950448989868, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.16666666666666666}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.7999999999999999, 'latency': 46.1371853351593, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.5800000000000001, 'latency': 33.79699158668518, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.4, 'latency': 33.02373433113098, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.0}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.8799999999999999, 'latency': 47.49162840843201, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.6}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.85, 'latency': 5.381503105163574, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.5}], 'avg_latency': 31.739832202593487}\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace 24 lines with 70 lines\nChange 2: Replace 42 lines with 50 lines\nChange 3: Replace 12 lines with 14 lines\n- Metrics: combined_score: 0.6284, latency: 76.5532, artifacts: {'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.65, 'latency': 50.38360857963562, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8333333333333334}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.7999999999999999, 'latency': 112.34088468551636, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.8799999999999999, 'latency': 95.99157357215881, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.6}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.0, 'latency': 20.13335156440735, 'code_extracted': False, 'exec_success': False, 'keyword_match': 0.0}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 1.0, 'latency': 112.4048523902893, 'code_extracted': True, 'exec_success': True, 'keyword_match': 1.0}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.8999999999999999, 'latency': 68.0646824836731, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.6666666666666666}], 'avg_latency': 76.55315887928009}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.6284)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\n\n# Define specialized sub-agents for planning, querying, code check, and synthesis in a SequentialAgent pipeline\n\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent specialized in analyzing user questions about Google ADK. \"\n        \"If the question involves multiple distinct concepts, split it into 2-3 focused and concise subqueries. \"\n        \"Return only a valid JSON array of strings representing these subqueries. \"\n        \"If only one concept is present, return a single-element array with that query.\"\n        \"Do not add any explanations or extra text outside the JSON array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer each focused query about Google ADK by using the MCP RAG toolset. \"\n        \"If the user requests code, include Python code blocks with correct syntax. \"\n        \"Use only the ADK APIs explicitly documented. \"\n        \"Do not invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Demonstrate usage following the Runner/Invocation patterns as shown in the official ADK documentation. \"\n        \"Output only the answer content and code blocks, without extra commentary.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Analyze the rag_response output and extract all Python code blocks. \"\n        \"For each code block, call the code-check tool to validate correct imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond strictly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass, respond strictly with 'CHECK_PASSED'. \"\n        \"Do not add any other text or explanations.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Produce the final concise answer by synthesizing the rag_response content. \"\n        \"If code_check_result is 'CHECK_PASSED', include all valid Python code blocks inline. \"\n        \"If code_check_result is 'CHECK_FAILED', respond with a short message indicating that you are retrying due to code validation failure, \"\n        \"but do not include code blocks. \"\n        \"Ensure the response is self-contained and user-ready, without internal agent notes.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nbase_rag_agent = SequentialAgent(\n    name=\"RagAgentPipeline\",\n    sub_agents=[planning_agent, query_agent, code_check_agent, synthesizer_agent],\n    description=\"Pipeline: plan query, check code, synthesize answer\",\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentWithRetry\",\n    sub_agents=[base_rag_agent],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit loops if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (basic heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\", \"__import__\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to avoid abuse and long runs\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        # Escalate to exit LoopAgent early if used in loop\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, invoke the RagAgentWithRetry workflow. \"\n        \"Use the LoopAgent to retry once if code validation fails. \"\n        \"When the RagAgentWithRetry returns Python code blocks, use the code-check tool to validate imports and instantiations. \"\n        \"If validation fails, instruct the RagAgentWithRetry to reformulate the answer and retry once. \"\n        \"Only respond with the final validated answer content. \"\n        \"Avoid commented-out or non-existent method calls in your responses.\"\n    ),\n    tools=[AgentTool(agent=rag_agent), check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nKey features: Performs well on combined_score (0.6284), Performs well on latency (76.5532), Performs well on artifacts ({'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.65, 'latency': 50.38360857963562, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8333333333333334}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.7999999999999999, 'latency': 112.34088468551636, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.8799999999999999, 'latency': 95.99157357215881, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.6}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.0, 'latency': 20.13335156440735, 'code_extracted': False, 'exec_success': False, 'keyword_match': 0.0}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 1.0, 'latency': 112.4048523902893, 'code_extracted': True, 'exec_success': True, 'keyword_match': 1.0}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.8999999999999999, 'latency': 68.0646824836731, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.6666666666666666}], 'avg_latency': 76.55315887928009})\n\n### Program 2 (Score: 0.6283)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\n\n# Split the rag_agent into a SequentialAgent workflow with planning, querying, code-checking, and synthesis steps\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"if it contains multiple concepts, split it into 2-3 focused subqueries. \"\n        \"Return the list of subqueries in a JSON array format. If only one concept, return single-element array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the rag_response for Python code blocks. For each code block, \"\n        \"run the code-check tool to validate imports and instantiation. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize the final answer by combining rag_response. \"\n        \"If code_check_result is 'CHECK_PASSED', include code blocks in the answer. \"\n        \"If 'CHECK_FAILED', say you are retrying.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[\n        planning_agent,\n        query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit loops if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. Given a user query, use the RagAgentLoop workflow \"\n        \"to plan, query, check code, and synthesize a final answer. \"\n        \"If code check fails, the loop allows retrying once. \"\n        \"Return only the final synthesized answer. \"\n        \"Avoid commented-out or non-existent method calls.\"\n    ),\n    tools=[AgentTool(agent=rag_agent), check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nKey features: Performs well on combined_score (0.6283), Performs well on latency (31.7398), Performs well on artifacts ({'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.45, 'latency': 24.607950448989868, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.16666666666666666}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.7999999999999999, 'latency': 46.1371853351593, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.5800000000000001, 'latency': 33.79699158668518, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.4, 'latency': 33.02373433113098, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.0}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.8799999999999999, 'latency': 47.49162840843201, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.6}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.85, 'latency': 5.381503105163574, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.5}], 'avg_latency': 31.739832202593487})\n\n### Program 3 (Score: 0.5314)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent\n\n# Create specialized agents for planning, querying, code checking and synthesis to improve robustness and clarity\n\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"if it contains multiple concepts, split it into 2-3 focused subqueries. \"\n        \"Return the list of subqueries in a JSON array format. If only one concept, return single-element array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the RAG response for Python code blocks. For each code block, \"\n        \"run the code snippet checker tool to validate imports and instantiation. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'.\"\n    ),\n    tools=[],\n    output_key=\"check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize the final answer by combining the RAG responses to the subqueries. \"\n        \"If code was checked and passed, include the code blocks in the answer. \"\n        \"If code check failed, say you are retrying. \"\n        \"Keep the answer concise and relevant.\"\n    ),\n    output_key=\"final_answer\",\n)\n\n# Define a loop agent to allow retrying query and code check once if code check fails\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[\n        planning_agent,\n        query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\n# Attach code check tool explicitly only to the code_check_agent, and rag_toolset to query_agent\n# But ADK does not support partial tool assignment yet - workaround by passing all tools but instructions limit tool usage\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. Given a user query, use the RagAgentLoop workflow \"\n        \"to plan, query, check code, and synthesize a final answer. \"\n        \"If code check fails, the loop allows retrying once. \"\n        \"Return only the final synthesized answer. \"\n        \"Avoid commented-out or non-existent method calls.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nKey features: Performs well on combined_score (0.5314), Performs well on latency (35.2564), Performs well on artifacts ({'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.5, 'latency': 53.40760922431946, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.5, 'latency': 32.95418953895569, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.5800000000000001, 'latency': 31.257057666778564, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.65, 'latency': 36.97488808631897, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8333333333333334}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.52, 'latency': 32.2972366809845, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.4}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.65, 'latency': 24.64751362800598, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8333333333333334}], 'avg_latency': 35.256415804227196})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.5243)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\n\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"if it contains multiple concepts, split it into 2-3 focused subqueries. \"\n        \"Return the list of subqueries in a JSON array format. If only one concept, return single-element array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the rag_response for Python code blocks. For each code block, \"\n        \"run the code snippet checker tool to validate imports and instantiations. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize the final answer by combining rag_response. \"\n        \"If code_check_result is 'CHECK_PASSED', include code blocks in the answer. \"\n        \"If 'CHECK_FAILED', say you are retrying.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[\n        planning_agent,\n        query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit loops if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. Given a user query, use the RagAgentLoop workflow \"\n        \"to plan, query, check code, and synthesize a final answer. \"\n        \"If code check fails, the loop allows retrying once. \"\n        \"Return only the final synthesized answer. \"\n        \"Avoid commented-out or non-existent method calls.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to latency\n\n### Program D2 (Score: 0.5281)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import LoopAgent, LlmAgent\n\n# Wrap the rag_agent in a LoopAgent for retry logic on code check failure\nbase_rag_agent = LlmAgent(\n    name=\"RagAgent\",\n    model=model,\n    instruction=(\n        \"Answer user questions about Google ADK using the MCP RAG tool. \"\n        \"If the question has multiple concepts, split into 2-3 focused subqueries, \"\n        \"call the MCP tool for each, and synthesize a single answer. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n        \"Do not include commented-out calls to non-existent methods; omit the call entirely.\"\n    ),\n    tools=[rag_toolset],\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[base_rag_agent],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit loops if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Limit snippet size to avoid abuse and long runs\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        # Escalate to exit LoopAgent early if used in loop\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, delegate to the RAG loop agent. \"\n        \"When the RAG agent returns Python code blocks, use the code-check tool to validate imports and instantiations. \"\n        \"If validation fails, instruct the RAG agent to reformulate the answer and retry once. \"\n        \"Only return finalized answers after successful code validation. \"\n        \"Avoid commented-out or non-existent method calls in your responses.\"\n    ),\n    tools=[rag_tool, check_tool],\n)\n\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to latency\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.6284, Type: Alternative)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\n\n# Define specialized sub-agents for planning, querying, code check, and synthesis in a SequentialAgent pipeline\n\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent specialized in analyzing user questions about Google ADK. \"\n        \"If the question involves multiple distinct concepts, split it into 2-3 focused and concise subqueries. \"\n        \"Return only a valid JSON array of strings representing these subqueries. \"\n        \"If only one concept is present, return a single-element array with that query.\"\n        \"Do not add any explanations or extra text outside the JSON array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer each focused query about Google ADK by using the MCP RAG toolset. \"\n        \"If the user requests code, include Python code blocks with correct syntax. \"\n        \"Use only the ADK APIs explicitly documented. \"\n        \"Do not invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Demonstrate usage following the Runner/Invocation patterns as shown in the official ADK documentation. \"\n        \"Output only the answer content and code blocks, without extra commentary.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Analyze the rag_response output and extract all Python code blocks. \"\n        \"For each code block, call the code-check tool to validate correct imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond strictly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass, respond strictly with 'CHECK_PASSED'. \"\n        \"Do not add any other text or explanations.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Produce the final concise answer by synthesizing the rag_response content. \"\n        \"If code_check_result is 'CHECK_PASSED', include all valid Python code blocks inline. \"\n        \"If code_check_result is 'CHECK_FAILED', respond with a short message indicating that you are retrying due to code validation failure, \"\n        \"but do not include code blocks. \"\n        \"Ensure the response is self-contained and user-ready, without internal agent notes.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nbase_rag_agent = SequentialAgent(\n    name=\"RagAgentPipeline\",\n    sub_agents=[planning_agent, query_agent, code_check_agent, synthesizer_agent],\n    description=\"Pipeline: plan query, check code, synthesize answer\",\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentWithRetry\",\n    sub_agents=[base_rag_agent],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit loops if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (basic heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\", \"__import__\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to avoid abuse and long runs\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        # Escalate to exit LoopAgent early if used in loop\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, invoke the RagAgentWithRetry workflow. \"\n        \"Use the LoopAgent to retry once if code validation fails. \"\n        \"When the RagAgentWithRetry returns Python code blocks, use the code-check tool to validate imports and instantiations. \"\n        \"If validation fails, instruct the RagAgentWithRetry to reformulate the answer and retry once. \"\n        \"Only respond with the final validated answer content. \"\n        \"Avoid commented-out or non-existent method calls in your responses.\"\n    ),\n    tools=[AgentTool(agent=rag_agent), check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Comprehensive implementation\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\n\n# Compose a LoopAgent workflow for robust retry on code check failure, splitting planning, querying, code check and synthesis\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"if it contains multiple concepts, split it into 2-3 focused subqueries. \"\n        \"Return the list of subqueries in JSON array format. If only one, return a single-element array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nrag_query_agent = LlmAgent(\n    name=\"RagQueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs documented in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution. \"\n        \"Return the answer in markdown format with code blocks properly fenced.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect rag_response for Python code blocks. For each code block, \"\n        \"run the code snippet checker tool to validate imports and instantiation. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise, respond 'CHECK_PASSED'. \"\n        \"Use the check_tool only for code validation and do not perform other tasks.\"\n    ),\n    tools=[check_tool],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize the final answer by combining rag_response from all subqueries. \"\n        \"If code check result is CHECK_PASSED, include code blocks in the answer. \"\n        \"If CHECK_FAILED, clearly indicate you are retrying with a reformulated answer. \"\n        \"Keep the answer concise, clear, and free of speculative or unverifiable content.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nrag_agent_workflow = SequentialAgent(\n    name=\"RagAgentWorkflow\",\n    sub_agents=[\n        planning_agent,\n        rag_query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[rag_agent_workflow],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in a subprocess to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Limit snippet size to prevent abuse.\n    Abort early if code contains dangerous imports or system calls.\n    If code execution fails, escalate to exit any LoopAgent early.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    # Security check: forbid dangerous or disruptive code patterns\n    forbidden_patterns = [\"import os\", \"import sys\", \"subprocess\", \"eval(\", \"exec(\", \"open(\"]\n    if any(pattern in code for pattern in forbidden_patterns):\n        return {\"ok\": False, \"error\": \"Code contains forbidden operations.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LoopAgent(\n    name=\"RootAgent\",\n    sub_agents=[\n        rag_agent,\n        LlmAgent(\n            name=\"CodeValidationAgent\",\n            model=model,\n            instruction=(\n                \"Given the response from RagAgent, detect if there is a Python code block. \"\n                \"If present, extract each code block and run the code-check tool to validate imports and instantiations. \"\n                \"If any check fails, escalate to rerun RagAgent with a reformulated query. \"\n                \"If no code blocks are present, or all pass, approve the response. \"\n                \"Return a concise status indicating 'CHECK_PASSED' or 'CHECK_FAILED'.\"\n            ),\n            tools=[check_tool],\n            output_key=\"code_check_result\",\n        ),\n    ],\n    max_iterations=2,\n    instruction=(\n        \"Run RagAgent and validate Python code blocks iteratively, retrying once on failure. \"\n        \"If code check fails, the LoopAgent should escalate to retry. \"\n        \"Only return the final validated answer.\"\n    ),\n    output_key=\"final_answer\",\n)\n\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Comprehensive implementation\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent\n\n# Compose a SequentialAgent workflow with explicit input/output data flow via InvocationContext state\n\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given the user question in state['user_query'], \"\n        \"analyze carefully to identify 2-3 distinct focused subqueries if multiple concepts exist. \"\n        \"Return a JSON array of subqueries. Save as state['subqueries']. \"\n        \"If only one concept, return a single-element array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nrag_query_agent = LlmAgent(\n    name=\"RagQueryAgent\",\n    model=model,\n    instruction=(\n        \"For each query in state['subqueries'], use the MCP RAG tool to provide accurate answers about Google ADK. \"\n        \"Include Python code blocks only if the user explicitly requests code. \"\n        \"Strictly use only ADK APIs documented in the provided resources. \"\n        \"Avoid inventing convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK documentation. \"\n        \"Aggregate and save all answers in state['rag_response'].\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect state['rag_response'] carefully for Python code blocks. For each code block, invoke the code snippet checker tool \"\n        \"to validate imports and instantiations. If any check fails, respond with 'CHECK_FAILED', else respond 'CHECK_PASSED'. \"\n        \"Save the result in state['code_check_result'].\"\n    ),\n    tools=[check_tool],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize a clear and concise final answer by combining state['rag_response']. \"\n        \"If state['code_check_result'] == 'CHECK_PASSED', include the validated code blocks in your answer. \"\n        \"If state['code_check_result'] is 'CHECK_FAILED', clearly state that you are retrying.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nrag_agent = SequentialAgent(\n    name=\"RagAgent\",\n    sub_agents=[\n        planning_agent,\n        rag_query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Limit snippet size to prevent abuse.\n    Basic sanitization to disallow dangerous operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    # Basic blacklist for dangerous keywords to improve safety\n    forbidden_keywords = [\"import os\", \"import sys\", \"subprocess\", \"eval(\", \"exec(\"]\n    if any(keyword in code for keyword in forbidden_keywords):\n        # Escalate to signal failure for retry logic\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Code contains forbidden operations.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        # Run in a subprocess to isolate and limit execution time\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n            check=False,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip() if result.stdout else \"\",\n        \"stderr\": result.stderr.strip() if result.stderr else \"\",\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\n# Combine rag_agent and code validation in a LoopAgent with clear retry logic and shared state\nroot_agent = LoopAgent(\n    name=\"RootAgent\",\n    sub_agents=[\n        rag_agent,\n        LlmAgent(\n            name=\"CodeValidationAgent\",\n            model=model,\n            instruction=(\n                \"Examine state['final_answer'] for Python code blocks. For each code block, \"\n                \"run the code-check tool to validate imports and instantiations. \"\n                \"If any check fails, escalate to retry RagAgent with reformulated response. \"\n                \"If all checks pass, approve the response.\"\n            ),\n            tools=[check_tool],\n            output_key=\"code_check_result\",\n        ),\n    ],\n    max_iterations=2,\n    description=(\n        \"Run RagAgent workflow and validate Python code blocks iteratively, retrying once on failure.\"\n    ),\n)\n\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Comprehensive implementation\n\n# Current Program\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.tool_context import ToolContext\n\n# Compose a SequentialAgent that explicitly splits planning, querying, code-checking, and synthesis steps\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"if it contains multiple concepts, split it into 2-3 focused subqueries. \"\n        \"Return a JSON array of subqueries. If only one concept, return a single-element array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user requests code, include a Python code block. \"\n        \"Only use ADK APIs documented. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the rag_response for Python code blocks. For each code block, \"\n        \"run the code-check tool to validate imports and instantiations. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'. \"\n        \"If no code blocks are present, respond with 'NO_CODE'.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize the final answer by combining rag_response. \"\n        \"If code_check_result is 'CHECK_PASSED' or 'NO_CODE', include code blocks in the answer if any. \"\n        \"If 'CHECK_FAILED', say you are retrying and do not include code blocks. \"\n        \"Keep the answer concise and user-friendly.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nrag_agent = SequentialAgent(\n    name=\"RagAgentWorkflow\",\n    sub_agents=[\n        planning_agent,\n        query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n)\n\n# Add output_key to propagate final_answer to state for easy access by root agent if needed\nrag_agent = LoopAgent(\n    name=\"RagAgentWithRetry\",\n    sub_agents=[rag_agent],\n    max_iterations=2,\n    output_key=\"final_answer\",\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (basic heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\", \"__import__\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    # Escalate to exit LoopAgent early if code check fails\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. For every user query, call the RAG agent workflow. \"\n        \"If the response contains Python code blocks, run the code-check tool to validate imports and instantiations. \"\n        \"If the code check fails, instruct the RAG agent workflow to retry once with a reformulated answer. \"\n        \"Only respond with the final validated answer. \"\n        \"Avoid including commented-out code or calls to non-existent methods. \"\n        \"Respond concisely and clearly.\"\n    ),\n    tools=[AgentTool(agent=rag_agent), FunctionTool(func=run_python_snippet)],\n    output_key=\"final_answer\",\n)\n\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["<<<<<<< SEARCH\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the rag_response for Python code blocks. For each code block, \"\n        \"run the code-check tool to validate imports and instantiations. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'. \"\n        \"If no code blocks are present, respond with 'NO_CODE'.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n=======\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the rag_response for Python code blocks. For each code block, \"\n        \"run the code-check tool to validate imports and instantiations. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'. \"\n        \"If no code blocks are present, respond with 'NO_CODE'. \"\n        \"Output only one of these three strings exactly, no other text.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n>>>>>>> REPLACE\n\n# Reasoning: Adding explicit instruction to output only one of the three strings exactly improves downstream parsing and control flow, reducing ambiguity.\n\n<<<<<<< SEARCH\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the rag_response for Python code blocks. For each code block, \"\n        \"run the code-check tool to validate imports and instantiations. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'. \"\n        \"If no code blocks are present, respond with 'NO_CODE'.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n=======\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the rag_response for Python code blocks. For each code block, \"\n        \"run the code-check tool to validate imports and instantiations. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'. \"\n        \"If no code blocks are present, respond with 'NO_CODE'. \"\n        \"Do not add any other text or explanation.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n>>>>>>> REPLACE\n\n# Reasoning: Reinforce strict output format to avoid extraneous text, improving parsing reliability.\n\n<<<<<<< SEARCH\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the rag_response for Python code blocks. For each code block, \"\n        \"run the code-check tool to validate imports and instantiations. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'. \"\n        \"If no code blocks are present, respond with 'NO_CODE'.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize the final answer by combining rag_response. \"\n        \"If code_check_result is 'CHECK_PASSED' or 'NO_CODE', include code blocks in the answer if any. \"\n        \"If 'CHECK_FAILED', say you are retrying and do not include code blocks. \"\n        \"Keep the answer concise and user-friendly.\"\n    ),\n    output_key=\"final_answer\",\n)\n=======\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the rag_response for Python code blocks. For each code block, \"\n        \"run the code-check tool to validate imports and instantiations. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'. \"\n        \"If no code blocks are present, respond with 'NO_CODE'. \"\n        \"Do not add any other text or explanation.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize the final answer by combining rag_response. \"\n        \"If code_check_result is 'CHECK_PASSED' or 'NO_CODE', include code blocks in the answer if any. \"\n        \"If 'CHECK_FAILED', say you are retrying and do not include code blocks. \"\n        \"Keep the answer concise and user-friendly. \"\n        \"Avoid adding speculative or unverifiable content.\"\n    ),\n    output_key=\"final_answer\",\n)\n>>>>>>> REPLACE\n\n# Reasoning: Adding instruction to avoid speculative content improves answer quality and reliability.\n\n<<<<<<< SEARCH\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (basic heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\", \"__import__\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    # Escalate to exit LoopAgent early if code check fails\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n=======\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Sanitize code to prevent dangerous operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (basic heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\", \"__import__\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip() if result.stdout else \"\",\n        \"stderr\": result.stderr.strip() if result.stderr else \"\",\n    }\n    # Escalate to exit LoopAgent early if code check fails\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n>>>>>>> REPLACE\n\n# Reasoning: Escalate on all failure conditions to ensure loop retries are triggered promptly. Also add defensive empty string fallback on stdout/stderr.\n\n<<<<<<< SEARCH\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. For every user query, call the RAG agent workflow. \"\n        \"If the response contains Python code blocks, run the code-check tool to validate imports and instantiations. \"\n        \"If the code check fails, instruct the RAG agent workflow to retry once with a reformulated answer. \"\n        \"Only respond with the final validated answer. \"\n        \"Avoid including commented-out code or calls to non-existent methods. \"\n        \"Respond concisely and clearly.\"\n    ),\n    tools=[AgentTool(agent=rag_agent), FunctionTool(func=run_python_snippet)],\n    output_key=\"final_answer\",\n)\n=======\n# Add a before_model_callback to log agent start for observability\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.genai import types\nfrom typing import Optional\n\ndef before_agent_callback(ctx: CallbackContext, req: types.LlmRequest) -> Optional[types.LlmResponse]:\n    logging.info(f\"Agent '{ctx.agent.name}' is starting with prompt: {req.prompt[:100]}...\")\n    return None\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. For every user query, call the RAG agent workflow. \"\n        \"If the response contains Python code blocks, run the code-check tool to validate imports and instantiations. \"\n        \"If the code check fails, instruct the RAG agent workflow to retry once with a reformulated answer. \"\n        \"Only respond with the final validated answer. \"\n        \"Avoid including commented-out code or calls to non-existent methods. \"\n        \"Respond concisely and clearly.\"\n    ),\n    tools=[AgentTool(agent=rag_agent), FunctionTool(func=run_python_snippet)],\n    output_key=\"final_answer\",\n    before_model_callback=before_agent_callback,\n)\n>>>>>>> REPLACE\n\n# Reasoning: Adding a before_model_callback improves observability and debugging, helping monitor agent invocations. This is a useful ADK best practice.\n\n<<<<<<< SEARCH\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. For every user query, call the RAG agent workflow. \"\n        \"If the response contains Python code blocks, run the code-check tool to validate imports and instantiations. \"\n        \"If the code check fails, instruct the RAG agent workflow to retry once with a reformulated answer. \"\n        \"Only respond with the final validated answer. \"\n        \"Avoid including commented-out code or calls to non-existent methods. \"\n        \"Respond concisely and clearly.\"\n    ),\n    tools=[AgentTool(agent=rag_agent), FunctionTool(func=run_python_snippet)],\n    output_key=\"final_answer\",\n)\n=======\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. For every user query, call the RAG agent workflow. \"\n        \"If the response contains Python code blocks, run the code-check tool to validate imports and instantiations. \"\n        \"If the code check fails, instruct the RAG agent workflow to retry once with a reformulated answer. \"\n        \"Only respond with the final validated answer. \"\n        \"Avoid including commented-out code or calls to non-existent methods. \"\n        \"Respond concisely and clearly.\"\n    ),\n    tools=[AgentTool(agent=rag_agent), FunctionTool(func=run_python_snippet)],\n    output_key=\"final_answer\",\n    # Added a modest temperature to encourage variability but maintain coherence\n    temperature=0.3,\n)\n>>>>>>> REPLACE\n\n# Reasoning: Explicitly set a mild temperature (e.g., 0.3) to balance creativity and determinism, improving answer quality and robustness."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}