{"id": "c06e96a3-11a8-48c7-909a-9cee6187ed3e", "code": "from __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent\n\n# Create specialized agents for planning, querying, code checking and synthesis to improve robustness and clarity\n\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"carefully analyze if it contains multiple distinct concepts. \"\n        \"Split the question into 2-3 focused, concise subqueries if multiple concepts exist, \"\n        \"and return them as a JSON array. If only one concept, return a single-element array. \"\n        \"Return ONLY the JSON array with no extra text or explanation.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user requests code, include complete, runnable Python code blocks. \"\n        \"Use only ADK APIs explicitly documented in the official docs. \"\n        \"Do NOT invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Demonstrate usage strictly following the Runner/Invocation patterns shown in ADK documentation. \"\n        \"Respond ONLY with the answer content and code blocks; no extra commentary.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Carefully parse the rag_response output and extract every Python code block present. \"\n        \"For each code block, use the code snippet checker tool to validate imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond exactly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass validation or if no code blocks are found, respond exactly with 'CHECK_PASSED'. \"\n        \"Do NOT include any other text or explanation.\"\n    ),\n    tools=[],\n    output_key=\"check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Produce the final concise answer by synthesizing the rag_response content. \"\n        \"If code check result is 'CHECK_PASSED', include all valid Python code blocks inline. \"\n        \"If code check result is 'CHECK_FAILED', respond with a short message indicating retry due to code validation failure, \"\n        \"but do NOT include any code blocks. \"\n        \"Ensure the response is self-contained, user-ready, and free of internal notes.\"\n    ),\n    output_key=\"final_answer\",\n)\n\n# Define a loop agent to retry the sequence once if code check fails\nbase_rag_agent = SequentialAgent(\n    name=\"RagAgentPipeline\",\n    sub_agents=[planning_agent, query_agent, code_check_agent, synthesizer_agent],\n    description=\"Pipeline: plan query, code check, synthesize\",\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[base_rag_agent],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Execute a small Python snippet to validate imports, syntax, and simple instantiations.\n    Avoid running long or unsafe code. Escalate early to exit LoopAgent if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Basic security: disallow dangerous imports or calls\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\", \"__import__\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' detected in code snippet.\"}\n\n    # Limit snippet length to prevent abuse\n    if len(code) > 1000:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as tmp_file:\n        tmp_file.write(code)\n        path = tmp_file.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip() if result.stdout else \"\",\n        \"stderr\": result.stderr.strip() if result.stderr else \"\",\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\n# Attach code check tool explicitly only to the code_check_agent, and rag_toolset to query_agent\n# But ADK does not support partial tool assignment yet - workaround by passing all tools but instructions limit tool usage\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, orchestrate the RagAgentLoop workflow which plans, queries, \"\n        \"checks Python code, and synthesizes a final answer. If the code check fails, retry once by reformulating the answer. \"\n        \"Respond ONLY with the final validated answer content. \"\n        \"Avoid any commented-out code or calls to non-existent methods. \"\n        \"Do NOT invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Strictly use the Runner/Invocation patterns shown in ADK documentation. \"\n        \"Keep responses concise, accurate, and user-friendly.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n", "language": "python", "parent_id": "effda6c7-bc7b-47a4-871d-9109705fa63c", "generation": 4, "timestamp": 1769344273.777124, "iteration_found": 86, "metrics": {"combined_score": 0.5402179772059124, "latency": 43.11535612742106, "artifacts": {"details": [{"query": "Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.", "score": 0.5, "latency": 132.58946204185486, "code_extracted": true, "exec_success": false, "keyword_match": 0.3333333333333333}, {"query": "Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.", "score": 0.6, "latency": 28.002326011657715, "code_extracted": true, "exec_success": false, "keyword_match": 0.6666666666666666}, {"query": "Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.", "score": 0.64, "latency": 39.94667720794678, "code_extracted": true, "exec_success": false, "keyword_match": 0.8}, {"query": "Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.", "score": 0.45, "latency": 22.39903974533081, "code_extracted": true, "exec_success": false, "keyword_match": 0.16666666666666666}, {"query": "Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.", "score": 0.46, "latency": 30.702815532684326, "code_extracted": true, "exec_success": false, "keyword_match": 0.2}, {"query": "Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.", "score": 0.85, "latency": 5.05181622505188, "code_extracted": true, "exec_success": true, "keyword_match": 0.5}], "avg_latency": 43.11535612742106}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 13 lines with 13 lines\nChange 2: Replace 49 lines with 49 lines\nChange 3: Replace 13 lines with 15 lines", "parent_metrics": {"combined_score": 0.6383820996284486, "latency": 33.28456703821818, "artifacts": {"details": [{"query": "Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.", "score": 0.7, "latency": 48.86167073249817, "code_extracted": true, "exec_success": false, "keyword_match": 1.0}, {"query": "Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.", "score": 0.6, "latency": 41.50366258621216, "code_extracted": true, "exec_success": false, "keyword_match": 0.6666666666666666}, {"query": "Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.", "score": 0.64, "latency": 27.060906410217285, "code_extracted": true, "exec_success": false, "keyword_match": 0.8}, {"query": "Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.", "score": 0.55, "latency": 21.489675283432007, "code_extracted": true, "exec_success": false, "keyword_match": 0.5}, {"query": "Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.", "score": 0.64, "latency": 39.53539991378784, "code_extracted": true, "exec_success": false, "keyword_match": 0.8}, {"query": "Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.", "score": 0.8999999999999999, "latency": 21.25608730316162, "code_extracted": true, "exec_success": true, "keyword_match": 0.6666666666666666}], "avg_latency": 33.28456703821818}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert ADK Architect optimizing an agent for Python code generation.\nThe agent instructions and tool usage are key areas to optimize.\nEncourage the exploration of:\n- Different and more robust agent instructions.\n- Creating separate specialized agents if necessary (e.g. valid for creating/running agents vs using tools).\nAlso, you are free to improve 'initial_program.py' using these advanced ADK patterns:\n\n1. **Workflow Agents** (deterministic coordination):\n   - `SequentialAgent(name=str, sub_agents=[agent1, agent2], description=str)`: Linear pipelines (e.g., Plan -> Code -> Review).\n   - `LoopAgent(name=str, sub_agents=[...], max_iterations=int)`: Iterative tasks (e.g., Generate -> Test -> Fix).\n   - `ParallelAgent(name=str, sub_agents=[...])`: Concurrent execution (e.g., Research multiple topics).\n\n2. **State & Control**:\n   - **Shared State**: `InvocationContext` is shared. Access via `tool_context.state` (in tools) or `callback_context.state` (in callbacks).\n   - **Loop Escalation**: To exit a `LoopAgent` early from a tool, use:\n     ```python\n     def exit_tool(tool_context: ToolContext):\n         tool_context.actions.escalate = True\n         return {\"status\": \"exiting\"}\n     ```\n   - **Data Flow**: Use `output_key=\"my_key\"` in `LlmAgent` to automatically write its output to state.\n\n3. **Callbacks & Imports** (Cheat Sheet):\n   - **Imports**:\n     ```python\n     from google.adk.agents import LlmAgent, Action\n     from google.adk.agents.callback_context import CallbackContext\n     from google.adk.tool import ToolContext\n     from google.adk.runners import InMemoryRunner\n     from google.genai import types\n     from typing import Optional\n     ```\n   - **Signatures**:\n     - `def my_cb(ctx: CallbackContext, req: LlmRequest) -> Optional[LlmResponse]: ...`\n   - **Usage**: `LlmAgent(..., before_model_callback=my_cb)`\n\n4. **Custom Agents** (Deterministic Logic):\n   - Subclass `BaseAgent` for complex orchestration logic not covered by standard workflows.\n   - Implement `async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:`.\n   - Yield events from sub-agents: `async for event in self.sub_agent.run_async(ctx): yield event`.\n\n5. **Constraints**:\n   - `root_agent` MUST be an `LlmAgent` (not deterministic). It acts as the intelligent entry point.\n   - Ensure generated Python code is robust, self-contained, and uses these ADK patterns correctly.\n", "user": "# Current Program Information\n- Fitness: 0.6384\n- Feature coordinates: \n- Focus areas: - Fitness improved: 0.6144 \u2192 0.6384\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 5 lines with 7 lines\nChange 2: 'return result_payload' to 'return result_payload'\nChange 3: Replace 16 lines with 17 lines\nChange 4: Replace 10 lines with 12 lines\nChange 5: Replace 13 lines with 14 lines\nChange 6: Replace 11 lines with 13 lines\nChange 7: Replace 10 lines with 12 lines\nChange 8: Replace 15 lines with 11 lines\n- Metrics: combined_score: 0.6144, latency: 28.9389, artifacts: {'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.5, 'latency': 34.70959544181824, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.5, 'latency': 17.011049509048462, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.52, 'latency': 63.83197021484375, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.4}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.55, 'latency': 4.55392050743103, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.5}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.94, 'latency': 48.89831781387329, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.8}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.85, 'latency': 4.628303289413452, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.5}], 'avg_latency': 28.938859462738037}\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Change 1: Replace 15 lines with 61 lines\nChange 2: Replace 34 lines with 41 lines\nChange 3: Replace 13 lines with 13 lines\n- Metrics: combined_score: 0.6283, latency: 31.7398, artifacts: {'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.45, 'latency': 24.607950448989868, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.16666666666666666}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.7999999999999999, 'latency': 46.1371853351593, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.5800000000000001, 'latency': 33.79699158668518, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.4, 'latency': 33.02373433113098, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.0}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.8799999999999999, 'latency': 47.49162840843201, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.6}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.85, 'latency': 5.381503105163574, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.5}], 'avg_latency': 31.739832202593487}\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace 10 lines with 12 lines\nChange 2: Replace 13 lines with 14 lines\nChange 3: Replace 11 lines with 13 lines\nChange 4: Replace 10 lines with 12 lines\nChange 5: Replace 11 lines with 12 lines\nChange 6: Replace 41 lines with 49 lines\nChange 7: Replace 13 lines with 13 lines\n- Metrics: combined_score: 0.6384, latency: 33.2846, artifacts: {'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.7, 'latency': 48.86167073249817, 'code_extracted': True, 'exec_success': False, 'keyword_match': 1.0}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.6, 'latency': 41.50366258621216, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6666666666666666}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.64, 'latency': 27.060906410217285, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.55, 'latency': 21.489675283432007, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.5}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.64, 'latency': 39.53539991378784, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.8999999999999999, 'latency': 21.25608730316162, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.6666666666666666}], 'avg_latency': 33.28456703821818}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.6384)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent\n\n# Create specialized agents for planning, querying, code checking and synthesis to improve robustness and clarity\n\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"carefully analyze if it contains multiple distinct concepts. \"\n        \"Split the question into 2-3 focused, concise subqueries if multiple concepts exist, \"\n        \"and return them as a JSON array. If only one concept, return a single-element array. \"\n        \"Return ONLY the JSON array with no extra text or explanation.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user requests code, include complete, runnable Python code blocks. \"\n        \"Use only ADK APIs explicitly documented in the official docs. \"\n        \"Do NOT invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Demonstrate usage strictly following the Runner/Invocation patterns shown in ADK documentation. \"\n        \"Respond ONLY with the answer content and code blocks; no extra commentary.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Analyze the rag_response output and extract all Python code blocks. \"\n        \"For each code block, invoke the code snippet checker tool to validate correct imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond strictly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass, respond strictly with 'CHECK_PASSED'. \"\n        \"Do NOT include any other text or explanation.\"\n    ),\n    tools=[],\n    output_key=\"check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Produce the final concise answer by synthesizing the rag_response content. \"\n        \"If code check result is 'CHECK_PASSED', include all valid Python code blocks inline. \"\n        \"If code check result is 'CHECK_FAILED', respond with a short message indicating retry due to code validation failure, \"\n        \"but do NOT include any code blocks. \"\n        \"Ensure the response is self-contained, user-ready, and free of internal notes.\"\n    ),\n    output_key=\"final_answer\",\n)\n\n# Define a loop agent to retry the sequence once if code check fails\nbase_rag_agent = SequentialAgent(\n    name=\"RagAgentPipeline\",\n    sub_agents=[planning_agent, query_agent, code_check_agent, synthesizer_agent],\n    description=\"Pipeline: plan query, code check, synthesize\",\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[base_rag_agent],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit LoopAgent early if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (basic heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\n# Attach code check tool explicitly only to the code_check_agent, and rag_toolset to query_agent\n# But ADK does not support partial tool assignment yet - workaround by passing all tools but instructions limit tool usage\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, invoke the RagAgentLoop workflow \"\n        \"which plans, queries, checks code, and synthesizes a final answer. \"\n        \"If code validation fails, retry the loop once to improve the answer. \"\n        \"Respond ONLY with the final validated answer content. \"\n        \"Avoid commented-out or non-existent method calls. Be concise and user-friendly.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nKey features: Performs well on combined_score (0.6384), Performs well on latency (33.2846), Performs well on artifacts ({'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.7, 'latency': 48.86167073249817, 'code_extracted': True, 'exec_success': False, 'keyword_match': 1.0}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.6, 'latency': 41.50366258621216, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6666666666666666}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.64, 'latency': 27.060906410217285, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.55, 'latency': 21.489675283432007, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.5}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.64, 'latency': 39.53539991378784, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.8}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.8999999999999999, 'latency': 21.25608730316162, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.6666666666666666}], 'avg_latency': 33.28456703821818})\n\n### Program 2 (Score: 0.6283)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\n\n# Split the rag_agent into a SequentialAgent workflow with planning, querying, code-checking, and synthesis steps\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"if it contains multiple concepts, split it into 2-3 focused subqueries. \"\n        \"Return the list of subqueries in a JSON array format. If only one concept, return single-element array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user asks for code, include a Python code block. \"\n        \"Only use ADK APIs that appear in the provided documentation. \"\n        \"Do not invent convenience methods like agent.chat/agent.run/agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs for execution.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Inspect the rag_response for Python code blocks. For each code block, \"\n        \"run the code-check tool to validate imports and instantiation. \"\n        \"If any check fails, respond with 'CHECK_FAILED'. Otherwise respond 'CHECK_PASSED'.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize the final answer by combining rag_response. \"\n        \"If code_check_result is 'CHECK_PASSED', include code blocks in the answer. \"\n        \"If 'CHECK_FAILED', say you are retrying.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[\n        planning_agent,\n        query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit loops if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator. Given a user query, use the RagAgentLoop workflow \"\n        \"to plan, query, check code, and synthesize a final answer. \"\n        \"If code check fails, the loop allows retrying once. \"\n        \"Return only the final synthesized answer. \"\n        \"Avoid commented-out or non-existent method calls.\"\n    ),\n    tools=[AgentTool(agent=rag_agent), check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nKey features: Performs well on combined_score (0.6283), Performs well on latency (31.7398), Performs well on artifacts ({'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.45, 'latency': 24.607950448989868, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.16666666666666666}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.7999999999999999, 'latency': 46.1371853351593, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.5800000000000001, 'latency': 33.79699158668518, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.6}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.4, 'latency': 33.02373433113098, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.0}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.8799999999999999, 'latency': 47.49162840843201, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.6}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.85, 'latency': 5.381503105163574, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.5}], 'avg_latency': 31.739832202593487})\n\n### Program 3 (Score: 0.6144)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.tool_context import ToolContext\n\n# Compose a SequentialAgent that explicitly splits planning, querying, code-checking, and synthesis steps\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"carefully analyze if it contains multiple distinct concepts. \"\n        \"Split the question into 2-3 focused, concise subqueries if multiple concepts exist, \"\n        \"and return them as a JSON array. If only one concept, return a single-element array. \"\n        \"Return ONLY the JSON array with no extra text or explanation.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user requests code, include complete, runnable Python code blocks. \"\n        \"Use only ADK APIs explicitly documented in the official docs. \"\n        \"Do NOT invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Demonstrate usage strictly following the Runner/Invocation patterns shown in ADK documentation. \"\n        \"Respond ONLY with the answer content and code blocks; no extra commentary.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Analyze the rag_response output and extract all Python code blocks. \"\n        \"For each code block, invoke the code snippet checker tool to validate correct imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond strictly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass, respond strictly with 'CHECK_PASSED'. \"\n        \"Do NOT include any other text or explanation.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Produce the final concise answer by synthesizing the rag_response content. \"\n        \"If code check result is 'CHECK_PASSED', include all valid Python code blocks inline. \"\n        \"If code check result is 'CHECK_FAILED', respond with a short message indicating retry due to code validation failure, \"\n        \"but do NOT include any code blocks. \"\n        \"Ensure the response is self-contained, user-ready, and free of internal notes.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nbase_rag_agent = SequentialAgent(\n    name=\"RagAgentPipeline\",\n    sub_agents=[planning_agent, query_agent, code_check_agent, synthesizer_agent],\n    description=\"Pipeline: plan query, code check, synthesize\",\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[base_rag_agent],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (basic heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            # Escalate to exit LoopAgent early on unsafe code\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, orchestrate the RagAgentWithRetry workflow to \"\n        \"plan, query, check Python code, and synthesize a final answer. If the code check fails, retry once by reformulating the answer. \"\n        \"Only respond with the final validated answer content. \"\n        \"Avoid commented-out or non-existent method calls. \"\n        \"Do not invent convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Use the Runner/Invocation patterns shown in ADK docs strictly.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nKey features: Performs well on combined_score (0.6144), Performs well on latency (28.9389), Performs well on artifacts ({'details': [{'query': \"Write a complete Python script to create and run a simple ADK agent named 'SimpleAgent' using the 'gpt-4.1-nano' model. The agent should have the instruction 'You are a helpful assistant.' and respond to the user message 'Hello'. Use InMemorySessionService for the session.\", 'score': 0.5, 'latency': 34.70959544181824, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': \"Create a Python script that defines a custom tool function `calculate_area(radius: int) -> dict` which returns the area of a circle. Initialize an ADK Agent with this tool and run it with the query 'Calculate area of circle with radius 5'.\", 'score': 0.5, 'latency': 17.011049509048462, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.3333333333333333}, {'query': 'Write a Python script to create a SequentialAgent in ADK that chains two sub-agents: `step1_agent` and `step2_agent`. `step1_agent` should generate a topic, and `step2_agent` should write a poem about it. Run the sequential agent.', 'score': 0.52, 'latency': 63.83197021484375, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.4}, {'query': 'Write a Python script that configures an ADK Agent with a specific `GenerateContentConfig` setting the temperature to 0.7. Run the agent with a simple prompt.', 'score': 0.55, 'latency': 4.55392050743103, 'code_extracted': True, 'exec_success': False, 'keyword_match': 0.5}, {'query': \"Create a Python script that defines a `before_agent_callback` to print 'Agent Starting' before the agent runs. Attach this callback to an ADK Agent and execute it.\", 'score': 0.94, 'latency': 48.89831781387329, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.8}, {'query': \"Write a Python script defining a custom agent class `MyCustomAgent` that inherits from `BaseAgent`. Implement the `_run_async_impl` method to yield a single text event 'Custom Run'. Run an instance of this agent.\", 'score': 0.85, 'latency': 4.628303289413452, 'code_extracted': True, 'exec_success': True, 'keyword_match': 0.5}], 'avg_latency': 28.938859462738037})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.5428)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\n\n# Split the rag_agent into a SequentialAgent workflow with planning, querying, code-checking, and synthesis steps\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"carefully analyze if it contains multiple distinct concepts. \"\n        \"If yes, split it into 2-3 clear, focused subqueries. \"\n        \"Return ONLY a JSON array of strings representing these subqueries. \"\n        \"If only one concept, return a single-element array. \"\n        \"Do not add any additional explanation or text outside the JSON array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG toolset. \"\n        \"If the user requests code, include valid Python code blocks using only documented ADK APIs. \"\n        \"Do NOT invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Demonstrate usage following the Runner/Invocation patterns exactly as shown in official ADK documentation. \"\n        \"Output only the answer content and code blocks, without extra commentary or invented APIs.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Parse the rag_response output carefully and extract all Python code blocks. \"\n        \"For each code block, invoke the code snippet checker tool to validate imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond exactly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass, respond exactly with 'CHECK_PASSED'. \"\n        \"Do not add any extra commentary or explanation.\"\n    ),\n    tools=[],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize a concise final answer by combining the rag_response content. \"\n        \"If code_check_result is 'CHECK_PASSED', include all valid Python code blocks inline. \"\n        \"If code_check_result is 'CHECK_FAILED', respond with a brief message indicating you are retrying due to code validation failure, \"\n        \"but do not include code blocks. \"\n        \"Ensure the response is self-contained, user-ready, and without internal agent notes.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[\n        planning_agent,\n        query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit LoopAgent if validation fails.\n    Implement basic safety: disallow dangerous imports or calls.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Basic safety check: disallow dangerous imports or system commands\n    forbidden_substrings = [\"import os\", \"import sys\", \"subprocess\", \"eval\", \"exec\", \"__import__\"]\n    if any(sub in code for sub in forbidden_substrings):\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Code contains forbidden operations.\"}\n\n    # Limit snippet size to prevent abuse and long execution\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, orchestrate the RagAgentLoop workflow to plan, query, \"\n        \"check Python code, and synthesize a final answer. If the code check fails, retry once by reformulating the answer. \"\n        \"Return only the final synthesized answer. \"\n        \"Avoid commented-out or non-existent method calls. \"\n        \"Use only the tools provided and keep responses concise and accurate.\"\n    ),\n    tools=[AgentTool(agent=rag_agent), check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to latency\n\n### Program D2 (Score: 0.5697)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent\n\n# Create specialized agents for planning, querying, code checking and synthesis to improve robustness and clarity\n\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent specialized in analyzing user questions about Google ADK. \"\n        \"If the question contains multiple distinct concepts, split it into 2-3 focused, concise subqueries. \"\n        \"Return only a valid JSON array of strings representing these subqueries. \"\n        \"If only one concept is present, return a single-element array with that query. \"\n        \"Do not include explanations or extra text outside the JSON array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer each focused query about Google ADK by using the MCP RAG toolset. \"\n        \"If the user requests code, include Python code blocks with correct syntax. \"\n        \"Only use the ADK APIs explicitly documented. \"\n        \"Do not invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Demonstrate usage following the Runner/Invocation patterns shown in the official ADK documentation. \"\n        \"Output only the answer content and code blocks, without extra commentary.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Analyze the rag_response output and extract all Python code blocks. \"\n        \"For each code block, invoke the code snippet checker tool to validate correct imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond strictly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass, respond strictly with 'CHECK_PASSED'. \"\n        \"Do NOT include any other text or explanation.\"\n    ),\n    tools=[],\n    output_key=\"check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Produce the final concise answer by synthesizing the rag_response content. \"\n        \"If code_check_result is 'CHECK_PASSED', include all valid Python code blocks inline. \"\n        \"If code_check_result is 'CHECK_FAILED', respond with a short message indicating retry due to code validation failure, \"\n        \"but do NOT include any code blocks. \"\n        \"Ensure the response is self-contained and user-ready, without internal agent notes.\"\n    ),\n    output_key=\"final_answer\",\n)\n\n# Define a loop agent to allow retrying query and code check once if code check fails\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[\n        planning_agent,\n        query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit loops if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (basic heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            # Escalate to exit LoopAgent early\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\n# Attach code check tool explicitly only to the code_check_agent, and rag_toolset to query_agent\n# But ADK does not support partial tool assignment yet - workaround by passing all tools but instructions limit tool usage\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, invoke the RagAgentLoop workflow to plan, query, check code, and synthesize a final answer. \"\n        \"If code validation fails, retry the loop once to improve the answer. \"\n        \"Only respond with the final, validated answer content. \"\n        \"Avoid commented-out code or calls to non-existent methods. \"\n        \"Be concise and user-friendly.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to latency\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\n\n# Compose a LoopAgent workflow for robust retry on code check failure, splitting planning, querying, code check and synthesis\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, carefully analyze it. \"\n        \"If it contains multiple distinct concepts, split it into 2-3 focused, concise subqueries. \"\n        \"Return ONLY a valid JSON array of these subqueries as strings. \"\n        \"If only one concept, return a single-element array. No extra explanation or text.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nrag_query_agent = LlmAgent(\n    name=\"RagQueryAgent\",\n    model=model,\n    instruction=(\n        \"You will receive a focused query about Google ADK. Answer using the MCP RAG toolset. \"\n        \"If the user requests code, include a complete, runnable Python code block. \"\n        \"Use only ADK APIs explicitly documented in the official docs. \"\n        \"Do NOT invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Demonstrate usage strictly following Runner/Invocation patterns shown in ADK documentation. \"\n        \"Output ONLY a JSON object with keys 'answer' (string) and optionally 'code' (string) if code is included. \"\n        \"Avoid extra commentary or explanation.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Analyze the 'rag_response' output carefully. Extract all Python code blocks if present. \"\n        \"For each code block, run the code snippet checker tool to validate imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond exactly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass, respond exactly with 'CHECK_PASSED'. \"\n        \"Do NOT include any other text or explanation.\"\n    ),\n    tools=[check_tool],\n    output_key=\"code_check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Produce a concise, user-ready final answer by synthesizing the content in 'rag_response'. \"\n        \"If 'code_check_result' is 'CHECK_PASSED', include all valid Python code blocks inline. \"\n        \"If 'CHECK_FAILED', respond with a brief message that you are retrying due to code validation failure. \"\n        \"Do NOT include any code blocks in this case. \"\n        \"Ensure the response is free of internal notes and is fully self-contained.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nrag_agent_workflow = SequentialAgent(\n    name=\"RagAgentWorkflow\",\n    sub_agents=[\n        planning_agent,\n        rag_query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n    description=(\n        \"Sequential workflow: plan user query -> query MCP RAG -> check code validity -> synthesize final answer.\"\n    ),\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[rag_agent_workflow],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Implement basic safety checks forbidding dangerous imports or calls.\n    Escalate early to exit LoopAgent if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Basic safety check: disallow dangerous imports or system calls\n    forbidden_substrings = [\"import os\", \"import sys\", \"subprocess\", \"eval\", \"exec\", \"__import__\", \"open(\"]\n    if any(sub in code for sub in forbidden_substrings):\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Code contains forbidden operations.\"}\n\n    if len(code) > 1000:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as tmp_file:\n        tmp_file.write(code)\n        path = tmp_file.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n            check=False,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip() if result.stdout else \"\",\n        \"stderr\": result.stderr.strip() if result.stderr else \"\",\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LoopAgent(\n    name=\"RootAgent\",\n    sub_agents=[\n        rag_agent,\n        LlmAgent(\n            name=\"CodeValidationAgent\",\n            model=model,\n            instruction=(\n                \"Given the RagAgent's response, detect Python code blocks. \"\n                \"For each code block, run the code snippet checker tool to validate imports and instantiations. \"\n                \"If validation fails, escalate to rerun RagAgent with a reformulated query. \"\n                \"Otherwise, approve the response. \"\n                \"If no Python code blocks are present, approve the response directly.\"\n            ),\n            tools=[check_tool],\n            output_key=\"code_check_result\",\n        ),\n    ],\n    max_iterations=2,\n    instruction=(\n        \"Iteratively run RagAgent and code validation, retrying once if code check fails by escalation. \"\n        \"Return ONLY the final validated answer after successful code validation.\"\n    ),\n    output_key=\"final_answer\",\n)\n\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Comprehensive implementation\n\n### Inspiration 2 (Score: 0.4911, Type: Experimental)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.tool_context import ToolContext\n\n# Create specialized sub-agents for planning, querying, code checking, and synthesis for better robustness\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent specialized in analyzing user questions about Google ADK. \"\n        \"If the question contains multiple distinct concepts, split it into 2-3 focused, concise subqueries. \"\n        \"Return only a valid JSON array of strings representing these subqueries. \"\n        \"If only one concept is present, return a single-element array with that query. \"\n        \"Do not include explanations or extra text outside the JSON array.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG toolset. \"\n        \"If the user asks for code, include complete, runnable Python code blocks. \"\n        \"Use only ADK APIs explicitly documented in the official docs. \"\n        \"Do NOT invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Demonstrate usage strictly following the Runner/Invocation patterns shown in ADK documentation. \"\n        \"Respond ONLY with the answer content and code blocks; no extra commentary.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Parse the rag_response output carefully and extract all Python code blocks. \"\n        \"For each code block, invoke the code snippet checker tool to validate imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond exactly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass, respond exactly with 'CHECK_PASSED'. \"\n        \"Do NOT add any extra commentary or explanation.\"\n    ),\n    tools=[],\n    output_key=\"check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Synthesize a concise final answer by combining the rag_response content. \"\n        \"If code_check_result is 'CHECK_PASSED', include all valid Python code blocks inline. \"\n        \"If code_check_result is 'CHECK_FAILED', respond with a brief message indicating retry due to code validation failure, \"\n        \"but do NOT include any code blocks. \"\n        \"Ensure the response is self-contained, user-ready, and free of internal notes.\"\n    ),\n    output_key=\"final_answer\",\n)\n\nbase_rag_agent = SequentialAgent(\n    name=\"RagAgentPipeline\",\n    sub_agents=[planning_agent, query_agent, code_check_agent, synthesizer_agent],\n    description=\"Pipeline: plan query, code check, synthesize\",\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentWithRetry\",\n    sub_agents=[base_rag_agent],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit LoopAgent early if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (improved heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\", \"__import__\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n            check=False,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, orchestrate the RagAgentWithRetry workflow which plans, queries, checks Python code, and synthesizes a final answer. \"\n        \"If code validation fails, retry the loop once by reformulating the answer. \"\n        \"Return ONLY the final validated and user-ready answer content. \"\n        \"Do NOT include commented-out or calls to non-existent methods. \"\n        \"Avoid invented convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Use the Runner/Invocation patterns strictly as documented in ADK.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Comprehensive implementation\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent, LlmAgent\n\n# Compose a workflow agent that separates planning, RAG querying, code checking, and synthesis\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"carefully analyze if it contains multiple distinct concepts. \"\n        \"Split it into 2-3 focused, concise subqueries if multiple concepts exist. \"\n        \"Return ONLY a JSON array of strings representing these subqueries. \"\n        \"If only one concept, return a single-element array. Do not add explanations.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nrag_query_agent = LlmAgent(\n    name=\"RagQueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer each focused query about Google ADK using the MCP RAG toolset. \"\n        \"If the user requests code, include complete and runnable Python code blocks. \"\n        \"Use only ADK APIs explicitly documented, and strictly follow Runner/Invocation patterns as in official docs. \"\n        \"Do NOT invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Do not include commented-out code or speculative implementations.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\n# Agent to check code snippets in rag_response\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Extract all Python code blocks from 'rag_response'. \"\n        \"For each code block, invoke the code snippet checker tool to validate correct imports and instantiations. \"\n        \"If all code blocks pass, respond exactly with 'CHECK_PASSED'. \"\n        \"If any fail, respond exactly with 'CHECK_FAILED'. \"\n        \"If no Python code blocks exist, respond 'CHECK_PASSED'. \"\n        \"Do not add any other text or explanation.\"\n    ),\n    tools=[check_tool],\n    output_key=\"code_check_result\",\n)\n\n# Agent to synthesize final answer\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Produce a concise final answer by synthesizing 'rag_response'. \"\n        \"If 'code_check_result' is 'CHECK_PASSED', include all Python code blocks exactly as provided. \"\n        \"If 'CHECK_FAILED', respond with a brief message stating you are retrying with a reformulated query to fix code errors. \"\n        \"Avoid verbosity, repetition, or speculative content. Keep the answer professional and user-friendly.\"\n    ),\n    output_key=\"final_answer\",\n)\n\n# Wrap the sequential agent in a LoopAgent for retry on code validation failure\nbase_rag_agent = SequentialAgent(\n    name=\"RagAgentPipeline\",\n    sub_agents=[\n        planning_agent,\n        rag_query_agent,\n        code_check_agent,\n        synthesizer_agent,\n    ],\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[base_rag_agent],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Limit snippet size to prevent abuse.\n    Escalate to exit LoopAgent early if validation fails.\n    Use a whitelist approach to allow only safe imports and constructs.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    # Simple whitelist check: allow only certain safe imports and constructs\n    allowed_imports = [\"from google.adk\", \"import math\", \"import typing\"]\n    for line in code.splitlines():\n        line_strip = line.strip()\n        if line_strip.startswith(\"import\") or line_strip.startswith(\"from\"):\n            if not any(allowed in line_strip for allowed in allowed_imports):\n                return {\"ok\": False, \"error\": \"Code contains disallowed imports.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\nroot_agent = LoopAgent(\n    name=\"RootAgent\",\n    sub_agents=[\n        rag_agent,\n        LlmAgent(\n            name=\"CodeValidationAgent\",\n            model=model,\n            instruction=(\n                \"Analyze the response from RagAgent for Python code blocks. \"\n                \"If any code blocks are present, extract them and run the code-check tool to validate imports and instantiations. \"\n                \"If validation fails, escalate to rerun RagAgent with a reformulated query to fix errors. \"\n                \"If validation passes, approve and finalize the response. \"\n                \"Do not return partial or ambiguous results. \"\n                \"Respond only with the validation outcome and do not include any other text.\"\n            ),\n            tools=[check_tool],\n            output_key=\"code_check_result\",\n        ),\n    ],\n    max_iterations=2,\n    instruction=(\n        \"Iteratively run RagAgent and validate Python code blocks, retrying once if code validation fails. \"\n        \"Return only the final validated answer.\"\n    ),\n)\n\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Comprehensive implementation\n\n# Current Program\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import SseConnectionParams\nfrom google.adk.tools.tool_context import ToolContext\n\nload_dotenv()\n\n\ndef _configure_logging() -> None:\n    log_dir = Path(__file__).resolve().parent / \"logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / \"adk.log\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        handlers=[\n            logging.FileHandler(log_file, encoding=\"utf-8\"),\n            logging.StreamHandler(),\n        ],\n    )\n\n\n_configure_logging()\n\n\n\n# Validating and resolving configuration\ndef _resolve_llm_model() -> str | LiteLlm:\n    provider = os.getenv(\"ADK_LLM_PROVIDER\", \"openai\").strip().lower()\n    model = os.getenv(\"ADK_LLM_MODEL\", \"gpt-4.1-mini\").strip()\n    if provider == \"openai\":\n        return LiteLlm(model=f\"openai/{model}\")\n    return model\n\ndef _rag_mcp_url() -> str:\n    return os.getenv(\"RAG_MCP_URL\", \"http://127.0.0.1:8000/sse\").strip()\n\nmodel = _resolve_llm_model()\nrag_mcp_url = _rag_mcp_url()\n\n# 1. Define the RAG Agent\nrag_toolset = MCPToolset(\n    connection_params=SseConnectionParams(\n        url=rag_mcp_url,\n        timeout=300,\n    )\n)\n\nfrom google.adk.agents import SequentialAgent, LoopAgent\n\n# Create specialized agents for planning, querying, code checking and synthesis to improve robustness and clarity\n\nplanning_agent = LlmAgent(\n    name=\"PlanningAgent\",\n    model=model,\n    instruction=(\n        \"You are a planning agent. Given a user question about Google ADK, \"\n        \"carefully analyze if it contains multiple distinct concepts. \"\n        \"Split the question into 2-3 focused, concise subqueries if multiple concepts exist, \"\n        \"and return them as a JSON array. If only one concept, return a single-element array. \"\n        \"Return ONLY the JSON array with no extra text or explanation.\"\n    ),\n    output_key=\"subqueries\",\n)\n\nquery_agent = LlmAgent(\n    name=\"QueryAgent\",\n    model=model,\n    instruction=(\n        \"Answer a focused query about Google ADK using the MCP RAG tool. \"\n        \"If the user requests code, include complete, runnable Python code blocks. \"\n        \"Use only ADK APIs explicitly documented in the official docs. \"\n        \"Do NOT invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Demonstrate usage strictly following the Runner/Invocation patterns shown in ADK documentation. \"\n        \"Respond ONLY with the answer content and code blocks; no extra commentary.\"\n    ),\n    tools=[rag_toolset],\n    output_key=\"rag_response\",\n)\n\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Analyze the rag_response output and extract all Python code blocks. \"\n        \"For each code block, invoke the code snippet checker tool to validate correct imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond strictly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass, respond strictly with 'CHECK_PASSED'. \"\n        \"Do NOT include any other text or explanation.\"\n    ),\n    tools=[],\n    output_key=\"check_result\",\n)\n\nsynthesizer_agent = LlmAgent(\n    name=\"SynthesizerAgent\",\n    model=model,\n    instruction=(\n        \"Produce the final concise answer by synthesizing the rag_response content. \"\n        \"If code check result is 'CHECK_PASSED', include all valid Python code blocks inline. \"\n        \"If code check result is 'CHECK_FAILED', respond with a short message indicating retry due to code validation failure, \"\n        \"but do NOT include any code blocks. \"\n        \"Ensure the response is self-contained, user-ready, and free of internal notes.\"\n    ),\n    output_key=\"final_answer\",\n)\n\n# Define a loop agent to retry the sequence once if code check fails\nbase_rag_agent = SequentialAgent(\n    name=\"RagAgentPipeline\",\n    sub_agents=[planning_agent, query_agent, code_check_agent, synthesizer_agent],\n    description=\"Pipeline: plan query, code check, synthesize\",\n)\n\nrag_agent = LoopAgent(\n    name=\"RagAgentLoop\",\n    sub_agents=[base_rag_agent],\n    max_iterations=2,\n)\n\n\n# 2. Define the Code Check Tool\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit LoopAgent early if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (basic heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n\n\n# 3. Define the Root Agent\nrag_tool = AgentTool(agent=rag_agent)\ncheck_tool = FunctionTool(func=run_python_snippet)\n\n# Attach code check tool explicitly only to the code_check_agent, and rag_toolset to query_agent\n# But ADK does not support partial tool assignment yet - workaround by passing all tools but instructions limit tool usage\n\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, invoke the RagAgentLoop workflow \"\n        \"which plans, queries, checks code, and synthesizes a final answer. \"\n        \"If code validation fails, retry the loop once to improve the answer. \"\n        \"Respond ONLY with the final validated answer content. \"\n        \"Avoid commented-out or non-existent method calls. Be concise and user-friendly.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["<<<<<<< SEARCH\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Analyze the rag_response output and extract all Python code blocks. \"\n        \"For each code block, invoke the code snippet checker tool to validate correct imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond strictly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass, respond strictly with 'CHECK_PASSED'. \"\n        \"Do NOT include any other text or explanation.\"\n    ),\n    tools=[],\n    output_key=\"check_result\",\n)\n=======\ncode_check_agent = LlmAgent(\n    name=\"CodeCheckAgent\",\n    model=model,\n    instruction=(\n        \"Carefully parse the rag_response output and extract every Python code block present. \"\n        \"For each code block, use the code snippet checker tool to validate imports, syntax, and instantiations. \"\n        \"If any code block fails validation, respond exactly with 'CHECK_FAILED'. \"\n        \"If all code blocks pass validation or if no code blocks are found, respond exactly with 'CHECK_PASSED'. \"\n        \"Do NOT include any other text or explanation.\"\n    ),\n    tools=[],\n    output_key=\"check_result\",\n)\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Run a small Python snippet in the current environment to validate imports or\n    simple instantiations. Avoid long-running operations.\n    Escalate early to exit LoopAgent early if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Sanitize code to prevent dangerous imports or calls (basic heuristic)\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' in code snippet.\"}\n\n    # Limit snippet size to prevent abuse\n    if len(code) > 1000:\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as handle:\n        handle.write(code)\n        path = handle.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=5,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip(),\n        \"stderr\": result.stderr.strip(),\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n=======\ndef run_python_snippet(code: str, tool_context: ToolContext) -> Dict[str, object]:\n    \"\"\"\n    Execute a small Python snippet to validate imports, syntax, and simple instantiations.\n    Avoid running long or unsafe code. Escalate early to exit LoopAgent if validation fails.\n    \"\"\"\n    if not code or not code.strip():\n        return {\"ok\": False, \"error\": \"No code provided.\"}\n\n    # Basic security: disallow dangerous imports or calls\n    restricted_keywords = [\"import os\", \"import sys\", \"subprocess\", \"open(\", \"exec(\", \"eval(\", \"__import__\"]\n    for keyword in restricted_keywords:\n        if keyword in code:\n            tool_context.actions.escalate = True\n            return {\"ok\": False, \"error\": f\"Use of restricted keyword '{keyword}' detected in code snippet.\"}\n\n    # Limit snippet length to prevent abuse\n    if len(code) > 1000:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Code snippet too long.\"}\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as tmp_file:\n        tmp_file.write(code)\n        path = tmp_file.name\n\n    try:\n        result = subprocess.run(\n            [sys.executable, path],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n    except subprocess.TimeoutExpired:\n        tool_context.actions.escalate = True\n        return {\"ok\": False, \"error\": \"Execution timed out.\"}\n    finally:\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n    result_payload = {\n        \"ok\": result.returncode == 0,\n        \"returncode\": result.returncode,\n        \"stdout\": result.stdout.strip() if result.stdout else \"\",\n        \"stderr\": result.stderr.strip() if result.stderr else \"\",\n    }\n    if not result_payload[\"ok\"]:\n        tool_context.actions.escalate = True\n    return result_payload\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, invoke the RagAgentLoop workflow \"\n        \"which plans, queries, checks code, and synthesizes a final answer. \"\n        \"If code validation fails, retry the loop once to improve the answer. \"\n        \"Respond ONLY with the final validated answer content. \"\n        \"Avoid commented-out or non-existent method calls. Be concise and user-friendly.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n=======\nroot_agent = LlmAgent(\n    name=\"RootAgent\",\n    model=model,\n    instruction=(\n        \"You are the main coordinator agent. For each user query, orchestrate the RagAgentLoop workflow which plans, queries, \"\n        \"checks Python code, and synthesizes a final answer. If the code check fails, retry once by reformulating the answer. \"\n        \"Respond ONLY with the final validated answer content. \"\n        \"Avoid any commented-out code or calls to non-existent methods. \"\n        \"Do NOT invent or mention convenience methods like agent.chat, agent.run, or agent.invoke. \"\n        \"Strictly use the Runner/Invocation patterns shown in ADK documentation. \"\n        \"Keep responses concise, accurate, and user-friendly.\"\n    ),\n    tools=[rag_tool, check_tool],\n    output_key=\"final_answer\",\n)\n>>>>>>> REPLACE"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}