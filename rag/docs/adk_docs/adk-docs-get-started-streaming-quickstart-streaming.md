---
url: https://google.github.io/adk-docs/get-started/streaming/quickstart-streaming/
source: Google ADK Documentation
---

[adk-python](https://github.com/google/adk-python "adk-python")

[adk-go](https://github.com/google/adk-go "adk-go")

[adk-java](https://github.com/google/adk-java "adk-java")

* [Home](../../..)

  Home
* Build Agents




  Build Agents
  + [Get Started](../../)

    Get Started
    - [Python](../../python/)
    - [Go](../../go/)
    - [Java](../../java/)
  + [Build your Agent](../../../tutorials/)

    Build your Agent
    - [Multi-tool agent](../../quickstart/)
    - [Agent team](../../../tutorials/agent-team/)
    - [Streaming agent](../)

      Streaming agent
      * Python

        [Python](./)



        Table of contents
        + [Supported models for voice/video streaming](#supported-models)
        + [1. Setup Environment & Install ADK](#setup-environment-install-adk)
        + [2. Project Structure](#project-structure)

          - [agent.py](#agentpy)
        + [3. Set up the platform](#set-up-the-platform)
        + [4. Try the agent with adk web](#try-the-agent-with-adk-web)

          - [Try with text](#try-with-text)
          - [Try with voice and video](#try-with-voice-and-video)
          - [Stop the tool](#stop-the-tool)
          - [Note on ADK Streaming](#note-on-adk-streaming)
        + [Next steps: build custom streaming app](#next-steps-build-custom-streaming-app)
      * [Java](../quickstart-streaming-java/)
    - [Visual Builder](../../../visual-builder/)
    - [Advanced setup](../../installation/)
  + [Agents](../../../agents/)

    Agents
    - [LLM agents](../../../agents/llm-agents/)
    - [Workflow agents](../../../agents/workflow-agents/)

      Workflow agents
      * [Sequential agents](../../../agents/workflow-agents/sequential-agents/)
      * [Loop agents](../../../agents/workflow-agents/loop-agents/)
      * [Parallel agents](../../../agents/workflow-agents/parallel-agents/)
    - [Custom agents](../../../agents/custom-agents/)
    - [Multi-agent systems](../../../agents/multi-agents/)
    - [Agent Config](../../../agents/config/)
    - [Models & Authentication](../../../agents/models/)
  + [Tools for Agents](../../../tools/)

    Tools for Agents
    - [Built-in tools](../../../tools/built-in-tools/)
    - Gemini API tools




      Gemini API tools
      * [Computer use](../../../tools/gemini-api/computer-use/)
    - Google Cloud tools




      Google Cloud tools
      * [Overview](../../../tools/google-cloud-tools/)
      * [MCP Toolbox for Databases](../../../tools/google-cloud/mcp-toolbox-for-databases/)
      * [BigQuery Agent Analytics](../../../tools/google-cloud/bigquery-agent-analytics/)
      * [Code Execution with Agent Engine](../../../tools/google-cloud/code-exec-agent-engine/)
    - [Third-party tools](../../../tools/third-party/)

      Third-party tools
      * [AgentQL](../../../tools/third-party/agentql/)
      * [Bright Data](../../../tools/third-party/bright-data/)
      * [Browserbase](../../../tools/third-party/browserbase/)
      * [Exa](../../../tools/third-party/exa/)
      * [Firecrawl](../../../tools/third-party/firecrawl/)
      * [GitHub](../../../tools/third-party/github/)
      * [Hugging Face](../../../tools/third-party/hugging-face/)
      * [Notion](../../../tools/third-party/notion/)
      * [Tavily](../../../tools/third-party/tavily/)
      * [Agentic UI (AG-UI)](../../../tools/third-party/ag-ui/)
  + [Custom Tools](../../../tools-custom/)

    Custom Tools
    - Function tools




      Function tools
      * [Overview](../../../tools-custom/function-tools/)
      * [Tool performance](../../../tools-custom/performance/)
      * [Action confirmations](../../../tools-custom/confirmation/)
    - [MCP tools](../../../tools-custom/mcp-tools/)
    - [OpenAPI tools](../../../tools-custom/openapi-tools/)
    - [Authentication](../../../tools-custom/authentication/)
* Run Agents




  Run Agents
  + [Agent Runtime](../../../runtime/)

    Agent Runtime
    - [Runtime Config](../../../runtime/runconfig/)
    - [API Server](../../../runtime/api-server/)
    - [Resume Agents](../../../runtime/resume/)
  + [Deployment](../../../deploy/)

    Deployment
    - [Agent Engine](../../../deploy/agent-engine/)
    - [Cloud Run](../../../deploy/cloud-run/)
    - [GKE](../../../deploy/gke/)
  + Observability




    Observability
    - [Logging](../../../observability/logging/)
    - [Cloud Trace](../../../observability/cloud-trace/)
    - [AgentOps](../../../observability/agentops/)
    - [Arize AX](../../../observability/arize-ax/)
    - [Freeplay](../../../observability/freeplay/)
    - [Monocle](../../../observability/monocle/)
    - [Phoenix](../../../observability/phoenix/)
    - [W&B Weave](../../../observability/weave/)
  + [Evaluation](../../../evaluate/)

    Evaluation
    - [Criteria](../../../evaluate/criteria/)
    - [User Simulation](../../../evaluate/user-sim/)
  + [Safety and Security](../../../safety/)

    Safety and Security
* Components




  Components
  + [Technical Overview](../../about/)
  + [Context](../../../context/)

    Context
    - [Context caching](../../../context/caching/)
    - [Context compression](../../../context/compaction/)
  + [Sessions & Memory](../../../sessions/)

    Sessions & Memory
    - [Session](../../../sessions/session/)
    - [State](../../../sessions/state/)
    - [Memory](../../../sessions/memory/)
    - [Vertex AI Express Mode](../../../sessions/express-mode/)
  + [Callbacks](../../../callbacks/)

    Callbacks
    - [Types of callbacks](../../../callbacks/types-of-callbacks/)
    - [Callback patterns](../../../callbacks/design-patterns-and-best-practices/)
  + [Artifacts](../../../artifacts/)

    Artifacts
  + [Events](../../../events/)

    Events
  + [Apps](../../../apps/)

    Apps
  + [Plugins](../../../plugins/)

    Plugins
    - [Reflect and retry](../../../plugins/reflect-and-retry/)
  + [MCP](../../../mcp/)

    MCP
  + [A2A Protocol](../../../a2a/)

    A2A Protocol
    - [Introduction to A2A](../../../a2a/intro/)
    - A2A Quickstart (Exposing)




      A2A Quickstart (Exposing)
      * [Python](../../../a2a/quickstart-exposing/)
      * [Go](../../../a2a/quickstart-exposing-go/)
    - A2A Quickstart (Consuming)




      A2A Quickstart (Consuming)
      * [Python](../../../a2a/quickstart-consuming/)
      * [Go](../../../a2a/quickstart-consuming-go/)
  + [Bidi-streaming (live)](../../../streaming/)

    Bidi-streaming (live)
    - [Custom Audio Bidi-streaming app sample (WebSockets)](../../../streaming/custom-streaming-ws/)
    - [Bidi-streaming development guide series](../../../streaming/dev-guide/part1/)
    - [Streaming Tools](../../../streaming/streaming-tools/)
    - [Configurating Bidi-streaming behaviour](../../../streaming/configuration/)
  + Grounding




    Grounding
    - [Understanding Google Search Grounding](../../../grounding/google_search_grounding/)
    - [Understanding Vertex AI Search Grounding](../../../grounding/vertex_ai_search_grounding/)
* Reference




  Reference
  + [API Reference](../../../api-reference/)

    API Reference
    - [Python ADK](../../../api-reference/python/)
    - [Go ADK](https://pkg.go.dev/google.golang.org/adk)
    - [Java ADK](../../../api-reference/java/)
    - [CLI Reference](../../../api-reference/cli/)
    - [Agent Config reference](../../../api-reference/agentconfig/)
    - [REST API](../../../api-reference/rest/)
  + [Community Resources](../../../community/)
  + [Contributing Guide](../../../contributing-guide/)

Table of contents

* [Supported models for voice/video streaming](#supported-models)
* [1. Setup Environment & Install ADK](#setup-environment-install-adk)
* [2. Project Structure](#project-structure)

  + [agent.py](#agentpy)
* [3. Set up the platform](#set-up-the-platform)
* [4. Try the agent with adk web](#try-the-agent-with-adk-web)

  + [Try with text](#try-with-text)
  + [Try with voice and video](#try-with-voice-and-video)
  + [Stop the tool](#stop-the-tool)
  + [Note on ADK Streaming](#note-on-adk-streaming)
* [Next steps: build custom streaming app](#next-steps-build-custom-streaming-app)

# Build a streaming agent with Python[¶](#build-a-streaming-agent-with-python "Permanent link")

With this quickstart, you'll learn to create a simple agent and use ADK Streaming to enable voice and video communication with it that is low-latency and bidirectional. We will install ADK, set up a basic "Google Search" agent, try running the agent with Streaming with `adk web` tool, and then explain how to build a simple asynchronous web app by yourself using ADK Streaming and [FastAPI](https://fastapi.tiangolo.com/).

**Note:** This guide assumes you have experience using a terminal in Windows, Mac, and Linux environments.

## Supported models for voice/video streaming[¶](#supported-models "Permanent link")

In order to use voice/video streaming in ADK, you will need to use Gemini models that support the Live API. You can find the **model ID(s)** that supports the Gemini Live API in the documentation:

* [Google AI Studio: Gemini Live API](https://ai.google.dev/gemini-api/docs/models#live-api)
* [Vertex AI: Gemini Live API](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)

## 1. Setup Environment & Install ADK[¶](#setup-environment-install-adk "Permanent link")

Create & Activate Virtual Environment (Recommended):

```python
# Create
python -m venv .venv
# Activate (each new terminal)
# macOS/Linux: source .venv/bin/activate
# Windows CMD: .venv\Scripts\activate.bat
# Windows PowerShell: .venv\Scripts\Activate.ps1
```

Install ADK:

```python
pip install google-adk
```

## 2. Project Structure[¶](#project-structure "Permanent link")

Create the following folder structure with empty files:

```python
adk-streaming/  # Project folder
└── app/ # the web app folder
    ├── .env # Gemini API key
    └── google_search_agent/ # Agent folder
        ├── __init__.py # Python package
        └── agent.py # Agent definition
```

### agent.py[¶](#agentpy "Permanent link")

Copy-paste the following code block into the `agent.py` file.

For `model`, please double check the model ID as described earlier in the [Models section](#supported-models).

```python
from google.adk.agents import Agent
from google.adk.tools import google_search  # Import the tool

root_agent = Agent(
   # A unique name for the agent.
   name="basic_search_agent",
   # The Large Language Model (LLM) that agent will use.
   # Please fill in the latest model id that supports live from
   # https://google.github.io/adk-docs/get-started/streaming/quickstart-streaming/#supported-models
   model="...",  # for example: model="gemini-2.0-flash-live-001" or model="gemini-2.0-flash-live-preview-04-09"
   # A short description of the agent's purpose.
   description="Agent to answer questions using Google Search.",
   # Instructions to set the agent's behavior.
   instruction="You are an expert researcher. You always stick to the facts.",
   # Add google_search tool to perform grounding with Google search.
   tools=[google_search]
)
```

`agent.py` is where all your agent(s)' logic will be stored, and you must have a `root_agent` defined.

Notice how easily you integrated [grounding with Google Search](https://ai.google.dev/gemini-api/docs/grounding?lang=python#configure-search) capabilities. The `Agent` class and the `google_search` tool handle the complex interactions with the LLM and grounding with the search API, allowing you to focus on the agent's *purpose* and *behavior*.

![intro_components.png](../../../assets/quickstart-streaming-tool.png)

Copy-paste the following code block to `__init__.py` file.

\_\_init\_\_.py

```python
from . import agent
```

## 3. Set up the platform[¶](#set-up-the-platform "Permanent link")

To run the agent, choose a platform from either Google AI Studio or Google Cloud Vertex AI:

Gemini - Google AI StudioGemini - Google Cloud Vertex AI

1. Get an API key from [Google AI Studio](https://aistudio.google.com/apikey).
2. Open the **`.env`** file located inside (`app/`) and copy-paste the following code.

   .env

   ```python
   GOOGLE_GENAI_USE_VERTEXAI=FALSE
   GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE
   ```
3. Replace `PASTE_YOUR_ACTUAL_API_KEY_HERE` with your actual `API KEY`.

1. You need an existing
   [Google Cloud](https://cloud.google.com/?e=48754805&hl=en) account and a
   project.
   * Set up a
     [Google Cloud project](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal#setup-gcp)
   * Set up the
     [gcloud CLI](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal#setup-local)
   * Authenticate to Google Cloud, from the terminal by running
     `gcloud auth login`.
   * [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).
2. Open the **`.env`** file located inside (`app/`). Copy-paste
   the following code and update the project ID and location.

   .env

   ```python
   GOOGLE_GENAI_USE_VERTEXAI=TRUE
   GOOGLE_CLOUD_PROJECT=PASTE_YOUR_ACTUAL_PROJECT_ID
   GOOGLE_CLOUD_LOCATION=us-central1
   ```

## 4. Try the agent with `adk web`[¶](#try-the-agent-with-adk-web "Permanent link")

Now it's ready to try the agent. Run the following command to launch the **dev UI**. First, make sure to set the current directory to `app`:

```python
cd app
```

Also, set `SSL_CERT_FILE` variable with the following command. This is required for the voice and video tests later.

OS X & LinuxWindows

```python
export SSL_CERT_FILE=$(python -m certifi)
```

```python
$env:SSL_CERT_FILE = (python -m certifi)
```

Then, run the dev UI:

```python
adk web
```

Note for Windows users

When hitting the `_make_subprocess_transport NotImplementedError`, consider using `adk web --no-reload` instead.

Open the URL provided (usually `http://localhost:8000` or
`http://127.0.0.1:8000`) **directly in your browser**. This connection stays
entirely on your local machine. Select `google_search_agent`.

### Try with text[¶](#try-with-text "Permanent link")

Try the following prompts by typing them in the UI.

* What is the weather in New York?
* What is the time in New York?
* What is the weather in Paris?
* What is the time in Paris?

The agent will use the google\_search tool to get the latest information to answer those questions.

### Try with voice and video[¶](#try-with-voice-and-video "Permanent link")

To try with voice, reload the web browser, click the microphone button to enable the voice input, and ask the same question in voice. You will hear the answer in voice in real-time.

To try with video, reload the web browser, click the camera button to enable the video input, and ask questions like "What do you see?". The agent will answer what they see in the video input.

(Just clicking the microphone or camera button once is enough. Your voice or video will be streamed to models and the model response will be streamed back continuously. Clicking on the microphone or camera button multiple times is not supported.)

### Stop the tool[¶](#stop-the-tool "Permanent link")

Stop `adk web` by pressing `Ctrl-C` on the console.

### Note on ADK Streaming[¶](#note-on-adk-streaming "Permanent link")

The following features will be supported in the future versions of the ADK Streaming: Callback, LongRunningTool, ExampleTool, and Shell agent (e.g. SequentialAgent).

Congratulations! You've successfully created and interacted with your first Streaming agent using ADK!

## Next steps: build custom streaming app[¶](#next-steps-build-custom-streaming-app "Permanent link")

In [Custom Audio Streaming app](../../../streaming/custom-streaming/) tutorial, it overviews the server and client code for a custom asynchronous web app built with ADK Streaming and [FastAPI](https://fastapi.tiangolo.com/), enabling real-time, bidirectional audio and text communication.

Back to top