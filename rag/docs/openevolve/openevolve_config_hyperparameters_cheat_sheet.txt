Top-level (general)

- max_iterations: Maximum number of evolution iterations to run.
- checkpoint_interval: Save checkpoints every N iterations.
- log_level: Logging verbosity (DEBUG, INFO, WARNING, ERROR, CRITICAL).
- log_dir: Optional custom log directory (defaults to output_dir/logs).
- random_seed: Random seed for reproducibility (default 42; null disables seeding). If database.random_seed is null, it inherits this value.
- language: Explicit code language for parsing/formatting (defaults to auto-detected from the initial program).
- file_suffix: Output file extension for generated programs (default .py).
- diff_based_evolution: If true, LLM emits diff blocks; if false, full rewrite is expected.
- diff_pattern: Regex used to parse diff blocks in LLM responses.
- max_code_length: Maximum program length in characters (hard cap).
- max_tasks_per_child: For parallel evaluation, recycle worker processes after N tasks (null disables).

Early stopping

- early_stopping_patience: Stop after N iterations without improvement (null disables).
- convergence_threshold: Minimum improvement required to reset patience.
- early_stopping_metric: Metric name to track (e.g., "combined_score").

LLM (shared defaults)

- llm.api_base: Base URL for OpenAI-compatible API.
- llm.api_key: API key; null uses env OPENAI_API_KEY. Supports ${VAR} (entire string only).
- llm.system_message: Default system message for models (overridden by prompt.system_message at load time).
- llm.temperature: Sampling temperature.
- llm.top_p: Nucleus sampling parameter.
- llm.max_tokens: Max tokens in generated responses.
- llm.timeout: Request timeout (seconds).
- llm.retries: Number of retries on failure.
- llm.retry_delay: Delay between retries (seconds).
- llm.random_seed: Optional seed forwarded to model APIs that support it.
- llm.reasoning_effort: Optional reasoning control for models that support it.

LLM (model lists)

- llm.models: List of evolution models (each has name + weight and can override any LLMModelConfig field below).
- llm.evaluator_models: Optional models for LLM-based evaluator feedback (defaults to llm.models when empty).
- llm.primary_model / llm.primary_model_weight: Legacy single primary model config.
- llm.secondary_model / llm.secondary_model_weight: Legacy secondary model config (weight <= 0 disables).

LLMModelConfig (per-model overrides)

- name: Model name (required).
- weight: Ensemble weight for sampling.
- api_base, api_key: Per-model API overrides.
- init_client: Optional custom client factory.
- system_message, temperature, top_p, max_tokens: Per-model generation overrides.
- timeout, retries, retry_delay: Per-model request overrides.
- random_seed: Per-model seed override.
- reasoning_effort: Per-model reasoning control.

Prompt

- prompt.template_dir: Optional custom template directory.
- prompt.system_message: System prompt for evolution.
- prompt.evaluator_system_message: System prompt for evaluator (if LLM feedback used).
- prompt.num_top_programs: Number of top programs included in prompt.
- prompt.num_diverse_programs: Number of diverse programs included in prompt.
- prompt.use_template_stochasticity: Randomize prompt templates for diversity.
- prompt.template_variations: Alternate phrasing snippets for template parts.
- prompt.use_meta_prompting: Meta-prompting toggle (not implemented).
- prompt.meta_prompt_weight: Weight for meta-prompting (not implemented).
- prompt.include_artifacts: Include evaluator artifacts in prompts.
- prompt.max_artifact_bytes: Artifact size cap in prompt.
- prompt.artifact_security_filter: Redact common secrets from artifacts before prompting.
- prompt.suggest_simplification_after_chars: Suggest simplification when program exceeds this length.
- prompt.include_changes_under_chars: Include change descriptions if diff is smaller than this.
- prompt.concise_implementation_max_lines: Label "concise" if <= this many lines.
- prompt.comprehensive_implementation_min_lines: Label "comprehensive" if >= this many lines.
- prompt.code_length_threshold: Deprecated (use suggest_simplification_after_chars).

Database / MAP-Elites

- database.db_path: Path to persist DB (null = in-memory only).
- database.in_memory: Keep DB in memory for speed.
- database.log_prompts: Log prompts/responses into programs/<id>.json.
- database.population_size: Max number of programs kept.
- database.archive_size: Elite archive size.
- database.num_islands: Number of islands (separate sub-populations).
- database.elite_selection_ratio: Fraction treated as elites.
- database.exploration_ratio: Exploration share of selection.
- database.exploitation_ratio: Exploitation share of selection.
- database.diversity_metric: Diversity metric ("edit_distance" or "feature_based").
- database.feature_dimensions: Feature names for MAP-Elites bins. Built-ins: complexity, diversity, score. Custom dims must match evaluator metrics and be raw (continuous) values.
- database.feature_bins: Number of bins per feature (int for all or map per feature).
- database.diversity_reference_size: Sample size for diversity scoring.
- database.migration_interval: How often to migrate between islands (iterations).
- database.migration_rate: Fraction of top programs to migrate.
- database.random_seed: Random seed for database sampling (defaults to 42).
- database.artifacts_base_path: Base path for artifact storage (defaults to db_path/artifacts).
- database.artifact_size_threshold: Size threshold for artifact storage (bytes).
- database.cleanup_old_artifacts: Whether to delete old artifact dirs.
- database.artifact_retention_days: Retention period for old artifacts.
- database.novelty_llm: Internal LLM reference for novelty (not set via YAML).
- database.embedding_model: Embedding model name for similarity filtering.
- database.similarity_threshold: Similarity cutoff for near-duplicate filtering.

Evaluator

- evaluator.timeout: Max evaluation time (seconds).
- evaluator.max_retries: Retries if evaluation fails.
- evaluator.memory_limit_mb: Memory limit for evaluations (not implemented).
- evaluator.cpu_limit: CPU limit for evaluations (not implemented).
- evaluator.cascade_evaluation: Enable multi-stage evaluation.
- evaluator.cascade_thresholds: Thresholds to advance cascade stages.
- evaluator.parallel_evaluations: Number of parallel evals.
- evaluator.distributed: Distributed evaluation toggle (not implemented).
- evaluator.use_llm_feedback: Enable LLM-based evaluator feedback.
- evaluator.llm_feedback_weight: Weight for LLM feedback in final score.
- evaluator.enable_artifacts: Enable artifact collection.
- evaluator.max_artifact_storage: Max artifact storage per program (bytes).

Evolution trace

- evolution_trace.enabled: Enable trace logging.
- evolution_trace.format: jsonl, json, or hdf5.
- evolution_trace.include_code: Include full code in traces.
- evolution_trace.include_prompts: Include prompts/responses in traces.
- evolution_trace.output_path: Custom output path.
- evolution_trace.buffer_size: Buffered entries before write.
- evolution_trace.compress: Compress trace file (jsonl only).

Notes

- allow_full_rewrites appears in some example YAMLs, but it is not a supported config field in the current codebase. Use diff_based_evolution: false to force full rewrites.
