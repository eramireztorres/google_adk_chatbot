{"id": "294f76c0-c91a-43d0-9875-0e50257cf24e", "code": "import os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            # Append a standardized language tag for chunk tagging synergy\n            return f\"\\n\\n#### [{lang_tag}] {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\[A2A\\]', breadcrumb): project_tags.append(\"[A2A]\")\n            if re.search(r'\\[WORKFLOW\\]', breadcrumb): project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    lang_tag = \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                c.page_content = f\"{prefix} {lang_tag} {breadcrumb} {p.metadata.get('tags','')}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        for i, d in enumerate(docs):\n            # Include metadata tags to help reranker identify language and completeness\n            lang_tag = \"[LANG=Unknown]\"\n            if \"[DOC_CODE]\" in d.page_content:\n                # Try detect language from breadcrumb or content heuristics\n                if re.search(r'```python', d.page_content, re.I):\n                    lang_tag = \"[LANG=Python]\"\n                elif re.search(r'```go', d.page_content, re.I):\n                    lang_tag = \"[LANG=Go]\"\n                elif re.search(r'```java', d.page_content, re.I):\n                    lang_tag = \"[LANG=Java]\"\n            completeness_tag = \"[COMPLETE]\" if re.search(r'^\\s*(class|func|interface|def|type)\\s', d.page_content, re.I|re.M) else \"[PARTIAL]\"\n            \n            content_snippet = d.page_content[:1300].replace('\\n', ' ')\n            packed.append(f\"[{i}] {lang_tag} {completeness_tag} {content_snippet}\")\n        \n        prompt = (\n            \"Role: ADK Expert Reranker.\\n\"\n            \"Goal: Score each chunk from 0 to 100 on relevance to the query, prioritizing:\\n\"\n            \"1) Exact API names or full definitions over partial snippets.\\n\"\n            \"2) Code examples executable in the requested language.\\n\"\n            \"3) Language requested by user query (detect language tags).\\n\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return JSON ONLY with format: {'scores': {chunk_id: score, ...}}\\n\"\n            \"Scores must be integers 0 to 100.\"\n        )\n        \n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            # Use regex to find JSON if model adds fluff\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match: return docs[:self.rerank_top_n]\n            \n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)), \n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))), \n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n\n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n\n        # 3. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n\n        # 4. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n\n        # Summarize parent contexts to reduce context length and improve generation relevance\n        def summarize_parent(text: str) -> str:\n            max_len = 1000\n            if len(text) > max_len:\n                return text[:max_len].rstrip() + \"\\n... [truncated]\"\n            return text\n\n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                # Filter parent context by language tag similarly\n                lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', parent.page_content)\n                parent_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n                # Accept unknown language parents for Python queries to preserve recall\n                if requested_lang == \"Python\" and parent_lang not in (\"Python\", \"Unknown\"):\n                    continue\n                elif requested_lang != \"Python\" and parent_lang != requested_lang:\n                    continue\n\n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                parent_summary = summarize_parent(parent.page_content)\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent_summary}\\n</source>\\n\\n\"\n\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using ONLY the provided context.\\n\"\n            \"Rules:\\n\"\n            \"1. If the answer is not found in the context, respond exactly: 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc or code snippet, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n\n        try:\n            res = self.llm.invoke(prompt)\n        except Exception as e:\n            print(f\"LLM generation failed: {e}\")\n            return {\"answer\": \"I don't know from the provided documentation\", \"contexts\": final_contexts}\n        finally:\n            gc.collect()\n\n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n", "language": "python", "parent_id": "598c6aee-2a6c-4153-ab3a-e5552d3d09dc", "generation": 3, "timestamp": 1769730160.4602578, "iteration_found": 51, "metrics": {"combined_score": 0.5539196428571429, "num_samples": 10}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 48 lines with 84 lines", "parent_metrics": {"combined_score": 0.5389196428571429, "num_samples": 10}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert RAG system optimizer for Google ADK documentation. Improve the code to maximize RAG-pipeline performance.\n\nThe current architecture uses a **Parent-Child Retrieval** system with **Hybrid Search** and **LLM Reranking**.\n\n### High-Leverage Evolution Points:\n\n1. **Hyperparameter Synergy**: Optimize the balance between `chunk_size` (for retrieval precision), `top_k_vector/bm25` (for recall), and `weight_vector/bm25`. The documentation has many exact API names which may favor BM25, while conceptual \"how-to\" queries favor Vector.\n2. **Reranker Prompt Engineering**: The `_llm_rerank` prompt is critical. Evolve it to better identify relevance, handle multi-language snippets, or detect if a chunk contains a complete API definition vs. a partial snippet.\n3. **Metadata-Rich Ingestion**: Enhance `_chunk_document` to include more context in `breadcrumb` and `tagging`. Consider adding language-specific tags or project-area identifiers (e.g. `[A2A]`, `[WORKFLOW]`) to help the reranker and generator.\n4. **Context Assembly & Prompting**: Optimize the `context_block` formatting in `query`. Experiment with summarizing parent context or using XML-style tags to separate sources. Refine the final generation prompt for better \"Quote then Explain\" adherence.\n5. **Cross-Language Filtering**: Implement logic to detect the user's requested language and prioritize or filter retrieved chunks to reduce cross-language noise.\n\n**STRICT RULES**:\n- **Fork-Safety**: Avoid any top-level imports of `langchain`, `agno`, or `openai`. Use lazy imports inside methods.\n- **Compatibility**: Ensure `evaluate_rag(docs_path, query)` maintains its signature.\n- **Cleanup**: Always call `gc.collect()` after LLM calls or retrieval to maintain memory stability.\n\n**Example Improvement (Reranker Logic)**:\n```python\n# You can evolve the reranker prompt to be more specific:\nprompt = (\n    \"Role: ADK Expert Reranker. \"\n    \"Goal: Select chunks that provide EXECUTABLE code for the query. \"\n    f\"Query: {query}\\n\"\n    \"Chunks: ... \"\n)\n```\n- Maintain `evaluate_rag(docs_path, query)` signature and return keys: `answer`, `contexts`.\n- Keep `RAGSystem` class structure and lazy-loading in `__init__`.\n", "user": "# Current Program Information\n- Fitness: 0.5389\n- Feature coordinates: combined_score=0.54\n- Focus areas: - Fitness declined: 0.5918 \u2192 0.5389. Consider revising recent changes.\n- Exploring combined_score=0.54 region of solution space\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### raw_scores\n```\n[0.09583333333333334, 0.5041666666666667, 0.66, 0.5821428571428572, 0.5375000000000001, 0.685, 0.5833333333333334, 0.6630952380952382, 0.49479166666666674, 0.5833333333333334]\n```\n\n### error_details\n```\n[{'sample': 3, 'type': 'code_error', 'message': 'Syntax Error: invalid syntax (<unknown>, line 1)', 'bad_code': '> def get_weather(city: str) -> dict:\\n>     \"\"\"Retrieves weather for a city.\"\"\"\\n>     return {\"status\": \"success\", \"temperature\": \"25\u00b0C\"}\\n>\\n\\nfrom google.adk.tools import FunctionTool\\n\\ndef get_weather(city: str) -> dict:\\n    \"\"\"Retrieves weather for a city.\"\"\"\\n    return {\"status\": \"success\", \"temperature\": \"25\u00b0C\"}\\n\\n# Create a FunctionTool wrapping the function\\nweather_tool = FunctionTool(func=get_weather)\\n\\nfrom google.adk.tools import FunctionTool\\n\\ndef get_weather(city: str) -> dict:\\n    \"\"\"Retrieves weather for a city.\"\"\"\\n    return {\"status\": \"success\", \"temperature\": \"25\u00b0C\"}\\n\\nweather_tool = FunctionTool(func=get_weather)\\n\\n# Now weather_tool can be added to an agent\\'s tools list'}, {'sample': 4, 'type': 'code_error', 'message': '[\"Instantiation Error on line 57: name \\'get_weather\\' is not defined\", \"Instantiation Error on line 73: name \\'agent\\' is not defined\"]', 'bad_code': 'import asyncio\\nimport datetime\\nfrom zoneinfo import ZoneInfo\\n\\nfrom google.genai import types\\nfrom google.adk.agents.llm_agent import LlmAgent\\nfrom google.adk.runners import Runner\\nfrom google.adk.sessions import InMemorySessionService\\nfrom google.adk.planners import BuiltInPlanner\\nfrom google.genai.types import ThinkingConfig\\n\\n# --- Define example tool functions ---\\n\\ndef get_weather(city: str) -> dict:\\n    \"\"\"Retrieves the current weather report for a specified city.\"\"\"\\n    if city.lower() == \"new york\":\\n        return {\\n            \"status\": \"success\",\\n            \"report\": (\\n                \"The weather in New York is sunny with a temperature of 25 degrees \"\\n                \"Celsius (77 degrees Fahrenheit).\"\\n            ),\\n        }\\n    else:\\n        return {\\n            \"status\": \"error\",\\n            \"error_message\": f\"Weather information for \\'{city}\\' is not available.\",\\n        }\\n\\ndef get_current_time(city: str) -> dict:\\n    \"\"\"Returns the current time in a specified city.\"\"\"\\n    if city.lower() == \"new york\":\\n        tz_identifier = \"America/New_York\"\\n    else:\\n        return {\\n            \"status\": \"error\",\\n            \"error_message\": f\"Sorry, I don\\'t have timezone information for {city}.\",\\n        }\\n\\n    tz = ZoneInfo(tz_identifier)\\n    now = datetime.datetime.now(tz)\\n    report = f\\'The current time in {city} is {now.strftime(\"%Y-%m-%d %H:%M:%S %Z%z\")}\\'\\n    return {\"status\": \"success\", \"report\": report}\\n\\n# --- Configure the agent ---\\n\\n# Step 1: Create a ThinkingConfig\\nthinking_config = ThinkingConfig(\\n    include_thoughts=True,   # Ask the model to include its thoughts in the response\\n    thinking_budget=256      # Limit the \\'thinking\\' to 256 tokens (adjust as needed)\\n)\\n\\n# Step 2: Instantiate BuiltInPlanner with the thinking config\\nplanner = BuiltInPlanner(thinking_config=thinking_config)\\n\\n# Step 3: Create the LlmAgent with model, instruction, planner, and tools\\nagent = LlmAgent(\\n    model=\"gemini-2.5-pro-preview-03-25\",  # Replace with your model name\\n    name=\"weather_and_time_agent\",\\n    instruction=\"You are an agent that returns time and weather\",\\n    planner=planner,\\n    tools=[get_weather, get_current_time]\\n)\\n\\n# --- Setup session and runner ---\\n\\nAPP_NAME = \"weather_app\"\\nUSER_ID = \"1234\"\\nSESSION_ID = \"session1234\"\\n\\nsession_service = InMemorySessionService()\\nsession = session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\\nrunner = Runner(agent=agent, app_name=APP_NAME, session_service=session_service)\\n\\n# --- Function to call the agent with a query ---\\n\\ndef call_agent(query: str):\\n    content = types.Content(role=\\'user\\', parts=[types.Part(text=query)])\\n    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\\n\\n    for event in events:\\n        print(f\"\\\\nDEBUG EVENT: {event}\\\\n\")\\n        if event.is_final_response() and event.content:\\n            final_answer = event.content.parts[0].text.strip()\\n            print(\"\\\\n\ud83d\udfe2 FINAL ANSWER\\\\n\", final_answer, \"\\\\n\")\\n\\n# --- Example usage ---\\n\\nif __name__ == \"__main__\":\\n    call_agent(\"If it\\'s raining in New York right now, what is the current temperature?\")'}, {'sample': 5, 'type': 'code_error', 'message': 'Syntax Error: invalid syntax (<unknown>, line 1)', 'bad_code': '> async for event in self.some_sub_agent.run_async(ctx):\\n>     # Optionally inspect or log the event\\n>     yield event  # Pass the event up\\n>\\n\\n> # Read data set by a previous agent\\n> previous_result = ctx.session.state.get(\"some_key\")\\n> \\n> # Make a decision based on state\\n> if previous_result == \"some_value\":\\n>     # ... call a specific sub-agent ...\\n> else:\\n>     # ... call another sub-agent ...\\n>\\n\\nfrom typing import AsyncGenerator\\nfrom google.adk.agents import BaseAgent, LlmAgent\\nfrom google.adk.agents.invocation_context import InvocationContext\\nfrom google.adk.events import Event\\n\\nclass RoutingAgent(BaseAgent):\\n    # Define sub-agents as instance attributes\\n    agent_a: LlmAgent\\n    agent_b: LlmAgent\\n\\n    model_config = {\"arbitrary_types_allowed\": True}\\n\\n    def __init__(self, name: str, agent_a: LlmAgent, agent_b: LlmAgent):\\n        # Register sub_agents list for the framework\\n        sub_agents_list = [agent_a, agent_b]\\n        super().__init__(name=name, agent_a=agent_a, agent_b=agent_b, sub_agents=sub_agents_list)\\n\\n    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\\n        # Access a key in session state to decide routing\\n        route_key = ctx.session.state.get(\"route_key\")\\n\\n        if route_key == \"use_agent_a\":\\n            # Route to agent_a\\n            async for event in self.agent_a.run_async(ctx):\\n                yield event\\n        elif route_key == \"use_agent_b\":\\n            # Route to agent_b\\n            async for event in self.agent_b.run_async(ctx):\\n                yield event\\n        else:\\n            # Default or fallback behavior\\n            # For example, yield a simple event or run agent_a by default\\n            async for event in self.agent_a.run_async(ctx):\\n                yield event'}, {'sample': 6, 'type': 'code_error', 'message': 'Syntax Error: invalid syntax (<unknown>, line 1)', 'bad_code': '> from google.adk.tools import ToolContext, FunctionTool\\n> \\n> def update_user_preference(preference: str, value: str, tool_context: ToolContext):\\n>     \"\"\"Updates a user-specific preference.\"\"\"\\n>     user_prefs_key = \"user:preferences\"\\n>     # Get current preferences or initialize if none exist\\n>     preferences = tool_context.state.get(user_prefs_key, {})\\n>     preferences[preference] = value\\n>     # Write the updated dictionary back to the state\\n>     tool_context.state[user_prefs_key] = preferences\\n>     print(f\"Tool: Updated user preference \\'{preference}\\' to \\'{value}\\'\")\\n>     return {\"status\": \"success\", \"updated_preference\": preference}\\n> \\n> pref_tool = FunctionTool(func=update_user_preference)\\n>\\n\\nfrom google.adk.tools import ToolContext, FunctionTool\\n\\ndef update_user_preference(preference: str, value: str, tool_context: ToolContext):\\n    \"\"\"Updates a user-specific preference in the session state.\"\"\"\\n    user_prefs_key = \"user:preferences\"\\n    # Read existing preferences or initialize empty dict\\n    preferences = tool_context.state.get(user_prefs_key, {})\\n    # Update the preference\\n    preferences[preference] = value\\n    # Write back the updated preferences to state\\n    tool_context.state[user_prefs_key] = preferences\\n    print(f\"Tool: Updated user preference \\'{preference}\\' to \\'{value}\\'\")\\n    return {\"status\": \"success\", \"updated_preference\": preference}\\n\\n# Create the tool\\npref_tool = FunctionTool(func=update_user_preference)'}, {'sample': 7, 'type': 'code_error', 'message': 'Syntax Error: unterminated string literal (detected at line 63) (<unknown>, line 63)', 'bad_code': 'from google.adk.agents import SequentialAgent, LlmAgent\\n\\nvalidator = LlmAgent(name=\"ValidateInput\", instruction=\"Validate the input.\", output_key=\"validation_status\")\\nprocessor = LlmAgent(name=\"ProcessData\", instruction=\"Process data if {validation_status} is \\'valid\\'.\", output_key=\"result\")\\nreporter = LlmAgent(name=\"ReportResult\", instruction=\"Report the result from {result}.\")\\n\\ndata_pipeline = SequentialAgent(\\n    name=\"DataPipeline\",\\n    sub_agents=[validator, processor, reporter]\\n)\\n# validator runs -> saves to state[\\'validation_status\\']\\n# processor runs -> reads state[\\'validation_status\\'], saves to state[\\'result\\']\\n# reporter runs -> reads state[\\'result\\']\\n\\n# Full Example: Code Development Pipeline\\ncode_writer_agent = LlmAgent(\\n    name=\"CodeWriterAgent\",\\n    model=GEMINI_MODEL,\\n    instruction=\"You are a Python Code Generator. ...\",\\n    output_key=\"generated_code\"\\n)\\n\\ncode_reviewer_agent = LlmAgent(\\n    name=\"CodeReviewerAgent\",\\n    model=GEMINI_MODEL,\\n    instruction=\"You are an expert Python Code Reviewer. ... {generated_code} ...\",\\n    output_key=\"review_comments\"\\n)\\n\\ncode_refactorer_agent = LlmAgent(\\n    name=\"CodeRefactorerAgent\",\\n    model=GEMINI_MODEL,\\n    instruction=\"You are a Python Code Refactoring AI. ... {generated_code} ... {review_comments} ...\",\\n    output_key=\"refactored_code\"\\n)\\n\\ncode_pipeline_agent = SequentialAgent(\\n    name=\"CodePipelineAgent\",\\n    sub_agents=[code_writer_agent, code_reviewer_agent, code_refactorer_agent],\\n    description=\"Executes a sequence of code writing, reviewing, and refactoring.\"\\n)\\n\\nroot_agent = code_pipeline_agent\\n\\nfrom google.adk.agents import SequentialAgent, LlmAgent\\nfrom google.adk.runner import InMemoryRunner\\nfrom google.adk.sessions import Session\\nfrom google.genai.types import Content, Part\\nfrom google.adk.events import Event\\nimport asyncio\\n\\n# Replace GEMINI_MODEL with your actual model identifier or model object\\nGEMINI_MODEL = \"gemini-2.0-flash\"  # Example model name\\n\\n# --- Define the three LlmAgents ---\\n\\ncode_writer_agent = LlmAgent(\\n    name=\"CodeWriterAgent\",\\n    model=GEMINI_MODEL,\\n    instruction=(\\n        \"You are a Python Code Generator.\\\\n\"\\n        \"Based *only* on the user\\'s request, write Python code that fulfills the requirement.\\\\n\"\\n        \"Output *only* the complete Python code block, enclosed in triple backticks (\\n\\n).\\\\n\"\\n        \"Do not add any other text before or after the code block.\"\\n    ),\\n    output_key=\"generated_code\"\\n)\\n\\ncode_reviewer_agent = LlmAgent(\\n    name=\"CodeReviewerAgent\",\\n    model=GEMINI_MODEL,\\n    instruction=(\\n        \"You are an expert Python Code Reviewer.\\\\n\"\\n        \"Your task is to provide constructive feedback on the provided code.\\\\n\\\\n\"\\n        \"**Code to Review:**\\\\n\"\\n        \"\\n\\n\\\\n\\\\n\"\\n        \"**Review Criteria:**\\\\n\"\\n        \"1.  **Correctness:** Does the code work as intended? Are there logic errors?\\\\n\"\\n        \"2.  **Readability:** Is the code clear and easy to understand? Follows PEP 8 style guidelines?\\\\n\"\\n        \"3.  **Efficiency:** Is the code reasonably efficient? Any obvious performance bottlenecks?\\\\n\"\\n        \"4.  **Edge Cases:** Does the code handle potential edge cases or invalid inputs gracefully?\\\\n\"\\n        \"5.  **Best Practices:** Does the code follow common Python best practices?\\\\n\\\\n\"\\n        \"**Output:**\\\\n\"\\n        \"Provide your feedback as a concise, bulleted list. Focus on the most important points for improvement.\\\\n\"\\n        \"If the code is excellent and requires no changes, simply state: \\\\\"No major issues found.\\\\\"\\\\n\"\\n        \"Output *only* the review comments or the \\\\\"No major issues\\\\\" statement.\"\\n    ),\\n    output_key=\"review_comments\"\\n)\\n\\ncode_refactorer_agent = LlmAgent(\\n    name=\"CodeRefactorerAgent\",\\n    model=GEMINI_MODEL,\\n    instruction=(\\n        \"You are a Python Code Refactoring AI.\\\\n\"\\n        \"Your goal is to improve the given Python code based on the provided review comments.\\\\n\\\\n\"\\n        \"**Original Code:**\\\\n\"\\n        \"\\n\\n\\\\n\\\\n\"\\n        \"**Review Comments:**\\\\n\"\\n        \"{review_comments}\\\\n\\\\n\"\\n        \"**Task:**\\\\n\"\\n        \"Carefully apply the suggestions from the review comments to refactor the original code.\\\\n\"\\n        \"If the review comments state \\\\\"No major issues found,\\\\\" return the original code unchanged.\\\\n\"\\n        \"Ensure the final code is complete, functional, and includes necessary imports and docstrings.\\\\n\\\\n\"\\n        \"**Output:**\\\\n\"\\n        \"Output *only* the final, refactored Python code block, enclosed in triple backticks (\\n\\n).\\\\n\"\\n        \"Do not add any other text before or after the code block.\"\\n    ),\\n    output_key=\"refactored_code\"\\n)\\n\\n# --- Create the SequentialAgent pipeline ---\\n\\ncode_pipeline_agent = SequentialAgent(\\n    name=\"CodePipelineAgent\",\\n    sub_agents=[code_writer_agent, code_reviewer_agent, code_refactorer_agent],\\n    description=\"Executes a sequence of code writing, reviewing, and refactoring.\"\\n)\\n\\n# --- Run the pipeline with InMemoryRunner ---\\n\\nasync def main():\\n    runner = InMemoryRunner(code_pipeline_agent, \"CodePipelineApp\")\\n    session = runner.session_service().create_session(\"CodePipelineApp\", \"user_123\")\\n    user_prompt = \"Write a Python function to compute the factorial of a number.\"\\n\\n    content = Content.from_parts(Part.from_text(user_prompt))\\n\\n    # Run the agent asynchronously and collect events\\n    event_stream = runner.run_async(\"user_123\", session.id(), content)\\n\\n    async for event in event_stream:\\n        if event.final_response():\\n            print(\"Final Response:\")\\n            print(event.stringify_content())\\n\\nif __name__ == \"__main__\":\\n    asyncio.run(main())'}, {'sample': 8, 'type': 'code_error', 'message': '[\"Instantiation Error on line 11: name \\'exit_loop\\' is not defined\", \"Instantiation Error on line 33: name \\'refiner_agent\\' is not defined\"]', 'bad_code': 'from google.adk.agents import LoopAgent, LlmAgent, SequentialAgent\\nfrom google.adk.tools.tool_context import ToolContext\\n\\n# Define a tool function that triggers escalation to exit the loop early\\ndef exit_loop(tool_context: ToolContext):\\n    print(f\"[Tool Call] exit_loop triggered by {tool_context.agent_name}\")\\n    tool_context.actions.escalate = True\\n    return {}\\n\\n# Example sub-agent that checks a condition and calls exit_loop tool if met\\nrefiner_agent = LlmAgent(\\n    name=\"RefinerAgent\",\\n    model=\"gemini-2.0-flash\",\\n    instruction=\"\"\"\\nYou are a refining agent. If the condition to stop is met, call the exit_loop tool.\\nOtherwise, continue refining.\\n\"\"\",\\n    tools=[exit_loop],  # Provide the exit_loop tool to this agent\\n    output_key=\"current_document\"\\n)\\n\\n# Another sub-agent, e.g., a critic or checker\\ncritic_agent = LlmAgent(\\n    name=\"CriticAgent\",\\n    model=\"gemini-2.0-flash\",\\n    instruction=\"\"\"\\nYou are a critic agent that reviews the document and decides if it needs refinement.\\n\"\"\",\\n    output_key=\"criticism\"\\n)\\n\\n# Create the LoopAgent with sub-agents and max_iterations\\nloop_agent = LoopAgent(\\n    name=\"RefinementLoop\",\\n    sub_agents=[critic_agent, refiner_agent],\\n    max_iterations=5  # Optional max iteration limit\\n)\\n\\n# The LoopAgent will run the critic and refiner repeatedly.\\n# When refiner_agent calls exit_loop (setting escalate=True), the loop exits early.'}]\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 39 lines with 48 lines\nChange 2: Replace 37 lines with 53 lines\nChange 3: Replace 40 lines with 54 lines\nChange 4: Replace 65 lines with 67 lines\n- Metrics: combined_score: 0.5918, num_samples: 10.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Change 1: Replace 9 lines with 9 lines\nChange 2: Replace 10 lines with 12 lines\nChange 3: Replace 33 lines with 37 lines\nChange 4: Replace 47 lines with 62 lines\nChange 5: Replace 77 lines with 83 lines\n- Metrics: combined_score: 0.6114, num_samples: 10.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace 9 lines with 11 lines\nChange 2: Replace 10 lines with 11 lines\nChange 3: Replace 21 lines with 24 lines\nChange 4: Replace 47 lines with 47 lines\nChange 5: Replace 28 lines with 31 lines\nChange 6: Replace 45 lines with 46 lines\n- Metrics: combined_score: 0.6422, num_samples: 10.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.6422)\n```python\nimport os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            # Append a standardized language tag for chunk tagging synergy\n            return f\"\\n\\n#### [{lang_tag}] {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\[A2A\\]', breadcrumb): project_tags.append(\"[A2A]\")\n            if re.search(r'\\[WORKFLOW\\]', breadcrumb): project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    lang_tag = \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                # Also add project area tag into chunk content for reranker synergy\n                project_area = p.metadata.get(\"tags\", \"[GENERAL]\")\n                c.page_content = f\"{prefix} {lang_tag} {project_area} {breadcrumb}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                c.metadata[\"project_area\"] = project_area\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM with enhanced prompt for multi-language & completeness detection.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        requested_lang = None\n        # Detect requested language from query for prompt emphasis\n        lang_match = re.search(r'\\b(python|go|java)\\b', query, re.I)\n        if lang_match:\n            requested_lang = lang_match.group(1).lower()\n\n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1400].replace('\\n', ' ').strip()\n            completeness_tag = \"[COMPLETE_API]\" if re.search(r'\\b(class|func|def|interface|type|package|func\\s+main)\\s+\\w*', snippet, re.I) else \"[PARTIAL]\"\n            lang = d.metadata.get(\"language\", \"unknown\").lower()\n            requested_lang_tag = \"[REQUESTED_LANG]\" if requested_lang and lang == requested_lang else \"\"\n            tags = d.metadata.get(\"tags\", \"\")\n            breadcrumb = d.metadata.get(\"breadcrumb\", \"\")\n            packed.append(f\"[{i}] {completeness_tag} {requested_lang_tag} Tags:{tags} Breadcrumb:{breadcrumb}\\n{snippet}\")\n\n        prompt = (\n            \"Role: ADK Expert Reranker.\\n\"\n            \"Goal: Score each chunk from 0 to 100 for relevance to the query.\\n\"\n            \"Prioritize chunks with:\\n\"\n            \"- Exact API names matching the query\\n\"\n            \"- Complete API definitions over partial snippets\\n\"\n            \"- Code examples in the user's requested programming language\\n\"\n            \"- Proper handling of multi-language snippets\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return JSON object with 'scores' mapping chunk IDs to numeric scores.\"\n        )\n\n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match:\n                return docs[:self.rerank_top_n]\n\n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)),\n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))),\n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            # Use chunk language tag in content or fallback to unknown\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n        else:\n            # If too few, fallback to original for recall preservation\n            pass\n        \n        # 3. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 4. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                # Filter parent context by language tag similarly\n                lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', parent.page_content)\n                parent_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n                # Accept unknown language parents for Python queries to preserve recall\n                if requested_lang == \"Python\" and parent_lang not in (\"Python\", \"Unknown\"):\n                    continue\n                elif requested_lang != \"Python\" and parent_lang != requested_lang:\n                    continue\n                \n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent.page_content}\\n</source>\\n\\n\"\n\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            \"6. Use XML tags to indicate sources.\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        # Use caching for llm.invoke to reduce latency on repeated queries (optional)\n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n\n```\nKey features: Performs well on combined_score (0.6422), Performs well on num_samples (10.0000)\n\n### Program 2 (Score: 0.6114)\n```python\nimport os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            # Normalize label to title case and add language tag explicitly in header for clarity\n            normalized_label = label.title()\n            return f\"\\n\\n#### [{lang_tag}] {normalized_label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\bA2A\\b', breadcrumb, re.I) or re.search(r'\\ba2a\\b', source, re.I):\n                project_tags.append(\"[A2A]\")\n            if re.search(r'\\bWORKFLOW\\b', breadcrumb, re.I) or re.search(r'workflow', source, re.I):\n                project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"[GENERAL]\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging, fallback to parent's language tag\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    # fallback to parent's detected language tag if available\n                    parent_lang = p.metadata.get(\"language\", \"unknown\").capitalize()\n                    lang_tag = f\"[LANG={parent_lang}]\" if parent_lang != \"Unknown\" else \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                c.page_content = f\"{prefix} {lang_tag} {breadcrumb} {p.metadata.get('tags','')}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM with enhanced prompt for language, completeness, and snippet type detection.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        requested_lang = None\n        # Detect requested language from query for prompt emphasis\n        lang_match = re.search(r'\\b(python|go|java)\\b', query, re.I)\n        if lang_match:\n            requested_lang = lang_match.group(1).lower()\n        \n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1400].replace('\\n', ' ').strip()\n            completeness_tag = \"[COMPLETE_API]\" if re.search(r'\\b(class|func|def|interface|type|package|func\\s+main)\\s+\\w*', snippet, re.I) else \"[PARTIAL]\"\n            \n            # Mark language if available and if matches requested language\n            lang = d.metadata.get(\"language\", \"unknown\").lower()\n            lang_flag = \"[LANG_MATCH]\" if requested_lang and lang == requested_lang else \"[LANG_OTHER]\"\n            \n            tags = d.metadata.get(\"tags\", \"\")\n            breadcrumb = d.metadata.get(\"breadcrumb\", \"\")\n            packed.append(f\"[{i}] {completeness_tag} {lang_flag} Tags:{tags} Breadcrumb:{breadcrumb}\\n{snippet}\")\n\n        prompt = (\n            \"Role: ADK Expert Reranker.\\n\"\n            \"Goal: Assign a relevance score (0-100) to each chunk for the user query.\\n\"\n            \"Prioritize:\\n\"\n            \"- Chunks containing complete API definitions or well-formed code examples.\\n\"\n            \"- Chunks with exact API names matching the query.\\n\"\n            \"- Chunks in the user's requested programming language if specified (Python, Go, Java).\\n\"\n            \"- Penalize partial snippets and chunks in other languages.\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return JSON with 'scores' mapping chunk_id to score (0-100).\"\n        )\n\n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match:\n                # Fallback heuristic: rank by presence of requested language and completeness\n                def score_heuristic(doc):\n                    score = 0\n                    content = doc.page_content.lower()\n                    if requested_lang and f\"[lang={requested_lang}]\" in content:\n                        score += 50\n                    if re.search(r'\\b(class|func|def)\\b', content):\n                        score += 30\n                    if query.lower() in content:\n                        score += 20\n                    return score\n                scored_docs = sorted(docs, key=score_heuristic, reverse=True)\n                return scored_docs[:self.rerank_top_n]\n\n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)),\n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))),\n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            # Use chunk language tag in content or fallback to unknown\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n        \n        # 3. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 4. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                # Filter parent context by language tag similarly\n                lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', parent.page_content)\n                parent_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n                # Accept unknown language parents for Python queries to preserve recall\n                if requested_lang == \"Python\" and parent_lang not in (\"Python\", \"Unknown\"):\n                    continue\n                elif requested_lang != \"Python\" and parent_lang != requested_lang:\n                    continue\n                \n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent.page_content}\\n</source>\\n\\n\"\n\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            \"6. Use XML tags to indicate sources.\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        # Use LLM invoke with retry to improve robustness\n        try:\n            res = self.llm.invoke(prompt)\n        except Exception as e:\n            print(f\"LLM generation failed: {e}\")\n            return {\"answer\": \"I don't know from the provided documentation\", \"contexts\": final_contexts}\n        finally:\n            gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n\n```\nKey features: Performs well on combined_score (0.6114), Performs well on num_samples (10.0000)\n\n### Program 3 (Score: 0.5918)\n```python\nimport os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    # Only ingest .md files, skip hidden and non-API docs\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n\n                        # Add language and project tags in chunk metadata by filename heuristics and content\n                        lang_tag = None\n                        # Detect language from filename and also from code fences in content for synergy\n                        if re.search(r'\\bpython\\b', file.lower()):\n                            lang_tag = \"[LANG_PYTHON]\"\n                        elif re.search(r'\\bgo\\b', file.lower()):\n                            lang_tag = \"[LANG_GO]\"\n                        elif re.search(r'\\bjava\\b', file.lower()):\n                            lang_tag = \"[LANG_JAVA]\"\n                        else:\n                            # Fallback: detect language from first code fence in text content\n                            code_lang_match = re.search(r'```(\\w+)', text_content)\n                            if code_lang_match:\n                                lang = code_lang_match.group(1).lower()\n                                if lang in (\"python\", \"go\", \"java\"):\n                                    lang_tag = f\"[LANG_{lang.upper()}]\"\n\n                        # Project area tags example: detect A2A, WORKFLOW from path or filename heuristics\n                        project_tag = None\n                        if \"a2a\" in root.lower() or \"a2a\" in file.lower():\n                            project_tag = \"[A2A]\"\n                        elif \"workflow\" in root.lower() or \"workflow\" in file.lower():\n                            project_tag = \"[WORKFLOW]\"\n\n                        chunks = self._chunk_document(text_content, file_path)\n                        # Inject tags into each chunk content for better reranking and generation\n                        for c in chunks:\n                            tags = []\n                            if lang_tag: tags.append(lang_tag)\n                            if project_tag: tags.append(project_tag)\n                            if tags:\n                                c.page_content = \" \".join(tags) + \" \" + c.page_content\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers.\"\"\"\n        # Simple regex for {% tab label=\"Python\" %} blocks\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1)\n            content = match.group(2)\n            return f\"\\n\\n#### {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n\n            # Detect language tag from first code fence in parent content\n            lang_match = re.search(r'```(\\w+)', p.page_content)\n            language = lang_match.group(1).lower() if lang_match else \"unknown\"\n            p.metadata[\"language\"] = language\n\n            # Heuristic project-area tagging based on breadcrumb or source path\n            if re.search(r'a2a|auth', breadcrumb, re.I) or re.search(r'a2a|auth', source, re.I):\n                p.metadata[\"project_area\"] = \"[A2A]\"\n            elif re.search(r'workflow', breadcrumb, re.I) or re.search(r'workflow', source, re.I):\n                p.metadata[\"project_area\"] = \"[WORKFLOW]\"\n            else:\n                p.metadata[\"project_area\"] = \"[GENERAL]\"\n\n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                c.page_content = f\"{prefix} {breadcrumb} {p.metadata['project_area']}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                c.metadata[\"language\"] = language\n                c.metadata[\"project_area\"] = p.metadata[\"project_area\"]\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM with enhanced prompt for code, language, and completeness.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1500].replace('\\n', ' ')  # flatten newlines for prompt\n            # Indicate if chunk looks like a full API def or partial snippet\n            is_complete_api = \"Complete API definition\" if re.search(r'^\\s*(class|func|interface|def|type)\\s', snippet, re.I|re.M) else \"Partial snippet\"\n            # Include language tag if present in metadata or content\n            lang_tag = \"[LANG=Unknown]\"\n            if \"[DOC_CODE]\" in d.page_content:\n                lang_search = re.search(r'\\[LANG=([A-Za-z]+)\\]', d.page_content)\n                if lang_search:\n                    lang_tag = f\"[LANG={lang_search.group(1)}]\"\n                else:\n                    # Fallback heuristic by code fences\n                    if re.search(r'```python', d.page_content, re.I):\n                        lang_tag = \"[LANG=Python]\"\n                    elif re.search(r'```go', d.page_content, re.I):\n                        lang_tag = \"[LANG=Go]\"\n                    elif re.search(r'```java', d.page_content, re.I):\n                        lang_tag = \"[LANG=Java]\"\n            packed.append(f\"[{i}] {lang_tag} ({is_complete_api}) {snippet}\")\n        \n        prompt = (\n            \"Role: Google ADK Expert Reranker.\\n\"\n            \"Goal: Given the user query and a list of documentation chunks, assign a relevance score 0-100. \"\n            \"Prioritize chunks with:\\n\"\n            \"- Exact API names matching the query,\\n\"\n            \"- Complete API definitions over partial snippets,\\n\"\n            \"- Relevant code examples,\\n\"\n            \"- Matching requested programming language if specified.\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return a JSON object with format: {'scores': {chunk_id: score, ...}} with scores as integers.\"\n        )\n        \n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            # Extract JSON robustly\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match: return docs[:self.rerank_top_n]\n            \n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            # Sort indices by score descending\n            ranked_indices = sorted(range(len(docs)), \n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))), \n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Detect requested language from query (if any)\n        requested_lang = None\n        lang_patterns = {\n            \"python\": r\"\\bpython\\b\",\n            \"go\": r\"\\bgo\\b\",\n            \"java\": r\"\\bjava\\b\",\n        }\n        for lang, pattern in lang_patterns.items():\n            if re.search(pattern, query_str, re.I):\n                requested_lang = lang.upper()\n                break\n\n        # 2. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # 3. Filter candidates by language tag if requested to reduce noise\n        if requested_lang:\n            filtered = []\n            lang_tag = f\"[LANG_{requested_lang}]\"\n            for c in candidates:\n                if lang_tag in c.page_content:\n                    filtered.append(c)\n            # Relax filtering if too few candidates remain to preserve recall\n            if filtered and len(filtered) >= max(3, self.rerank_top_n):\n                candidates = filtered\n\n        # 4. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 5. Parent Retrieval & Formatting with XML-style tags and summarized parents\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Summarize parent to first 1000 chars for conciseness\n                parent_summary = parent.page_content[:1000].strip() + (\"...\" if len(parent.page_content) > 1000 else \"\")\n                context_block += (\n                    f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent_summary}\\n</source>\\n\\n\"\n                )\n\n        # 6. Generation (Strict Grounding) with improved prompt to emphasize quote/explain and language\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using ONLY the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not found in the context, explicitly respond: 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc or code snippet, then provide your explanation.\\n\"\n            \"4. Only provide code or examples in the requested programming language if specified by the user. \"\n            \"If no language is specified, default to Python but mention that other languages exist.\\n\"\n            \"5. When quoting code, explicitly indicate the programming language of the snippet.\\n\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n\n```\nKey features: Performs well on combined_score (0.5918), Performs well on num_samples (10.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.5695)\n```python\nimport os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            return f\"\\n\\n#### [{lang_tag}] {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\[A2A\\]', breadcrumb): project_tags.append(\"[A2A]\")\n            if re.search(r'\\[WORKFLOW\\]', breadcrumb): project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    lang_tag = \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                c.page_content = f\"{prefix} {lang_tag} {breadcrumb} {p.metadata.get('tags','')}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        requested_lang = None\n        # Detect requested language from query for prompt emphasis\n        lang_match = re.search(r'\\b(python|go|java)\\b', query, re.I)\n        if lang_match:\n            requested_lang = lang_match.group(1).lower()\n\n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1400].replace('\\n', ' ').strip()\n            completeness_tag = \"[COMPLETE_API]\" if re.search(r'\\b(class|func|def|interface|type|package|func\\s+main)\\s+\\w*', snippet, re.I) else \"[PARTIAL]\"\n            lang = d.metadata.get(\"language\", \"unknown\").lower()\n            requested_lang_tag = \"[REQUESTED_LANG]\" if requested_lang and lang == requested_lang else \"\"\n            tags = d.metadata.get(\"tags\", \"\")\n            breadcrumb = d.metadata.get(\"breadcrumb\", \"\")\n            packed.append(f\"[{i}] {completeness_tag} {requested_lang_tag} Tags:{tags} Breadcrumb:{breadcrumb}\\n{snippet}\")\n\n        prompt = (\n            \"Role: ADK Expert Reranker.\\n\"\n            \"Goal: Score each chunk from 0 to 100 for relevance to the user query.\\n\"\n            \"Prioritize:\\n\"\n            \"- Exact API names matching the query.\\n\"\n            \"- Complete API definitions over partial snippets.\\n\"\n            \"- Code examples in the user's requested programming language if specified.\\n\"\n            \"- Proper handling of multi-language snippets.\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return a JSON object with 'scores' mapping chunk IDs to numeric scores.\"\n        )\n\n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match:\n                return docs[:self.rerank_top_n]\n\n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)),\n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))),\n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            # Use chunk language tag in content or fallback to unknown\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n        \n        # 3. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 4. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                # Filter parent context by language tag similarly\n                lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', parent.page_content)\n                parent_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n                # Accept unknown language parents for Python queries to preserve recall\n                if requested_lang == \"Python\" and parent_lang not in (\"Python\", \"Unknown\"):\n                    continue\n                elif requested_lang != \"Python\" and parent_lang != requested_lang:\n                    continue\n                \n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent.page_content}\\n</source>\\n\\n\"\n\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            \"6. Use XML tags to indicate sources.\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to num_samples\n\n### Program D2 (Score: 0.5847)\n```python\nimport os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            # Normalize label to title case and add language tag explicitly in header for clarity\n            normalized_label = label.title()\n            return f\"\\n\\n#### [{lang_tag}] {normalized_label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\bA2A\\b', breadcrumb, re.I) or re.search(r'\\ba2a\\b', source, re.I):\n                project_tags.append(\"[A2A]\")\n            if re.search(r'\\bWORKFLOW\\b', breadcrumb, re.I) or re.search(r'workflow', source, re.I):\n                project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"[GENERAL]\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging, fallback to parent's language tag\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    # fallback to parent's detected language tag if available\n                    parent_lang = p.metadata.get(\"language\", \"unknown\").capitalize()\n                    lang_tag = f\"[LANG={parent_lang}]\" if parent_lang != \"Unknown\" else \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                c.page_content = f\"{prefix} {lang_tag} {breadcrumb} {p.metadata.get('tags','')}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM with enhanced prompt for language, completeness, and snippet type detection.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        requested_lang = None\n        # Detect requested language from query for prompt emphasis\n        lang_match = re.search(r'\\b(python|go|java)\\b', query, re.I)\n        if lang_match:\n            requested_lang = lang_match.group(1).lower()\n        \n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1400].replace('\\n', ' ').strip()\n            completeness_tag = \"[COMPLETE_API]\" if re.search(r'\\b(class|func|def|interface|type|package|func\\s+main)\\s+\\w*', snippet, re.I) else \"[PARTIAL]\"\n            \n            # Mark language if available and if matches requested language\n            lang = d.metadata.get(\"language\", \"unknown\").lower()\n            lang_flag = \"[LANG_MATCH]\" if requested_lang and lang == requested_lang else \"[LANG_OTHER]\"\n            \n            tags = d.metadata.get(\"tags\", \"\")\n            breadcrumb = d.metadata.get(\"breadcrumb\", \"\")\n            packed.append(f\"[{i}] {completeness_tag} {lang_flag} Tags:{tags} Breadcrumb:{breadcrumb}\\n{snippet}\")\n\n        prompt = (\n            \"Role: ADK Expert Reranker.\\n\"\n            \"Goal: Assign a relevance score (0-100) to each chunk for the user query.\\n\"\n            \"Prioritize:\\n\"\n            \"- Chunks containing complete API definitions or well-formed code examples.\\n\"\n            \"- Chunks with exact API names matching the query.\\n\"\n            \"- Chunks in the user's requested programming language if specified (Python, Go, Java).\\n\"\n            \"- Penalize partial snippets and chunks in other languages.\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return JSON with 'scores' mapping chunk_id to score (0-100).\"\n        )\n\n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match:\n                # Fallback heuristic: rank by presence of requested language and completeness\n                def score_heuristic(doc):\n                    score = 0\n                    content = doc.page_content.lower()\n                    if requested_lang and f\"[lang={requested_lang}]\" in content:\n                        score += 50\n                    if re.search(r'\\b(class|func|def)\\b', content):\n                        score += 30\n                    if query.lower() in content:\n                        score += 20\n                    return score\n                scored_docs = sorted(docs, key=score_heuristic, reverse=True)\n                return scored_docs[:self.rerank_top_n]\n\n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)),\n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))),\n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            # Use chunk language tag in content or fallback to unknown\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n        \n        # 3. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 4. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                # Filter parent context by language tag similarly\n                lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', parent.page_content)\n                parent_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n                # Accept unknown language parents for Python queries to preserve recall\n                if requested_lang == \"Python\" and parent_lang not in (\"Python\", \"Unknown\"):\n                    continue\n                elif requested_lang != \"Python\" and parent_lang != requested_lang:\n                    continue\n                \n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent.page_content}\\n</source>\\n\\n\"\n        \n        # Summarize parent contexts to reduce context length and improve generation relevance\n        def summarize_parent(text: str) -> str:\n            # Keep first 1000 chars plus a note if truncated\n            max_len = 1000\n            if len(text) > max_len:\n                return text[:max_len].rstrip() + \"\\n... [truncated]\"\n            return text\n        \n        summarized_contexts = []\n        for ctx in final_contexts:\n            summarized_contexts.append(summarize_parent(ctx))\n        \n        context_block = \"\"\n        for i, ctx in enumerate(summarized_contexts):\n            p_id = top_chunks[i].metadata.get(\"parent_id\", f\"unknown_{i}\")\n            parent_meta = self.parent_docs.get(p_id)\n            src = os.path.basename(parent_meta.metadata.get(\"source\", \"unknown\")) if parent_meta else \"unknown\"\n            breadcrumb = parent_meta.metadata.get(\"breadcrumb\", \"\") if parent_meta else \"\"\n            context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{ctx}\\n</source>\\n\\n\"\n\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            \"6. Use XML tags to indicate sources.\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        # Use LLM invoke with retry to improve robustness\n        try:\n            res = self.llm.invoke(prompt)\n        except Exception as e:\n            print(f\"LLM generation failed: {e}\")\n            return {\"answer\": \"I don't know from the provided documentation\", \"contexts\": final_contexts}\n        finally:\n            gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to num_samples\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.6422, Type: Alternative)\n```python\nimport os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            # Append a standardized language tag for chunk tagging synergy\n            return f\"\\n\\n#### [{lang_tag}] {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\[A2A\\]', breadcrumb): project_tags.append(\"[A2A]\")\n            if re.search(r'\\[WORKFLOW\\]', breadcrumb): project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    lang_tag = \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                # Also add project area tag into chunk content for reranker synergy\n                project_area = p.metadata.get(\"tags\", \"[GENERAL]\")\n                c.page_content = f\"{prefix} {lang_tag} {project_area} {breadcrumb}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                c.metadata[\"project_area\"] = project_area\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM with enhanced prompt for multi-language & completeness detection.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        requested_lang = None\n        # Detect requested language from query for prompt emphasis\n        lang_match = re.search(r'\\b(python|go|java)\\b', query, re.I)\n        if lang_match:\n            requested_lang = lang_match.group(1).lower()\n\n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1400].replace('\\n', ' ').strip()\n            completeness_tag = \"[COMPLETE_API]\" if re.search(r'\\b(class|func|def|interface|type|package|func\\s+main)\\s+\\w*', snippet, re.I) else \"[PARTIAL]\"\n            lang = d.metadata.get(\"language\", \"unknown\").lower()\n            requested_lang_tag = \"[REQUESTED_LANG]\" if requested_lang and lang == requested_lang else \"\"\n            tags = d.metadata.get(\"tags\", \"\")\n            breadcrumb = d.metadata.get(\"breadcrumb\", \"\")\n            packed.append(f\"[{i}] {completeness_tag} {requested_lang_tag} Tags:{tags} Breadcrumb:{breadcrumb}\\n{snippet}\")\n\n        prompt = (\n            \"Role: ADK Expert Reranker.\\n\"\n            \"Goal: Score each chunk from 0 to 100 for relevance to the query.\\n\"\n            \"Prioritize chunks with:\\n\"\n            \"- Exact API names matching the query\\n\"\n            \"- Complete API definitions over partial snippets\\n\"\n            \"- Code examples in the user's requested programming language\\n\"\n            \"- Proper handling of multi-language snippets\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return JSON object with 'scores' mapping chunk IDs to numeric scores.\"\n        )\n\n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match:\n                return docs[:self.rerank_top_n]\n\n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)),\n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))),\n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            # Use chunk language tag in content or fallback to unknown\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n        else:\n            # If too few, fallback to original for recall preservation\n            pass\n        \n        # 3. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 4. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                # Filter parent context by language tag similarly\n                lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', parent.page_content)\n                parent_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n                # Accept unknown language parents for Python queries to preserve recall\n                if requested_lang == \"Python\" and parent_lang not in (\"Python\", \"Unknown\"):\n                    continue\n                elif requested_lang != \"Python\" and parent_lang != requested_lang:\n                    continue\n                \n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent.page_content}\\n</source>\\n\\n\"\n\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            \"6. Use XML tags to indicate sources.\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        # Use caching for llm.invoke to reduce latency on repeated queries (optional)\n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Object-oriented approach, Comprehensive implementation\n\n### Inspiration 2 (Score: 0.5529, Type: Experimental)\n```python\nimport os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers.\"\"\"\n        # Simple regex for {% tab label=\"Python\" %} blocks\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1)\n            content = match.group(2)\n            return f\"\\n\\n#### {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\[A2A\\]', breadcrumb): project_tags.append(\"[A2A]\")\n            if re.search(r'\\[WORKFLOW\\]', breadcrumb): project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    lang_tag = \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                c.page_content = f\"{prefix} {lang_tag} {breadcrumb} {p.metadata.get('tags','')}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        for i, d in enumerate(docs):\n            # Include metadata tags to help reranker identify language and completeness\n            lang_tag = \"[LANG=Unknown]\"\n            if \"[DOC_CODE]\" in d.page_content:\n                # Try detect language from breadcrumb or content heuristics\n                if re.search(r'```python', d.page_content, re.I):\n                    lang_tag = \"[LANG=Python]\"\n                elif re.search(r'```go', d.page_content, re.I):\n                    lang_tag = \"[LANG=Go]\"\n                elif re.search(r'```java', d.page_content, re.I):\n                    lang_tag = \"[LANG=Java]\"\n            # Detect if chunk likely contains a complete API definition or partial snippet\n            completeness_tag = \"[COMPLETE]\" if re.search(\n                r'^\\s*(class|func|interface|def|type|package|func\\s+main)\\s', d.page_content, re.I|re.M) else \"[PARTIAL]\"\n            \n            content_snippet = d.page_content[:1300].replace('\\n', ' ')\n            packed.append(f\"[{i}] {lang_tag} {completeness_tag} {content_snippet}\")\n        \n        prompt = (\n            \"Role: ADK Expert Reranker.\\n\"\n            \"Goal: Score each chunk from 0 to 100 on relevance to the query, prioritizing:\\n\"\n            \"1) Exact API names or full definitions over partial snippets.\\n\"\n            \"2) Code examples executable in the requested language.\\n\"\n            \"3) Language requested by user query (detect language tags).\\n\"\n            \"4) Prefer chunks with complete API definitions or full function/class blocks.\\n\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return JSON ONLY with format: {'scores': {chunk_id: score, ...}}\\n\"\n            \"Scores must be integers 0 to 100.\"\n        )\n        \n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            # Use regex to find JSON if model adds fluff\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match: return docs[:self.rerank_top_n]\n            \n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)), \n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))), \n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            # Use chunk language tag in content or fallback to unknown\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n        \n        # 3. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 4. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                # Filter parent context by language tag similarly\n                lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', parent.page_content)\n                parent_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n                if requested_lang == \"Python\" and parent_lang not in (\"Python\", \"Unknown\"):\n                    continue\n                elif requested_lang != \"Python\" and parent_lang != requested_lang:\n                    continue\n                \n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent.page_content}\\n</source>\\n\\n\"\n\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Object-oriented approach, Comprehensive implementation\n\n### Inspiration 3 (Score: 0.5209, Type: Experimental)\n```python\nimport os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with alias normalization and multi-lang snippet merging\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            # Normalize language aliases to consistent uppercase tags\n            lang_map = {\"py\": \"PYTHON\", \"python\": \"PYTHON\", \"go\": \"GO\", \"golang\": \"GO\", \"java\": \"JAVA\"}\n            lang_tag = lang_map.get(label.lower(), label.upper())\n            # Annotate with language tag in header for chunk tagging synergy\n            return f\"\\n\\n#### [{lang_tag}] {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        # Also flatten nested tabs by replacing tabs inside tabs (rare, but possible)\n        text = re.sub(pattern, replacement, text, flags=re.DOTALL)\n        return text\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags heuristically from breadcrumb or source filename\n            tags = []\n            if re.search(r'\\bworkflow\\b', breadcrumb, re.I) or 'workflow' in source.lower():\n                tags.append(\"[WORKFLOW]\")\n            if re.search(r'\\ba2a\\b', breadcrumb, re.I) or 'a2a' in source.lower():\n                tags.append(\"[A2A]\")\n            if tags:\n                p.metadata[\"tags\"] = \" \".join(tags)\n            else:\n                p.metadata[\"tags\"] = \"[GENERAL]\"\n            \n            # Detect language from first code fence in parent content for metadata and reranker\n            lang_match = re.search(r'```(\\w+)', p.page_content)\n            language = lang_match.group(1).lower() if lang_match else \"unknown\"\n            # Normalize language tags for consistent filtering downstream\n            if language in ('python', 'py'):\n                language = 'python'\n            elif language in ('go', 'golang'):\n                language = 'go'\n            elif language == 'java':\n                language = 'java'\n            else:\n                language = 'unknown'\n            p.metadata[\"language\"] = language\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation and language info\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language tag inside chunk (from markdown tab headers or code fences)\n                lang_tag = \"\"\n                lang_search = re.search(r'\\[(LANG=)?([A-Z]+)\\]', c.page_content)\n                if lang_search:\n                    lang_tag = f\"[LANG={lang_search.group(2)}]\"\n                else:\n                    # fallback: detect language from code fence\n                    fence_lang_search = re.search(r'```(\\w+)', c.page_content)\n                    if fence_lang_search:\n                        lang_tag = f\"[LANG={fence_lang_search.group(1).upper()}]\"\n                    else:\n                        lang_tag = \"[LANG=UNKNOWN]\"\n                # Compose chunk content prefix with tags and breadcrumb for reranker and generation\n                tag_str = p.metadata.get(\"tags\", \"\")\n                c.page_content = f\"{prefix} {lang_tag} {tag_str} {breadcrumb}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                c.metadata[\"language\"] = language\n                c.metadata[\"tags\"] = tag_str\n                # Add project_area to chunk metadata for reranker synergy\n                c.metadata[\"project_area\"] = tag_str if tag_str else \"[GENERAL]\"\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM with enhanced prompt for language, completeness, and API definition detection.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        # Detect requested language from query for prompt emphasis\n        requested_lang = None\n        lang_search = re.search(r'\\b(python|go|java)\\b', query, re.I)\n        if lang_search:\n            requested_lang = lang_search.group(1).lower()\n        \n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1400].replace('\\n', ' ').strip()\n            tags = d.metadata.get(\"tags\", \"\")\n            breadcrumb = d.metadata.get(\"breadcrumb\", \"\")\n            lang = d.metadata.get(\"language\", \"unknown\")\n            completeness_tag = \"[COMPLETE_API]\" if re.search(r'\\b(class|func|def|interface|type)\\s+\\w+', snippet, re.I) else \"[PARTIAL]\"\n            requested_lang_tag = \"[REQUESTED_LANG]\" if requested_lang and lang == requested_lang else \"\"\n            packed.append(f\"[{i}] {completeness_tag} {requested_lang_tag} Tags:{tags} Breadcrumb:{breadcrumb}\\n{snippet}\")\n        \n        prompt = (\n            \"Role: Google ADK Expert Reranker.\\n\"\n            \"Goal: Given a user query and a list of documentation chunks, assign a relevance score 0-100. Prioritize:\\n\"\n            \"- Exact API names matching the query.\\n\"\n            \"- Complete API definitions over partial snippets.\\n\"\n            \"- Code examples in the user's requested programming language.\\n\"\n            \"- Proper handling of multi-language snippets.\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return a JSON object with format: {'scores': {chunk_id: score, ...}} with integer scores.\"\n        )\n        \n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match:\n                return docs[:self.rerank_top_n]\n            \n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)),\n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))),\n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Detect requested language from query (case-insensitive)\n        requested_lang = None\n        lang_candidates = ['python', 'go', 'java']\n        query_lower = query_str.lower()\n        for lang in lang_candidates:\n            if re.search(r'\\b' + lang + r'\\b', query_lower):\n                requested_lang = lang\n                break\n\n        # 2. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n\n        # 3. Cross-language filtering: filter candidates to requested language if specified\n        if requested_lang:\n            filtered_candidates = []\n            for c in candidates:\n                # Check language tag in chunk content or metadata\n                chunk_lang = c.metadata.get(\"language\", \"unknown\")\n                # Accept if chunk language matches or is unknown (for Python default)\n                if chunk_lang == requested_lang or (requested_lang == \"python\" and chunk_lang == \"unknown\"):\n                    filtered_candidates.append(c)\n            # Use filtered only if enough candidates to preserve recall\n            if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n                candidates = filtered_candidates\n            else:\n                # Relax filtering by including chunks with [LANG=UNKNOWN] tag if too few candidates remain\n                relaxed = [c for c in candidates if \"[LANG=UNKNOWN]\" in c.page_content]\n                candidates.extend(relaxed)\n                # Deduplicate candidates by id (if available)\n                seen = set()\n                unique_candidates = []\n                for cand in candidates:\n                    cid = id(cand)\n                    if cid not in seen:\n                        seen.add(cid)\n                        unique_candidates.append(cand)\n                candidates = unique_candidates\n\n        # 4. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n\n        # 5. Parent Retrieval & Formatting with XML-style tags and language filtering\n        final_contexts = []\n        seen_parents = set()\n        context_blocks = []\n\n        def chunk_language_filter(chunk_text: str) -> bool:\n            # Accept chunk if no language requested, or matches requested language tag or code fence\n            if requested_lang is None:\n                return True\n            lang_tag = requested_lang.capitalize()\n            if f\"#### [{lang_tag}]\" in chunk_text:\n                return True\n            if re.search(r'\\[' + requested_lang.upper() + r'\\]', chunk_text, re.I):\n                return True\n            if chunk_text.startswith(\"[DOC_CODE]\"):\n                return True\n            return False\n\n        for c in top_chunks:\n            if not chunk_language_filter(c.page_content):\n                continue\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                if not chunk_language_filter(parent.page_content):\n                    continue\n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Summarize parent content for conciseness (up to 1000 chars)\n                parent_summary = parent.page_content[:1000].strip()\n                if len(parent.page_content) > 1000:\n                    parent_summary += \"...\"\n                context_blocks.append(f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent_summary}\\n</source>\")\n\n        context_block = \"\\n\\n\".join(context_blocks)\n\n        # 6. Generation (Strict Grounding) with improved prompt emphasizing Quote then Explain and language adherence\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using ONLY the provided context.\\n\"\n            \"Rules:\\n\"\n            \"1. If the answer is not found in the context, respond exactly: 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc or code snippet, then provide your explanation.\\n\"\n            \"4. Only provide code or examples in the requested programming language if specified; if none specified, default to Python but mention other languages exist.\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n\n        res = self.llm.invoke(prompt)\n        gc.collect()\n\n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], Object-oriented approach, Comprehensive implementation\n\n# Current Program\n```python\nimport os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            # Append a standardized language tag for chunk tagging synergy\n            return f\"\\n\\n#### [{lang_tag}] {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\[A2A\\]', breadcrumb): project_tags.append(\"[A2A]\")\n            if re.search(r'\\[WORKFLOW\\]', breadcrumb): project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    lang_tag = \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                c.page_content = f\"{prefix} {lang_tag} {breadcrumb} {p.metadata.get('tags','')}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        for i, d in enumerate(docs):\n            # Include metadata tags to help reranker identify language and completeness\n            lang_tag = \"[LANG=Unknown]\"\n            if \"[DOC_CODE]\" in d.page_content:\n                # Try detect language from breadcrumb or content heuristics\n                if re.search(r'```python', d.page_content, re.I):\n                    lang_tag = \"[LANG=Python]\"\n                elif re.search(r'```go', d.page_content, re.I):\n                    lang_tag = \"[LANG=Go]\"\n                elif re.search(r'```java', d.page_content, re.I):\n                    lang_tag = \"[LANG=Java]\"\n            completeness_tag = \"[COMPLETE]\" if re.search(r'^\\s*(class|func|interface|def|type)\\s', d.page_content, re.I|re.M) else \"[PARTIAL]\"\n            \n            content_snippet = d.page_content[:1300].replace('\\n', ' ')\n            packed.append(f\"[{i}] {lang_tag} {completeness_tag} {content_snippet}\")\n        \n        prompt = (\n            \"Role: ADK Expert Reranker.\\n\"\n            \"Goal: Score each chunk from 0 to 100 on relevance to the query, prioritizing:\\n\"\n            \"1) Exact API names or full definitions over partial snippets.\\n\"\n            \"2) Code examples executable in the requested language.\\n\"\n            \"3) Language requested by user query (detect language tags).\\n\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return JSON ONLY with format: {'scores': {chunk_id: score, ...}}\\n\"\n            \"Scores must be integers 0 to 100.\"\n        )\n        \n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            # Use regex to find JSON if model adds fluff\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match: return docs[:self.rerank_top_n]\n            \n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)), \n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))), \n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # 2. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 3. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent.page_content}\\n</source>\\n\\n\"\n\n        # 4. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, combined_score\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["<<<<<<< SEARCH\n        # 2. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 3. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent.page_content}\\n</source>\\n\\n\"\n\n        # 4. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n=======\n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n\n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n\n        # 3. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n\n        # 4. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n\n        # Summarize parent contexts to reduce context length and improve generation relevance\n        def summarize_parent(text: str) -> str:\n            max_len = 1000\n            if len(text) > max_len:\n                return text[:max_len].rstrip() + \"\\n... [truncated]\"\n            return text\n\n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                # Filter parent context by language tag similarly\n                lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', parent.page_content)\n                parent_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n                # Accept unknown language parents for Python queries to preserve recall\n                if requested_lang == \"Python\" and parent_lang not in (\"Python\", \"Unknown\"):\n                    continue\n                elif requested_lang != \"Python\" and parent_lang != requested_lang:\n                    continue\n\n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                parent_summary = summarize_parent(parent.page_content)\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent_summary}\\n</source>\\n\\n\"\n\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using ONLY the provided context.\\n\"\n            \"Rules:\\n\"\n            \"1. If the answer is not found in the context, respond exactly: 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc or code snippet, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n\n        try:\n            res = self.llm.invoke(prompt)\n        except Exception as e:\n            print(f\"LLM generation failed: {e}\")\n            return {\"answer\": \"I don't know from the provided documentation\", \"contexts\": final_contexts}\n        finally:\n            gc.collect()\n\n        return {\"answer\": res.content, \"contexts\": final_contexts}\n>>>>>>> REPLACE"]}}, "artifacts_json": "{\"raw_scores\": [0.5, 0.5083333333333333, 0.5, 0.5857142857142857, 0.5089285714285715, 0.8200000000000001, 0.525, 0.6630952380952382, 0.428125, 0.5], \"error_details\": [{\"sample\": 3, \"type\": \"code_error\", \"message\": \"[\\\"Instantiation Error on line 11: name 'get_weather' is not defined\\\"]\", \"bad_code\": \"def get_weather(city: str) -> dict:\\n    \\\"\\\"\\\"Retrieves weather for a city.\\\"\\\"\\\"\\n    return {\\\"status\\\": \\\"success\\\", \\\"temperature\\\": \\\"25\\u00b0C\\\"}\\n\\nfrom google.adk.tools import FunctionTool\\n\\ndef get_weather(city: str) -> dict:\\n    \\\"\\\"\\\"Retrieves weather for a city.\\\"\\\"\\\"\\n    return {\\\"status\\\": \\\"success\\\", \\\"temperature\\\": \\\"25\\u00b0C\\\"}\\n\\nget_weather_tool = FunctionTool(func=get_weather)\"}, {\"sample\": 4, \"type\": \"code_error\", \"message\": \"Syntax Error: invalid syntax (<unknown>, line 48)\", \"bad_code\": \"# Copyright 2025 Google LLC\\n#\\n# Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\\n# you may not use this file except in compliance with the License.\\n# You may obtain a copy of the License at\\n#\\n#     http://www.apache.org/licenses/LICENSE-2.0\\n#\\n# Unless required by applicable law or agreed to in writing, software\\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n# See the License for the specific language governing permissions and\\n# limitations under the License.\\n\\nimport asyncio\\nfrom google.adk.agents import LlmAgent\\nfrom google.adk.runners import Runner\\nfrom google.adk.sessions import InMemorySessionService\\nfrom google.genai import types\\n\\nasync def main():\\n    # Create the LlmAgent with model and instruction\\n    agent = LlmAgent(\\n        model=\\\"gemini-2.0-flash\\\",\\n        name=\\\"my_agent\\\",\\n        instruction=\\\"You are a helpful assistant.\\\"\\n    )\\n\\n    # Create a runner to run the agent\\n    runner = Runner(agent=agent, session_service=InMemorySessionService())\\n\\n    # Prepare a request with the question to ask\\n    request = types.LlmRequest(\\n        prompt=\\\"What is the capital of France?\\\",\\n        temperature=0.2,\\n        max_output_tokens=256\\n    )\\n\\n    # Run the agent with the request\\n    response = await runner.run(request)\\n\\n    # Print the agent's response text\\n    print(\\\"Agent response:\\\", response.output)\\n\\nif __name__ == \\\"__main__\\\":\\n    asyncio.run(main())\\n\\n> from google.adk.agents import LlmAgent\\n> \\n> agent = LlmAgent(\\n> model=\\\"gemini-2.0-flash\\\",\\n> name=\\\"my_agent\\\",\\n> instruction=\\\"You are a helpful assistant.\\\",\\n> tools=[my_tool_function]\\n> )\\n>\\n\\n> import asyncio\\n> from google.adk.agents import LlmAgent\\n> from google.adk.runners import Runner\\n> from google.adk.sessions import InMemorySessionService\\n> from google.genai import types\\n> \\n> async def main():\\n>     agent = LlmAgent(\\n>         model=\\\"gemini-2.0-flash\\\",\\n>         name=\\\"my_agent\\\",\\n>         instruction=\\\"You are a helpful assistant.\\\"\\n>     )\\n>     runner = Runner(agent=agent, session_service=InMemorySessionService())\\n>     request = types.LlmRequest(\\n>         prompt=\\\"What is the capital of France?\\\",\\n>         temperature=0.2,\\n>         max_output_tokens=256\\n>     )\\n>     response = await runner.run(request)\\n>     print(\\\"Agent response:\\\", response.output)\\n> \\n> if __name__ == \\\"__main__\\\":\\n>     asyncio.run(main())\\n>\"}, {\"sample\": 6, \"type\": \"code_error\", \"message\": \"Syntax Error: unterminated string literal (detected at line 7) (<unknown>, line 7)\", \"bad_code\": \"The `tool_context.state` attribute provides direct read and write access to the state associated with the current session. It behaves like a dictionary but ensures that any modifications are tracked as deltas and persisted by the session service. This enables tools to maintain and share information across different interactions and agent steps.  \\n* **Reading State**: Use standard dictionary access (`tool_context.state['my_key']`) or the `.get()` method (`tool_context.state.get('my_key', default_value)`).\\n* **Writing State**: Assign values directly (`tool_context.state['new_key'] = 'new_value'`). These changes are recorded in the state_delta of the resulting event.\\n\\nFor more advanced scenarios, ADK allows you to access additional contextual information within your tool function by including the special parameter `tool_context: ToolContext`. By including this in the function signature, ADK will **automatically** provide an **instance of the ToolContext** class when your tool is called during agent execution.  \\nThe **ToolContext** provides access to several key pieces of information and control levers:  \\n* `state: State`: Read and modify the current session's state. Changes made here are tracked and persisted.\\n\\nfrom google.adk.tools import ToolContext\\n\\ndef my_tool_function(tool_context: ToolContext):\\n    # Read a value from the session state (with a default)\\n    current_count = tool_context.state.get('count', 0)\\n    \\n    # Modify the state by incrementing the count\\n    tool_context.state['count'] = current_count + 1\\n    \\n    # Optionally return some result\\n    return f\\\"Count updated to {tool_context.state['count']}\\\"\"}, {\"sample\": 7, \"type\": \"code_error\", \"message\": \"Syntax Error: invalid syntax (<unknown>, line 20)\", \"bad_code\": \"# Python\\nfrom google.adk.agents import SequentialAgent, LlmAgent\\nfrom google.adk.runtime import Runner\\n\\n# Define three LlmAgents with output_key to pass data via shared state\\nagent1 = LlmAgent(name=\\\"Step1_Fetch\\\", instruction=\\\"Fetch some data.\\\", output_key=\\\"data\\\")\\nagent2 = LlmAgent(name=\\\"Step2_Process\\\", instruction=\\\"Process the data: {data}.\\\", output_key=\\\"processed_data\\\")\\nagent3 = LlmAgent(name=\\\"Step3_Summarize\\\", instruction=\\\"Summarize the processed data: {processed_data}.\\\", output_key=\\\"summary\\\")\\n\\n# Create a SequentialAgent pipeline with the three sub_agents\\npipeline = SequentialAgent(name=\\\"MyPipeline\\\", sub_agents=[agent1, agent2, agent3])\\n\\n# Run the pipeline using the Runner\\nrunner = Runner()\\nresult = runner.run(pipeline)\\n\\n# Print the final state to see the outputs passed through the pipeline\\nprint(result.state)\\n\\n> step1 = LlmAgent(name=\\\"Step1_Fetch\\\", output_key=\\\"data\\\") # Saves output to state['data']\\n> step2 = LlmAgent(name=\\\"Step2_Process\\\", instruction=\\\"Process data from {data}.\\\")\\n> pipeline = SequentialAgent(name=\\\"MyPipeline\\\", sub_agents=[step1, step2])\\n> # When pipeline runs, Step2 can access the state['data'] set by Step1.\\n>\"}, {\"sample\": 8, \"type\": \"code_error\", \"message\": \"Syntax Error: invalid syntax (<unknown>, line 3)\", \"bad_code\": \"LoopAgent(sub_agents=[WriterAgent, CriticAgent], max_iterations=5)\\n\\nExplanation:  \\nTo implement a retry loop in a `LoopAgent` that exits early when a condition is met, you create sub-agents that run in sequence each iteration. One or more sub-agents should check the condition and signal termination by setting `actions.escalate = True` during their execution (for example, inside a tool or callback). This escalation signals the `LoopAgent` to stop looping early before reaching the max iterations.\\n\\nHere is a minimal Python example illustrating this pattern:\"}]}", "artifact_dir": null, "embedding": null}