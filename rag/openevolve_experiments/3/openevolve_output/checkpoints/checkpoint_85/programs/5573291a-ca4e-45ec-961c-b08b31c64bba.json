{"id": "5573291a-ca4e-45ec-961c-b08b31c64bba", "code": "import os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\", \"js\": \"JavaScript\", \"javascript\": \"JavaScript\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            # Append a standardized language tag for chunk tagging synergy\n            return f\"\\n\\n#### [{lang_tag}] {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\[A2A\\]', breadcrumb): project_tags.append(\"[A2A]\")\n            if re.search(r'\\[WORKFLOW\\]', breadcrumb): project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"[GENERAL]\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\", \"javascript\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    lang_tag = \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                # Also add project area tag into chunk content for reranker synergy\n                project_area = p.metadata.get(\"tags\", \"[GENERAL]\")\n                c.page_content = f\"{prefix} {lang_tag} {project_area} {breadcrumb}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                c.metadata[\"project_area\"] = project_area\n                c.metadata[\"language\"] = lang_tag[6:-1] if lang_tag.startswith(\"[LANG=\") else \"Unknown\"\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM with enhanced prompt for multi-language & completeness detection.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        requested_lang = None\n        # Detect requested language from query for prompt emphasis\n        lang_match = re.search(r'\\b(python|go|java)\\b', query, re.I)\n        if lang_match:\n            requested_lang = lang_match.group(1).lower()\n\n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1400].replace('\\n', ' ').strip()\n            completeness_tag = \"[COMPLETE_API]\" if re.search(r'\\b(class|func|def|interface|type|package|func\\s+main|enum|struct|const|var|method)\\s+\\w*', snippet, re.I) else \"[PARTIAL]\"\n            lang = d.metadata.get(\"language\", \"unknown\").lower()\n            requested_lang_tag = \"[REQUESTED_LANG]\" if requested_lang and lang == requested_lang else \"\"\n            tags = d.metadata.get(\"tags\", \"\")\n            breadcrumb = d.metadata.get(\"breadcrumb\", \"\")\n            packed.append(f\"[{i}] {completeness_tag} {requested_lang_tag} Tags:{tags} Breadcrumb:{breadcrumb}\\n{snippet}\")\n\n        prompt = (\n            \"Role: ADK Expert Reranker.\\n\"\n            \"Goal: Score each chunk from 0 to 100 for relevance to the query.\\n\"\n            \"Prioritize chunks with:\\n\"\n            \"- Exact API names matching the query\\n\"\n            \"- Complete API definitions over partial snippets\\n\"\n            \"- Code examples in the user's requested programming language\\n\"\n            \"- Proper handling of multi-language snippets\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return JSON object with 'scores' mapping chunk IDs to numeric scores.\"\n        )\n\n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match:\n                return docs[:self.rerank_top_n]\n\n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)),\n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))),\n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\", \"javascript\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            # Use chunk language tag in content or fallback to unknown\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n        else:\n            # If too few, fallback to original for recall preservation\n            pass\n        \n        # 3. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 4. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                # Filter parent context by language tag similarly\n                lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', parent.page_content)\n                parent_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n                # Accept unknown language parents for Python queries to preserve recall\n                if requested_lang == \"Python\" and parent_lang not in (\"Python\", \"Unknown\"):\n                    continue\n                elif requested_lang != \"Python\" and parent_lang != requested_lang:\n                    continue\n                \n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent.page_content}\\n</source>\\n\\n\"\n\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            \"6. Use XML tags to indicate sources.\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        # Use caching for llm.invoke to reduce latency on repeated queries (optional)\n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        # Defensive fallback if no contexts found in answer, add explicit note\n        if not final_contexts and \"I don't know\" not in res.content:\n            fallback_note = \"\\n\\nNote: No relevant context was found in the documentation.\"\n            return {\"answer\": res.content + fallback_note, \"contexts\": final_contexts}\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n", "language": "python", "parent_id": "d78acf0f-f24c-4735-a618-0281168050fb", "generation": 5, "timestamp": 1769737229.5551527, "iteration_found": 75, "metrics": {"combined_score": 0.5891845238095239, "num_samples": 10}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 9 lines with 9 lines\nChange 2: Replace 15 lines with 15 lines\nChange 3: Replace 62 lines with 63 lines\nChange 4: Replace 8 lines with 8 lines\nChange 5: Replace 28 lines with 28 lines\nChange 6: Replace 21 lines with 26 lines", "parent_metrics": {"combined_score": 0.6422142857142857, "num_samples": 10}, "island": 4}, "prompts": {"diff_user": {"system": "You are an expert RAG system optimizer for Google ADK documentation. Improve the code to maximize RAG-pipeline performance.\n\nThe current architecture uses a **Parent-Child Retrieval** system with **Hybrid Search** and **LLM Reranking**.\n\n### High-Leverage Evolution Points:\n\n1. **Hyperparameter Synergy**: Optimize the balance between `chunk_size` (for retrieval precision), `top_k_vector/bm25` (for recall), and `weight_vector/bm25`. The documentation has many exact API names which may favor BM25, while conceptual \"how-to\" queries favor Vector.\n2. **Reranker Prompt Engineering**: The `_llm_rerank` prompt is critical. Evolve it to better identify relevance, handle multi-language snippets, or detect if a chunk contains a complete API definition vs. a partial snippet.\n3. **Metadata-Rich Ingestion**: Enhance `_chunk_document` to include more context in `breadcrumb` and `tagging`. Consider adding language-specific tags or project-area identifiers (e.g. `[A2A]`, `[WORKFLOW]`) to help the reranker and generator.\n4. **Context Assembly & Prompting**: Optimize the `context_block` formatting in `query`. Experiment with summarizing parent context or using XML-style tags to separate sources. Refine the final generation prompt for better \"Quote then Explain\" adherence.\n5. **Cross-Language Filtering**: Implement logic to detect the user's requested language and prioritize or filter retrieved chunks to reduce cross-language noise.\n\n**STRICT RULES**:\n- **Fork-Safety**: Avoid any top-level imports of `langchain`, `agno`, or `openai`. Use lazy imports inside methods.\n- **Compatibility**: Ensure `evaluate_rag(docs_path, query)` maintains its signature.\n- **Cleanup**: Always call `gc.collect()` after LLM calls or retrieval to maintain memory stability.\n\n**Example Improvement (Reranker Logic)**:\n```python\n# You can evolve the reranker prompt to be more specific:\nprompt = (\n    \"Role: ADK Expert Reranker. \"\n    \"Goal: Select chunks that provide EXECUTABLE code for the query. \"\n    f\"Query: {query}\\n\"\n    \"Chunks: ... \"\n)\n```\n- Maintain `evaluate_rag(docs_path, query)` signature and return keys: `answer`, `contexts`.\n- Keep `RAGSystem` class structure and lazy-loading in `__init__`.\n", "user": "# Current Program Information\n- Fitness: 0.6422\n- Feature coordinates: combined_score=0.64\n- Focus areas: - Fitness unchanged at 0.6422\n- Exploring combined_score=0.64 region of solution space\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Change 1: Replace 9 lines with 11 lines\nChange 2: Replace 10 lines with 11 lines\nChange 3: Replace 21 lines with 24 lines\nChange 4: Replace 47 lines with 47 lines\nChange 5: Replace 28 lines with 31 lines\nChange 6: Replace 45 lines with 46 lines\n- Metrics: combined_score: 0.6422, num_samples: 10.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.6422)\n```python\nimport os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            # Append a standardized language tag for chunk tagging synergy\n            return f\"\\n\\n#### [{lang_tag}] {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\[A2A\\]', breadcrumb): project_tags.append(\"[A2A]\")\n            if re.search(r'\\[WORKFLOW\\]', breadcrumb): project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    lang_tag = \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                # Also add project area tag into chunk content for reranker synergy\n                project_area = p.metadata.get(\"tags\", \"[GENERAL]\")\n                c.page_content = f\"{prefix} {lang_tag} {project_area} {breadcrumb}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                c.metadata[\"project_area\"] = project_area\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM with enhanced prompt for multi-language & completeness detection.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        requested_lang = None\n        # Detect requested language from query for prompt emphasis\n        lang_match = re.search(r'\\b(python|go|java)\\b', query, re.I)\n        if lang_match:\n            requested_lang = lang_match.group(1).lower()\n\n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1400].replace('\\n', ' ').strip()\n            completeness_tag = \"[COMPLETE_API]\" if re.search(r'\\b(class|func|def|interface|type|package|func\\s+main)\\s+\\w*', snippet, re.I) else \"[PARTIAL]\"\n            lang = d.metadata.get(\"language\", \"unknown\").lower()\n            requested_lang_tag = \"[REQUESTED_LANG]\" if requested_lang and lang == requested_lang else \"\"\n            tags = d.metadata.get(\"tags\", \"\")\n            breadcrumb = d.metadata.get(\"breadcrumb\", \"\")\n            packed.append(f\"[{i}] {completeness_tag} {requested_lang_tag} Tags:{tags} Breadcrumb:{breadcrumb}\\n{snippet}\")\n\n        prompt = (\n            \"Role: ADK Expert Reranker.\\n\"\n            \"Goal: Score each chunk from 0 to 100 for relevance to the query.\\n\"\n            \"Prioritize chunks with:\\n\"\n            \"- Exact API names matching the query\\n\"\n            \"- Complete API definitions over partial snippets\\n\"\n            \"- Code examples in the user's requested programming language\\n\"\n            \"- Proper handling of multi-language snippets\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return JSON object with 'scores' mapping chunk IDs to numeric scores.\"\n        )\n\n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match:\n                return docs[:self.rerank_top_n]\n\n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)),\n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))),\n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            # Use chunk language tag in content or fallback to unknown\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n        else:\n            # If too few, fallback to original for recall preservation\n            pass\n        \n        # 3. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 4. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                # Filter parent context by language tag similarly\n                lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', parent.page_content)\n                parent_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n                # Accept unknown language parents for Python queries to preserve recall\n                if requested_lang == \"Python\" and parent_lang not in (\"Python\", \"Unknown\"):\n                    continue\n                elif requested_lang != \"Python\" and parent_lang != requested_lang:\n                    continue\n                \n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent.page_content}\\n</source>\\n\\n\"\n\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            \"6. Use XML tags to indicate sources.\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        # Use caching for llm.invoke to reduce latency on repeated queries (optional)\n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n\n```\nKey features: Performs well on combined_score (0.6422), Performs well on num_samples (10.0000)\n\n\n\n# Current Program\n```python\nimport os\nimport re\nimport gc\nfrom typing import Dict, Any, List, Optional\nfrom dotenv import load_dotenv\n\n# --- BOILERPLATE: DO NOT EVOLVE ---\n_rag_system_cache = None\n\ndef evaluate_rag(docs_path: str, query: str) -> Dict[str, Any]:\n    global _rag_system_cache\n    try:\n        # Simple caching to avoid re-ingesting for every query if docs path hasn't changed\n        if _rag_system_cache is None or _rag_system_cache.docs_dir != docs_path:\n            _rag_system_cache = RAGSystem(docs_path)\n            \n        return _rag_system_cache.query(query)\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return {\"answer\": f\"Error: {str(e)}\", \"contexts\": []}\n# --- END BOILERPLATE ---\n\n# EVOLVE-BLOCK-START\n# Imports removed from top-level to prevent parent process initialization\n# They are now lazy-loaded in RAGSystem.__init__ to ensure fork-safety\n\nclass RAGSystem:\n    def __init__(self, docs_dir: str):\n        self.docs_dir = docs_dir\n        self.retriever = None\n        self.llm = None\n        self.rerank_llm = None\n        self.parent_docs = {} # storage for parent nodes\n        \n        # Hyperparameters for evolution\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n        \n        # Load env from multiple possible locations\n        env_paths = [\n            os.path.join(os.path.dirname(__file__), '.env'),\n            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')\n        ]\n        for p in env_paths:\n            if os.path.exists(p):\n                load_dotenv(p)\n                \n        self._initialize_system()\n\n    def _initialize_system(self):\n        from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n        from langchain_core.documents import Document\n        from langchain_community.vectorstores import FAISS\n        from langchain_community.retrievers import BM25Retriever\n        from langchain_classic.retrievers import EnsembleRetriever\n        \n        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n        self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=self.temperature)\n        self.rerank_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n        \n        # Ingestion\n        all_chunks = []\n        if os.path.exists(self.docs_dir):\n            for root, dirs, files in os.walk(self.docs_dir):\n                dirs[:] = [d for d in dirs if not d.startswith('.')]\n                for file in files:\n                    if not file.endswith('.md') or file.startswith('.'): continue\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, 'r', encoding='utf-8') as f:\n                            text_content = f.read()\n                        \n                        # Apply evolved chunking strategy\n                        chunks = self._chunk_document(text_content, file_path)\n                        all_chunks.extend(chunks)\n                    except Exception as e:\n                        print(f\"Skipping {file_path}: {e}\")\n\n        if not all_chunks:\n            self.retriever = None\n            return\n\n        # Vector Retriever\n        vector_db = FAISS.from_documents(all_chunks, embeddings)\n        vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": self.top_k_vector})\n        \n        # BM25 Retriever\n        bm25_retriever = BM25Retriever.from_documents(all_chunks)\n        bm25_retriever.k = self.top_k_bm25\n        \n        # Hybrid Ensemble (Base retrieval)\n        ensemble_retriever = EnsembleRetriever(\n            retrievers=[vector_retriever, bm25_retriever],\n            weights=[self.weight_vector, self.weight_bm25]\n        )\n        self.retriever = ensemble_retriever\n        \n        gc.collect()\n\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            # Append a standardized language tag for chunk tagging synergy\n            return f\"\\n\\n#### [{lang_tag}] {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\[A2A\\]', breadcrumb): project_tags.append(\"[A2A]\")\n            if re.search(r'\\[WORKFLOW\\]', breadcrumb): project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    lang_tag = \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                # Also add project area tag into chunk content for reranker synergy\n                project_area = p.metadata.get(\"tags\", \"[GENERAL]\")\n                c.page_content = f\"{prefix} {lang_tag} {project_area} {breadcrumb}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                c.metadata[\"project_area\"] = project_area\n                child_chunks.append(c)\n                \n        return child_chunks\n\n    def _llm_rerank(self, query: str, docs: List[Any]) -> List[Any]:\n        \"\"\"Rerank candidates using a small LLM with enhanced prompt for multi-language & completeness detection.\"\"\"\n        if not docs: return []\n        \n        packed = []\n        requested_lang = None\n        # Detect requested language from query for prompt emphasis\n        lang_match = re.search(r'\\b(python|go|java)\\b', query, re.I)\n        if lang_match:\n            requested_lang = lang_match.group(1).lower()\n\n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1400].replace('\\n', ' ').strip()\n            completeness_tag = \"[COMPLETE_API]\" if re.search(r'\\b(class|func|def|interface|type|package|func\\s+main)\\s+\\w*', snippet, re.I) else \"[PARTIAL]\"\n            lang = d.metadata.get(\"language\", \"unknown\").lower()\n            requested_lang_tag = \"[REQUESTED_LANG]\" if requested_lang and lang == requested_lang else \"\"\n            tags = d.metadata.get(\"tags\", \"\")\n            breadcrumb = d.metadata.get(\"breadcrumb\", \"\")\n            packed.append(f\"[{i}] {completeness_tag} {requested_lang_tag} Tags:{tags} Breadcrumb:{breadcrumb}\\n{snippet}\")\n\n        prompt = (\n            \"Role: ADK Expert Reranker.\\n\"\n            \"Goal: Score each chunk from 0 to 100 for relevance to the query.\\n\"\n            \"Prioritize chunks with:\\n\"\n            \"- Exact API names matching the query\\n\"\n            \"- Complete API definitions over partial snippets\\n\"\n            \"- Code examples in the user's requested programming language\\n\"\n            \"- Proper handling of multi-language snippets\\n\"\n            f\"User Query: {query}\\n\\n\"\n            \"Chunks:\\n\" + \"\\n\\n\".join(packed) + \"\\n\\n\"\n            \"Return JSON object with 'scores' mapping chunk IDs to numeric scores.\"\n        )\n\n        try:\n            import json\n            res = self.rerank_llm.invoke(prompt)\n            match = re.search(r'\\{.*\\}', res.content, re.DOTALL)\n            if not match:\n                return docs[:self.rerank_top_n]\n\n            scores = json.loads(match.group(0)).get(\"scores\", {})\n            ranked_indices = sorted(range(len(docs)),\n                                    key=lambda i: float(scores.get(str(i), scores.get(i, 0))),\n                                    reverse=True)\n            return [docs[i] for i in ranked_indices[:self.rerank_top_n]]\n        except Exception as e:\n            print(f\"Reranking failed: {e}\")\n            return docs[:self.rerank_top_n]\n\n    def query(self, query_str: str) -> Dict[str, Any]:\n        if not self.retriever:\n            return {\"answer\": \"No documents ingested.\", \"contexts\": []}\n\n        # 1. Retrieval (Hybrid)\n        candidates = self.retriever.invoke(query_str)\n        \n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            # Use chunk language tag in content or fallback to unknown\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n        else:\n            # If too few, fallback to original for recall preservation\n            pass\n        \n        # 3. Reranking\n        top_chunks = self._llm_rerank(query_str, candidates)\n        \n        # 4. Parent Retrieval & Formatting\n        final_contexts = []\n        seen_parents = set()\n        context_block = \"\"\n        \n        for c in top_chunks:\n            p_id = c.metadata.get(\"parent_id\")\n            if p_id in self.parent_docs and p_id not in seen_parents:\n                parent = self.parent_docs[p_id]\n                # Filter parent context by language tag similarly\n                lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', parent.page_content)\n                parent_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n                # Accept unknown language parents for Python queries to preserve recall\n                if requested_lang == \"Python\" and parent_lang not in (\"Python\", \"Unknown\"):\n                    continue\n                elif requested_lang != \"Python\" and parent_lang != requested_lang:\n                    continue\n                \n                seen_parents.add(p_id)\n                final_contexts.append(parent.page_content)\n                src = os.path.basename(parent.metadata.get(\"source\", \"unknown\"))\n                breadcrumb = parent.metadata.get(\"breadcrumb\", \"\")\n                # Wrap each source in XML-style tags for clearer separation\n                context_block += f\"<source file=\\\"{src}\\\" section=\\\"{breadcrumb}\\\">\\n{parent.page_content}\\n</source>\\n\\n\"\n\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            \"6. Use XML tags to indicate sources.\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        # Use caching for llm.invoke to reduce latency on repeated queries (optional)\n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n# EVOLVE-BLOCK-END\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, combined_score\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["<<<<<<< SEARCH\n        self.chunk_size = 500 # Smaller chunks for better retrieval precision\n        self.chunk_overlap = 100\n        self.top_k_vector = 20 \n        self.top_k_bm25 = 20\n        self.weight_vector = 0.5\n        self.weight_bm25 = 0.5\n        self.rerank_top_n = 8 \n        self.temperature = 0.0\n        self.expand_query = False \n=======\n        self.chunk_size = 400 # Reduced chunk size for finer granularity, aiding precision\n        self.chunk_overlap = 120 # Slightly increased overlap to preserve context at chunk boundaries\n        self.top_k_vector = 25  # Increased vector top_k for better recall on conceptual queries\n        self.top_k_bm25 = 30    # Increased BM25 top_k to better capture exact API matches\n        self.weight_vector = 0.3 # Shift weight towards BM25 to favor exact API name matches in docs\n        self.weight_bm25 = 0.7\n        self.rerank_top_n = 10  # More rerank candidates to improve final answer quality\n        self.temperature = 0.0\n        self.expand_query = False \n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            # Append a standardized language tag for chunk tagging synergy\n            return f\"\\n\\n#### [{lang_tag}] {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n=======\n    def _flatten_markdown_tabs(self, text: str) -> str:\n        \"\"\"Unrolls Google-style tab widgets into sequential headers with normalized language tags.\"\"\"\n        # Enhanced regex for {% tab label=\"Python\" %} blocks with language normalization\n        pattern = r'{% tab label=\"(.*?)\" %}(.*?){% endtab %}'\n        def replacement(match):\n            label = match.group(1).strip()\n            content = match.group(2)\n            lang_map = {\"py\": \"Python\", \"python\": \"Python\", \"go\": \"Go\", \"golang\": \"Go\", \"java\": \"Java\", \"js\": \"JavaScript\", \"javascript\": \"JavaScript\"}\n            lang_tag = lang_map.get(label.lower(), label)\n            # Append a standardized language tag for chunk tagging synergy\n            return f\"\\n\\n#### [{lang_tag}] {label} Implementation\\n{content}\\n\"\n        \n        text = re.sub(r'{% tabs %}', '', text)\n        text = re.sub(r'{% endtabs %}', '', text)\n        return re.sub(pattern, replacement, text, flags=re.DOTALL)\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\[A2A\\]', breadcrumb): project_tags.append(\"[A2A]\")\n            if re.search(r'\\[WORKFLOW\\]', breadcrumb): project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    lang_tag = \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                # Also add project area tag into chunk content for reranker synergy\n                project_area = p.metadata.get(\"tags\", \"[GENERAL]\")\n                c.page_content = f\"{prefix} {lang_tag} {project_area} {breadcrumb}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                c.metadata[\"project_area\"] = project_area\n                child_chunks.append(c)\n                \n        return child_chunks\n=======\n    def _chunk_document(self, text: str, source: str) -> List[Any]:\n        from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n        from langchain_core.documents import Document\n        import uuid\n        \n        text = self._flatten_markdown_tabs(text)\n        \n        # 1. Split by headers to create Parent documents\n        header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n            (\"#\", \"h1\"), (\"##\", \"h2\"), (\"###\", \"h3\"), (\"####\", \"h4\")\n        ])\n        parent_docs = header_splitter.split_text(text)\n        \n        child_chunks = []\n        child_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n            separators=[\"\\n```\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        \n        for p in parent_docs:\n            parent_id = str(uuid.uuid4())\n            breadcrumb = \" > \".join([p.metadata.get(f\"h{i}\", \"\") for i in range(1, 5)]).strip(\" > \")\n            p.metadata[\"source\"] = source\n            p.metadata[\"breadcrumb\"] = breadcrumb\n            \n            # Add project-area tags if identifiable from breadcrumb (example)\n            project_tags = []\n            if re.search(r'\\[A2A\\]', breadcrumb): project_tags.append(\"[A2A]\")\n            if re.search(r'\\[WORKFLOW\\]', breadcrumb): project_tags.append(\"[WORKFLOW]\")\n            if project_tags:\n                p.metadata[\"tags\"] = \" \".join(project_tags)\n            else:\n                p.metadata[\"tags\"] = \"[GENERAL]\"\n            \n            self.parent_docs[parent_id] = p\n            \n            # 2. Split parents into children\n            for c in child_splitter.split_documents([p]):\n                # Add tagging for better semantic separation\n                prefix = \"[DOC_CODE]\" if \"```\" in c.page_content else \"[DOC_TEXT]\"\n                # Detect language from code fences for tagging\n                lang_tag = \"\"\n                lang_match = re.search(r'```(\\w+)', c.page_content)\n                if lang_match:\n                    lang = lang_match.group(1).lower()\n                    if lang in (\"python\", \"go\", \"java\", \"javascript\"):\n                        lang_tag = f\"[LANG={lang.capitalize()}]\"\n                    else:\n                        lang_tag = \"[LANG=Unknown]\"\n                else:\n                    lang_tag = \"[LANG=Unknown]\"\n                # Add tags and breadcrumb into chunk content for better reranking and generation\n                # Also add project area tag into chunk content for reranker synergy\n                project_area = p.metadata.get(\"tags\", \"[GENERAL]\")\n                c.page_content = f\"{prefix} {lang_tag} {project_area} {breadcrumb}\\n{c.page_content}\"\n                c.metadata[\"parent_id\"] = parent_id\n                c.metadata[\"source\"] = source\n                c.metadata[\"project_area\"] = project_area\n                c.metadata[\"language\"] = lang_tag[6:-1] if lang_tag.startswith(\"[LANG=\") else \"Unknown\"\n                child_chunks.append(c)\n                \n        return child_chunks\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1400].replace('\\n', ' ').strip()\n            completeness_tag = \"[COMPLETE_API]\" if re.search(r'\\b(class|func|def|interface|type|package|func\\s+main)\\s+\\w*', snippet, re.I) else \"[PARTIAL]\"\n            lang = d.metadata.get(\"language\", \"unknown\").lower()\n            requested_lang_tag = \"[REQUESTED_LANG]\" if requested_lang and lang == requested_lang else \"\"\n            tags = d.metadata.get(\"tags\", \"\")\n            breadcrumb = d.metadata.get(\"breadcrumb\", \"\")\n            packed.append(f\"[{i}] {completeness_tag} {requested_lang_tag} Tags:{tags} Breadcrumb:{breadcrumb}\\n{snippet}\")\n=======\n        for i, d in enumerate(docs):\n            snippet = d.page_content[:1400].replace('\\n', ' ').strip()\n            completeness_tag = \"[COMPLETE_API]\" if re.search(r'\\b(class|func|def|interface|type|package|func\\s+main|enum|struct|const|var|method)\\s+\\w*', snippet, re.I) else \"[PARTIAL]\"\n            lang = d.metadata.get(\"language\", \"unknown\").lower()\n            requested_lang_tag = \"[REQUESTED_LANG]\" if requested_lang and lang == requested_lang else \"\"\n            tags = d.metadata.get(\"tags\", \"\")\n            breadcrumb = d.metadata.get(\"breadcrumb\", \"\")\n            packed.append(f\"[{i}] {completeness_tag} {requested_lang_tag} Tags:{tags} Breadcrumb:{breadcrumb}\\n{snippet}\")\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            # Use chunk language tag in content or fallback to unknown\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n        else:\n            # If too few, fallback to original for recall preservation\n            pass\n=======\n        # Detect requested language from query (simple heuristic)\n        requested_lang = None\n        lang_candidates = [\"python\", \"go\", \"java\", \"javascript\"]\n        lower_query = query_str.lower()\n        for lang in lang_candidates:\n            if lang in lower_query:\n                requested_lang = lang.capitalize()\n                break\n        if not requested_lang:\n            requested_lang = \"Python\"  # default\n        \n        # 2. Cross-language filtering: filter candidates to requested language if specified\n        filtered_candidates = []\n        for c in candidates:\n            # Use chunk language tag in content or fallback to unknown\n            lang_tag_search = re.search(r'\\[LANG=(\\w+)\\]', c.page_content)\n            chunk_lang = lang_tag_search.group(1) if lang_tag_search else \"Unknown\"\n            # Include chunks with unknown language for Python requests to avoid losing recall\n            if requested_lang == \"Python\" and chunk_lang in (\"Python\", \"Unknown\"):\n                filtered_candidates.append(c)\n            elif chunk_lang == requested_lang:\n                filtered_candidates.append(c)\n        # Use filtered candidates only if enough remain, else fallback to full candidate set\n        if filtered_candidates and len(filtered_candidates) >= max(3, self.rerank_top_n):\n            candidates = filtered_candidates\n        else:\n            # If too few, fallback to original for recall preservation\n            pass\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            \"6. Use XML tags to indicate sources.\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        # Use caching for llm.invoke to reduce latency on repeated queries (optional)\n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n=======\n        # 5. Generation (Strict Grounding)\n        prompt = (\n            \"You are a technical expert on Google ADK. Answer the user's question STRICTLY using the provided context. \"\n            \"Follow these rules:\\n\"\n            \"1. If the answer is not in the context, explicitly state 'I don't know from the provided documentation'.\\n\"\n            \"2. When mentioning API classes or methods, use the EXACT names found in the context.\\n\"\n            \"3. Use the 'Quote then Explain' pattern: first quote the relevant doc/code, then provide your explanation.\\n\"\n            f\"4. Only provide code or examples in the requested language: {requested_lang}. \"\n            \"If none requested, default to Python but mention other languages exist.\\n\\n\"\n            \"5. Clearly indicate the programming language of any code snippet you quote.\\n\\n\"\n            \"6. Use XML tags to indicate sources.\\n\"\n            f\"Context:\\n{context_block}\\n\\n\"\n            f\"Question: {query_str}\\n\\n\"\n            \"Answer:\"\n        )\n        \n        # Use caching for llm.invoke to reduce latency on repeated queries (optional)\n        res = self.llm.invoke(prompt)\n        gc.collect()\n        \n        # Defensive fallback if no contexts found in answer, add explicit note\n        if not final_contexts and \"I don't know\" not in res.content:\n            fallback_note = \"\\n\\nNote: No relevant context was found in the documentation.\"\n            return {\"answer\": res.content + fallback_note, \"contexts\": final_contexts}\n        \n        return {\"answer\": res.content, \"contexts\": final_contexts}\n>>>>>>> REPLACE"]}}, "artifacts_json": "{\"raw_scores\": [0.5, 0.515, 0.5, 0.65, 0.5125000000000001, 0.76, 0.685, 0.4130952380952381, 0.53125, 0.825], \"error_details\": [{\"sample\": 3, \"type\": \"code_error\", \"message\": \"Syntax Error: invalid syntax (<unknown>, line 12)\", \"bad_code\": \"# Core abstractions: wrap a function as a tool.\\nfrom google.adk.tools import FunctionTool, ToolContext\\n\\ndef get_time(tool_context: ToolContext) -> dict:\\n    return {\\\"time\\\": \\\"12:00\\\"}\\n\\ntime_tool = FunctionTool(func=get_time, name=\\\"get_time\\\")\\n\\nfrom google.adk.tools import FunctionTool, ToolContext\\nfrom typing import Dict\\n\\ndef my_authenticated_tool_function(param1: str, ..., tool_context: ToolContext) -> dict:\\n    # ... your logic ...\\n    pass\\n\\nmy_tool = FunctionTool(func=my_authenticated_tool_function)\\n\\ndef get_weather(city: str) -> dict:\\n    \\\"\\\"\\\"Retrieves weather for a city.\\\"\\\"\\\"\\n    return {\\\"status\\\": \\\"success\\\", \\\"temperature\\\": \\\"25\\u00b0C\\\"}\\n\\nfrom google.adk.tools import FunctionTool, ToolContext\\n\\ndef get_time(tool_context: ToolContext) -> dict:\\n    \\\"\\\"\\\"Returns the current time.\\\"\\\"\\\"\\n    return {\\\"status\\\": \\\"success\\\", \\\"time\\\": \\\"12:00\\\"}\\n\\ntime_tool = FunctionTool(func=get_time, name=\\\"get_time\\\")\"}, {\"sample\": 4, \"type\": \"code_error\", \"message\": \"[\\\"Instantiation Error on line 31: name 'MODEL_NAME' is not defined\\\", \\\"Instantiation Error on line 46: name 'agent' is not defined\\\"]\", \"bad_code\": \"import asyncio\\nimport json\\n\\nfrom google.adk.agents import LlmAgent\\nfrom google.adk.runners import Runner\\nfrom google.adk.sessions import InMemorySessionService\\nfrom google.genai import types\\nfrom pydantic import BaseModel, Field\\n\\n# --- 1. Define Constants ---\\nAPP_NAME = \\\"agent_comparison_app\\\"\\nUSER_ID = \\\"test_user_456\\\"\\nSESSION_ID = \\\"session_tool_agent_xyz\\\"\\nMODEL_NAME = \\\"gemini-2.0-flash\\\"\\n\\n# --- 2. Define a simple tool function ---\\ndef get_capital_city(country: str) -> str:\\n    \\\"\\\"\\\"Retrieves the capital city of a given country.\\\"\\\"\\\"\\n    print(f\\\"\\\\n-- Tool Call: get_capital_city(country='{country}') --\\\")\\n    country_capitals = {\\n        \\\"united states\\\": \\\"Washington, D.C.\\\",\\n        \\\"canada\\\": \\\"Ottawa\\\",\\n        \\\"france\\\": \\\"Paris\\\",\\n        \\\"japan\\\": \\\"Tokyo\\\",\\n    }\\n    result = country_capitals.get(country.lower(), f\\\"Sorry, I couldn't find the capital for {country}.\\\")\\n    print(f\\\"-- Tool Result: '{result}' --\\\")\\n    return result\\n\\n# --- 3. Create the LlmAgent with the tool ---\\nagent = LlmAgent(\\n    model=MODEL_NAME,\\n    name=\\\"capital_agent_tool\\\",\\n    instruction=\\\"\\\"\\\"You are a helpful agent that provides the capital city of a country using a tool.\\nThe user will provide the country name in a JSON format like {\\\"country\\\": \\\"country_name\\\"}.\\n1. Extract the country name.\\n2. Use the `get_capital_city` tool to find the capital.\\n3. Respond clearly to the user, stating the capital city found by the tool.\\n\\\"\\\"\\\",\\n    tools=[get_capital_city]\\n)\\n\\n# --- 4. Setup session service and runner ---\\nsession_service = InMemorySessionService()\\nsession = session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\\nrunner = Runner(agent=agent, app_name=APP_NAME, session_service=session_service)\\n\\n# --- 5. Define a function to call the agent ---\\ndef call_agent(query: str):\\n    content = types.Content(role='user', parts=[types.Part(text=query)])\\n    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\\n\\n    for event in events:\\n        print(f\\\"\\\\nDEBUG EVENT: {event}\\\\n\\\")\\n        if event.is_final_response() and event.content:\\n            final_answer = event.content.parts[0].text.strip()\\n            print(\\\"\\\\n\\ud83d\\udfe2 FINAL ANSWER\\\\n\\\", final_answer, \\\"\\\\n\\\")\\n\\n# --- 6. Run the agent with a sample query ---\\nif __name__ == \\\"__main__\\\":\\n    call_agent('{\\\"country\\\": \\\"France\\\"}')\"}, {\"sample\": 6, \"type\": \"code_error\", \"message\": \"[\\\"Instantiation Error on line 14: name 'update_user_preference' is not defined\\\", \\\"Instantiation Error on line 57: name 'update_user_preference' is not defined\\\"]\", \"bad_code\": \"from google.adk.tools import ToolContext, FunctionTool\\n\\ndef update_user_preference(preference: str, value: str, tool_context: ToolContext):\\n    \\\"\\\"\\\"Updates a user-specific preference.\\\"\\\"\\\"\\n    user_prefs_key = \\\"user:preferences\\\"\\n    # Get current preferences or initialize if none exist\\n    preferences = tool_context.state.get(user_prefs_key, {})\\n    preferences[preference] = value\\n    # Write the updated dictionary back to the state\\n    tool_context.state[user_prefs_key] = preferences\\n    print(f\\\"Tool: Updated user preference '{preference}' to '{value}'\\\")\\n    return {\\\"status\\\": \\\"success\\\", \\\"updated_preference\\\": preference}\\n\\npref_tool = FunctionTool(func=update_user_preference)\\n\\n# In an Agent:\\n# my_agent = Agent(..., tools=[pref_tool])\\n\\n# When the LLM calls update_user_preference(preference='theme', value='dark', ...):\\n# The tool_context.state will be updated, and the change will be part of the\\n# resulting tool response event's actions.state_delta.\\n\\n# Pseudocode: Tool 1 - Fetches user ID\\nfrom google.adk.tools import ToolContext\\nimport uuid\\n\\ndef get_user_profile(tool_context: ToolContext) -> dict:\\n    user_id = str(uuid.uuid4())  # Simulate fetching ID\\n    # Save the ID to state for the next tool\\n    tool_context.state[\\\"temp:current_user_id\\\"] = user_id\\n    return {\\\"profile_status\\\": \\\"ID generated\\\"}\\n\\n# Pseudocode: Tool 2 - Uses user ID from state\\ndef get_user_orders(tool_context: ToolContext) -> dict:\\n    user_id = tool_context.state.get(\\\"temp:current_user_id\\\")\\n    if not user_id:\\n        return {\\\"error\\\": \\\"User ID not found in state\\\"}\\n\\n    print(f\\\"Fetching orders for user ID: {user_id}\\\")\\n    # ... logic to fetch orders using user_id ...\\n    return {\\\"orders\\\": [\\\"order123\\\", \\\"order456\\\"]}\\n\\nfrom google.adk.tools import ToolContext, FunctionTool\\n\\ndef update_user_preference(preference: str, value: str, tool_context: ToolContext):\\n    \\\"\\\"\\\"Updates a user-specific preference in session state.\\\"\\\"\\\"\\n    user_prefs_key = \\\"user:preferences\\\"\\n    # Read existing preferences or initialize empty dict\\n    preferences = tool_context.state.get(user_prefs_key, {})\\n    preferences[preference] = value\\n    # Write updated preferences back to state\\n    tool_context.state[user_prefs_key] = preferences\\n    print(f\\\"Tool: Updated user preference '{preference}' to '{value}'\\\")\\n    return {\\\"status\\\": \\\"success\\\", \\\"updated_preference\\\": preference}\\n\\n# Wrap the function as a FunctionTool to use in an agent\\npref_tool = FunctionTool(func=update_user_preference)\\n\\ndef get_user_profile(tool_context: ToolContext) -> dict:\\n    user_id = \\\"some_generated_id\\\"\\n    tool_context.state[\\\"temp:current_user_id\\\"] = user_id\\n    return {\\\"profile_status\\\": \\\"ID generated\\\"}\\n\\ndef get_user_orders(tool_context: ToolContext) -> dict:\\n    user_id = tool_context.state.get(\\\"temp:current_user_id\\\")\\n    if not user_id:\\n        return {\\\"error\\\": \\\"User ID not found in state\\\"}\\n    # Fetch orders using user_id...\\n    return {\\\"orders\\\": [\\\"order123\\\", \\\"order456\\\"]}\"}, {\"sample\": 7, \"type\": \"code_error\", \"message\": \"[\\\"Import Error on line 3: No module named 'google.adk.runner'\\\", \\\"Import Error on line 7: No module named 'rx'\\\", \\\"Instantiation Error on line 35: name 'InMemoryRunner' is not defined\\\"]\", \"bad_code\": \"# Conceptual Code: Sequential Data Pipeline\\nfrom google.adk.agents import SequentialAgent, LlmAgent\\nfrom google.adk.runner import InMemoryRunner\\nfrom google.adk.sessions import Session\\nfrom google.adk.events import Event\\nfrom google.genai.types import Content, Part\\nfrom rx import operators as ops\\n\\n# Define three LlmAgents with output_key to pass data via shared state\\n\\nvalidator = LlmAgent(\\n    name=\\\"ValidateInput\\\",\\n    instruction=\\\"Validate the input.\\\",\\n    output_key=\\\"validation_status\\\"\\n)\\n\\nprocessor = LlmAgent(\\n    name=\\\"ProcessData\\\",\\n    instruction=\\\"Process data if {validation_status} is 'valid'.\\\",\\n    output_key=\\\"result\\\"\\n)\\n\\nreporter = LlmAgent(\\n    name=\\\"ReportResult\\\",\\n    instruction=\\\"Report the result from {result}.\\\"\\n)\\n\\n# Create a SequentialAgent pipeline with the three sub_agents\\ndata_pipeline = SequentialAgent(\\n    name=\\\"DataPipeline\\\",\\n    sub_agents=[validator, processor, reporter]\\n)\\n\\n# Create an InMemoryRunner to run the pipeline\\nrunner = InMemoryRunner(data_pipeline, app_name=\\\"DataPipelineApp\\\")\\n\\n# Create a session for a user\\nuser_id = \\\"user_123\\\"\\nsession = runner.session_service().create_session(\\\"DataPipelineApp\\\", user_id).blocking_first()\\n\\n# Prepare user input as Content\\nuser_input = Content.from_parts(Part.from_text(\\\"Sample input data to validate and process.\\\"))\\n\\n# Run the pipeline asynchronously and print final responses\\nevent_stream = runner.run_async(user_id, session.id, user_input)\\n\\n# Subscribe to events and print final response content\\nevent_stream.pipe(\\n    ops.filter(lambda e: e.final_response())\\n).subscribe(lambda e: print(e.stringify_content()))\"}, {\"sample\": 8, \"type\": \"code_error\", \"message\": \"[\\\"Instantiation Error on line 15: name 'CheckCondition' is not defined\\\", \\\"Instantiation Error on line 50: name 'CheckStatusAndEscalate' is not defined\\\", \\\"Instantiation Error on line 78: name 'CheckCondition' is not defined\\\", \\\"Instantiation Error on line 110: name 'CheckStatusAndEscalate' is not defined\\\"]\", \"bad_code\": \"# Conceptual Example: Loop with Condition\\nfrom google.adk.agents import LoopAgent, LlmAgent, BaseAgent\\nfrom google.adk.events import Event, EventActions\\nfrom google.adk.agents.invocation_context import InvocationContext\\nfrom typing import AsyncGenerator\\n\\nclass CheckCondition(BaseAgent): # Custom agent to check state\\n    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\\n        status = ctx.session.state.get(\\\"status\\\", \\\"pending\\\")\\n        is_done = (status == \\\"completed\\\")\\n        yield Event(author=self.name, actions=EventActions(escalate=is_done)) # Escalate if done\\n\\nprocess_step = LlmAgent(name=\\\"ProcessingStep\\\") # Agent that might update state['status']\\n\\npoller = LoopAgent(\\n    name=\\\"StatusPoller\\\",\\n    max_iterations=10,\\n    sub_agents=[process_step, CheckCondition(name=\\\"Checker\\\")]\\n)\\n# When poller runs, it executes process_step then Checker repeatedly\\n# until Checker escalates (state['status'] == 'completed') or 10 iterations pass.\\n\\n# Conceptual Code: Iterative Code Refinement\\nfrom google.adk.agents import LoopAgent, LlmAgent, BaseAgent\\nfrom google.adk.events import Event, EventActions\\nfrom google.adk.agents.invocation_context import InvocationContext\\nfrom typing import AsyncGenerator\\n\\n# Agent to generate/refine code based on state['current_code'] and state['requirements']\\ncode_refiner = LlmAgent(\\n    name=\\\"CodeRefiner\\\",\\n    instruction=\\\"Read state['current_code'] (if exists) and state['requirements']. Generate/refine Python code to meet requirements. Save to state['current_code'].\\\",\\n    output_key=\\\"current_code\\\" # Overwrites previous code in state\\n)\\n\\n# Agent to check if the code meets quality standards\\nquality_checker = LlmAgent(\\n    name=\\\"QualityChecker\\\",\\n    instruction=\\\"Evaluate the code in state['current_code'] against state['requirements']. Output 'pass' or 'fail'.\\\",\\n    output_key=\\\"quality_status\\\"\\n)\\n\\n# Custom agent to check the status and escalate if 'pass'\\nclass CheckStatusAndEscalate(BaseAgent):\\n    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\\n        status = ctx.session.state.get(\\\"quality_status\\\", \\\"fail\\\")\\n        should_stop = (status == \\\"pass\\\")\\n        yield Event(author=self.name, actions=EventActions(escalate=should_stop))\\n\\nrefinement_loop = LoopAgent(\\n    name=\\\"CodeRefinementLoop\\\",\\n    max_iterations=5,\\n    sub_agents=[code_refiner, quality_checker, CheckStatusAndEscalate(name=\\\"StopChecker\\\")]\\n)\\n# Loop runs: Refiner -> Checker -> StopChecker\\n# State['current_code'] is updated each iteration.\\n# Loop stops if QualityChecker outputs 'pass' (leading to StopChecker escalating) or after 5 iterations.\\n\\nfrom google.adk.agents import LoopAgent, LlmAgent, BaseAgent\\nfrom google.adk.events import Event, EventActions\\nfrom google.adk.agents.invocation_context import InvocationContext\\nfrom typing import AsyncGenerator\\n\\n# Custom agent that checks a condition in the shared state and escalates to exit the loop\\nclass CheckCondition(BaseAgent):\\n    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\\n        # Read a status flag from the session state\\n        status = ctx.session.state.get(\\\"status\\\", \\\"pending\\\")\\n        # Determine if the condition to exit the loop is met\\n        is_done = (status == \\\"completed\\\")\\n        # Emit an event with escalate=True to signal the LoopAgent to stop\\n        yield Event(author=self.name, actions=EventActions(escalate=is_done))\\n\\n# An example agent that performs some processing and may update the state\\nprocess_step = LlmAgent(name=\\\"ProcessingStep\\\")\\n\\n# Create the LoopAgent with a max iteration limit and the sub-agents\\npoller = LoopAgent(\\n    name=\\\"StatusPoller\\\",\\n    max_iterations=10,\\n    sub_agents=[process_step, CheckCondition(name=\\\"Checker\\\")]\\n)\\n\\n# When poller runs, it executes process_step then Checker repeatedly\\n# until Checker escalates (state['status'] == 'completed') or 10 iterations pass.\\n\\nfrom google.adk.agents import LoopAgent, LlmAgent, BaseAgent\\nfrom google.adk.events import Event, EventActions\\nfrom google.adk.agents.invocation_context import InvocationContext\\nfrom typing import AsyncGenerator\\n\\ncode_refiner = LlmAgent(\\n    name=\\\"CodeRefiner\\\",\\n    instruction=\\\"Read state['current_code'] and state['requirements']. Generate/refine code.\\\",\\n    output_key=\\\"current_code\\\"\\n)\\n\\nquality_checker = LlmAgent(\\n    name=\\\"QualityChecker\\\",\\n    instruction=\\\"Evaluate code quality and output 'pass' or 'fail'.\\\",\\n    output_key=\\\"quality_status\\\"\\n)\\n\\nclass CheckStatusAndEscalate(BaseAgent):\\n    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\\n        status = ctx.session.state.get(\\\"quality_status\\\", \\\"fail\\\")\\n        should_stop = (status == \\\"pass\\\")\\n        yield Event(author=self.name, actions=EventActions(escalate=should_stop))\\n\\nrefinement_loop = LoopAgent(\\n    name=\\\"CodeRefinementLoop\\\",\\n    max_iterations=5,\\n    sub_agents=[code_refiner, quality_checker, CheckStatusAndEscalate(name=\\\"StopChecker\\\")]\\n)\"}]}", "artifact_dir": null, "embedding": null}